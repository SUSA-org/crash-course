{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUSA CX Kaggle Capstone\n",
    "## Part 1: Introduction, Exploratory Data Analysis, and Feature Selection\n",
    "\n",
    "### Table Of Contents\n",
    "* [Introduction](#section1)\n",
    "* [Data Science Workflow](#section2)\n",
    "    1. [Understanding Our Dataset](#i)\n",
    "    2. [Data Cleaning](#ii)\n",
    "    3. [EDA](#iii)\n",
    "    4. [Modeling](#iiii)\n",
    "    5. [Model Evaluation](#v)\n",
    "* [Conclusion](#conclusion)\n",
    "* [Additional Reading](#reading)\n",
    "\n",
    "\n",
    "### Hosted by and maintained by the [Statistics Undergraduate Students Association (SUSA)](https://susa.berkeley.edu). Originally authored by [Arun Ramamurthy](mailto:contact@arun.run), [Patrick Chao](mailto:prc@berkeley.edu), & [Noah Gundotra](mailto:noah.gundotra@berkeley.edu).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "# SUSA CX Kaggle Capstone Project\n",
    "\n",
    "Welcome to the last four weeks of your semester in SUSA's Career Exploration committee! Now that you've participated in nearly a dozen workshops on Python, R, data science, and machine learning, we're going to guide you through a four-week collaborative Kaggle competition with your peers in Career Exploration. We want to give you the experience of working with real data, using real machine learning algorithms, in an educational setting. You will have to make use of your data computing skills in Python, dive into reading kernels on the Kaggle website, use visualization and feature engineering to improve your score, and maybe even pick up a few advanced deep learning models along the way. \n",
    "\n",
    "If this sounds a bit intimidating right now, do not fret! Your SUSA Mentors will be there to mentor you through the whole thing. Don't worry if our code, our approach, or any part of this process seems unnatural. It is. It takes time to learn, and it takes time to teach. We're learning as we make these tutorials, too! So without further ado, let's get cracking!\n",
    "\n",
    "## What is [Kaggle](https://www.kaggle.com/)?\n",
    "\n",
    "Kaggle is platform that hosts datasets & data science competitions. Kaggle started off as a small community of data science practitioners looking to hone their hobbying skills and meet like-minded folks, not unlike SUSA! :)\n",
    "\n",
    "\n",
    "Today they host many different types of competitions for [money from 1k to 1M](https://www.kaggle.com/c/data-science-bowl-2018), [jobs](https://www.kaggle.com/jobs), [internships](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries) e.g. 2Sigma, and [prestige](https://www.kaggle.com/c/imagenet-object-detection-challenge). The best competitors get special badges that give their comments, contributions, and teams special status in the community. You can build your reputation by posting helpful notebooks (called **kernels** by Kaggle), like this one, on a Kaggle dataset.\n",
    "\n",
    "There's lots more to Kaggle. If you're interested some examples in getting started with Kaggle competitions, or how it works, see our [Kaggle Workshop slides!](https://github.com/ngundotra/SUSA_Kaggle_Workshop)\n",
    "\n",
    "### Kaggle Competition: Housing Prices\n",
    "\n",
    "In this project, we will be working with the [**Housing Prices**](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/) competition on the Kaggle website. The competition deals with accurately predicting the sales prices of houses in Ames, Iowa. More information on the dataset and competition will follow shortly.\n",
    "\n",
    "### Accessing the `House Prices` Dataset\n",
    "\n",
    "While you can access these datasets online at the [Kaggle webpage for this competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data), we have already downloaded the data for you and placed it in the `crash-course/Kaggle/DATA/house-prices/` directory. \n",
    "\n",
    "## Overview of the CX Capstone Project\n",
    "\n",
    "So where does Kaggle fit in into your CX education? So far, you've learned all sorts of skills, from the bias-variance tradeoff, to EDA, to deep learning. However, you've still only learned them in concept (with the exception of the mini-projects and workbook problems). To get a real handle on how these concepts work, you need to get some proper experience with a real-life dataset and data problem. Fortunately, Kaggle provides these datasets and problems, and so we're going to use a Kaggle competition to help you practice the skills you've learned from the CX workshop series, and hopefully bond a little bit with your fellow CX members as well! \n",
    "\n",
    "## Logistics\n",
    "\n",
    "This project is going to be tough and long, but we will be there with you through the whole thing. Additionally, you won't be working alone - we have used your input to assign you into teams of 3 - 4 members. These will be your team members for the rest of the semester, so get to know each other a little!\n",
    "\n",
    "The project will last the remaining 4 weeks of Career Ex, and one hour per each weekly CX meeting will be devoted to working on it with your team (The other hour will be devoted to guest speakers). However, that only leaves 4 hours of in-class time to work on the project. In order to complete it successfully, it is highly likely that you and your team will have to do some work outside of the weekly CX meetings. To help you stay accountable for yourself, we will be providing you with space and times to meet with SUSA Mentors to help.\n",
    "\n",
    "\n",
    "### Teams \n",
    "\n",
    "You can find the breakdown of the teams with this link:\n",
    "https://docs.google.com/document/d/1twOPXsil1ZyQ1_Rt770ubUbmdQto36OYNNhhBODukPI/edit?usp=sharing\n",
    "\n",
    "I would start by getting the Slack handle or phone number (or other contact info) of all the other members in your group so that you can easily communicate outside of the weekly meetings. It's up to you guys to determine how you are going to meet - however, we **highly encourage** all work on the project to be done **in-person together**.\n",
    "\n",
    "### Mandatory Office Hours\n",
    "\n",
    "Because this is such a large project, you and your team will surely have to work on it outside of meetings. In order to get you guys to seek help from this project, we are making it **mandatory** for you and your group to attend **two (2)** SUSA Office Hours over the next 4 weeks. This will allow questions to be answered outside of the regular meetings and will help promote collaboration with more experienced SUSA members.\n",
    "\n",
    "The schedule of SUSA office hours are below:\n",
    "https://susa.berkeley.edu/calendar#officehours-table\n",
    "\n",
    "We understand that most of you will end up going to Arun or Patrick's office hours, but we highly encourage you to go to other people's office hours as well. There are many qualified SUSA mentors who can help and this could be an opportunity for you to meet them.\n",
    "\n",
    "### SUSA Datathon\n",
    "\n",
    "One other time that we are hoping you will work on your Kaggle projects is during the SUSA Datathon. The time and place of the event is still tentative, but it will likely 4-8PM on Sunday 4/15. At the Datathon, members from many SUSA committees, notably Data Consulting, Research & Publication, and Career Exploration, will all meet up and work on their respective projects together. There will be many other SUSA members there to help you and it should be a great environment for you and your group to work. This is also another great opportunity to meet other experienced SUSA members and get a taste for other committees in the club. More details about this event will be released later.\n",
    "\n",
    "### Git\n",
    "\n",
    "Given that this is a collaborative project, you'll need to work with your team members on the same codebase simutaneously! This is fortunately simple with Git, which you learned in your very first workshop. Visit `py0` if you need a refresher, but we will be going over the steps for collaborative work here too.\n",
    "\n",
    "1. First, decide on which one of you will be hosting the forked Github repository for `crash-course`. Ideally, this would be someone with some GitHub experience and a GitHub account. If no one on your team has a GitHub account, one of you should sign up for one. For our examples, we will call this person's account name `rprincess`.\n",
    "\n",
    "2. Next, have the above person navigate to the [SUSA crash-course repository](https://github.com/SUSA-org/crash-course) and click the `Fork` button. GitHub will make a copy of the crash-course repository in your team member's account. \n",
    "\n",
    "3. Each one of you can download the `rprincess` repository to your local computer with the following command: `git clone https://github.com/rprincess/crash-course.git`. \n",
    "\n",
    "4. Feel free to work within the repository and use `git pull origin` and `git add -A && git commit -am \"My example message here\" && git push` to pull/push your local repository to the `rprincess` online repository.\n",
    "\n",
    "If you have any questions, just Slack Lucas, Noah, Patrick, or Arun and we can help you with your Git workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "# The Data Science Workflow\n",
    "\n",
    "In general, there are a few key steps to begin working with a dataset. \n",
    "\n",
    "First, we need to **understand what the dataset actually is about**, and what we are trying to do with it. Key to this stage is understanding what each row of the dataset represents, as well as what each column indicates. You can read more about this dataset by looking at the dataset itself, or reading the data dictionary in `crash-course/Kaggle/DATA/house-prices/data_description.txt`.\n",
    "\n",
    "Second, before we can even do exploratory data analysis, we need to **clean our dataset**. It is very helpful to identify the size of the dataset, so we know how many samples we have. We need to determine a consistent method of dealing with missing values, such as setting them to a value, removing the feature entirely, interpolating values, etc. Other crucial steps are separating into training and validation, as well as creating elementary data plots.\n",
    "\n",
    "Third, we have **exploratory data analysis (EDA)**. The point of this phase is to inspect & visualize key relationships, trends, outliers, and issues with our data. By conducting EDA, we get a better sense of the underlying structure of our data, and which features are most important. Especially since we have 81 features, we would like to select the features that are most important to our analysis before we begin modeling `SalePrice`. Once we have an idea about which features to use and how they relate to one another, our modeling stage will be more informed and robust. \n",
    "\n",
    "Fourth, we have the **modeling phase**, consisting of **model selection** and **model training**. Here, we select a predictive model to train on our features, and then actually train the model! In this first week, we will be using linear regression as a first-pass. In later weeks of the SUSA CX Kaggle Capstone project, we will be using more advanced models like random forest and neural networks. Depending on the model we are using, it is important to verify the model's assumptions before fully pledging to that model. Additionally, we may use **validation** in this stage to select certain hyperparameters for our model selection.\n",
    "\n",
    "Finally, we have the **model evaluation phase**. Here, we compute a metric for our model's performance, usually by  summing the squared errors of the model's predictions on the test set. This stage allows us to effectively compare various data cleaning and modeling selection decisions, by giving us a single comparable value for performance across our potential models.\n",
    "\n",
    "<a id='i'></a>\n",
    "## I. Understanding our Dataset \n",
    "Our dataset is about houses in Iowa! According to the Kaggle webpage, the competition is as follows:\n",
    "\n",
    "> Ask a home buyer to describe their dream house, and they probably won’t begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition’s dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "\n",
    "More explicitly, our dataset has 81 columns, or features: \n",
    "1. `SalePrice`, our response variable $Y$ that we are trying to predict accurately and precisely \n",
    "2. `Id`, a simple identification variable\n",
    "3. 79 explanatory variables $X_k$ that we can use to predict `SalePrice`. Some of the variables are categorical, and others are continuous quantitative. \n",
    "\n",
    "The goal of the next four weeks to to create a model that trains on (some of) the 79 explanators from the training set to predict `SalePrice` well in the test set. \n",
    "\n",
    "How will we know which explanators to use? We can start with some intuition and research into what each column represents by reading the data dictionary in `crash-course/Kaggle/DATA/house-prices/data_description.txt`. \n",
    "\n",
    "> Please take a moment to read over this dictionary, as you will need to have a keen sense of these features for the weeks ahead. Can you come up with five features you suspect will be important in determining the `SalePrice`?\n",
    "\n",
    "Now that we've talked a bit about this dataset, let's actually take a look at it. The first step is to load in the data! We will store this in a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "5         Lvl    AllPub    ...            0    NaN  MnPrv        Shed     700   \n",
       "6         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "7         Lvl    AllPub    ...            0    NaN    NaN        Shed     350   \n",
       "8         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "9         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "5     10   2009        WD         Normal     143000  \n",
       "6      8   2007        WD         Normal     307000  \n",
       "7     11   2009        WD         Normal     200000  \n",
       "8      4   2008        WD        Abnorml     129900  \n",
       "9      1   2008        WD         Normal     118000  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('DATA/house-prices/train.csv')\n",
    "test = pd.read_csv('DATA/house-prices/test.csv')\n",
    "\n",
    "#Let's see what the training dataframe looks like!\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for Understanding:\n",
    "> 1. How many features (columns) do we have? How many entries (rows)?\n",
    "> 2. What does a single row represent in our dataset?\n",
    "> 3. List 3 issues/questions that you see from the dataset. Some ideas to get started: What does `LotShape` represent? Is it a good thing that we have so many features? How does a large number of features affect our modeling approach?\n",
    "> 4. What are some important things we should do for data cleaning and exploration? Some ideas to get started: are all the values in `LotFrontage` numeric? What about `Alley`? How should we fix missing/`NA` values that appear sporadically in some columns? What about columns that are almost entirely full of `NA` values? Some columns are qualitative strings, whereas others are qualitative numerics - how might this affect our cleaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ii'></a>\n",
    "# II. Data Cleaning\n",
    "First, let's see how big our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size (1460, 81)\n",
      "Test size (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size\",train.shape)\n",
    "print(\"Test size\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we have $1460$ datapoints in the training set, and we would like to predict on $1459$ samples. There are $80$ total features, and one response variable we would like to predict. However, not all these 'features' are actually useful, such as `Id`. Thus we need to understand what the actual variables mean. A huge part in data science is actually understanding the variables. Of course it is possible to throw the data into some machine learning model and have it spit out predictions, but without actually understanding what data you are dealing with and how to feed the data into the model, your model is worthless.\n",
    "\n",
    "Spend a good deal of time reading over the data dictionary. It is located in  \n",
    "`crash-course/Kaggle/DATA/house-prices/data_description.txt`\n",
    "\n",
    "## Questions for Understanding:\n",
    "> 1. There are many categorical variables. What are some possibilities to deal with these variables? (Hint: [one hot encoding](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding))\n",
    "> 2. Are there any categorical variables that we can convert to numerical/quantitative variables as well? How might we do that?\n",
    "> 3. Are there any variables that are just irrelevant and we can ignore?\n",
    "\n",
    "One helpful method is looking at the unique values of a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PConc', 'CBlock', 'BrkTil', 'Wood', 'Slab', 'Stone'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can view the unique values of a given feature\n",
    "train['Foundation'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NA values\n",
    "In almost all datasets, we will have NA values. These can be a pain to deal with, as there are many viable choices of what to do. First, it is good to see what columns have NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "                 ... \n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sum the number of NA's in each column\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that many of the features have a great deal of NAs. However, this is not necessarily the case. The astute reader will notice that some variables like `Alley`, `PoolQC`, and `Fence`, have NA has an actual value. For example for `Pool Quality`, we have these possibilities.\n",
    "\n",
    "PoolQC: Pool quality\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "So having NA values is not the usual not available, it can actually be a legitimate value! We need to parse through the data dictionary to see when NA's are actually significant, and when they actually mean NA.\n",
    "\n",
    "## Questions for Understanding:\n",
    "> 1. Go through the data dictionary and find all features that have NA as legitimate values.\n",
    "> 2. How can we refactor the variables in question 1 appropriately?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that we found with NA's are:\n",
    "`Alley`, `BsmtQual`, `BsmtCond`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2`, `FireplaceQu`, `GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`, `PoolQC`, `Fence`, `Misc Feature`.\n",
    "\n",
    "Alley: NA for no alley access  \n",
    "`BsmtQual`, `BsmtCond`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2`: NA for no basement  \n",
    "`FireplaceQu`: NA for no fireplace  \n",
    "`GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`: NA for no garage  \n",
    "`PoolQC`: NA for no pool  \n",
    "`Fence`: NA for no fence  \n",
    "`Misc Feature`: NA for no other miscellanous features (i.e. elevator, 2nd garage, shed, tennis Court, other) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Functions\n",
    "We provide some functions to help with data cleaning and preprocessing. One is used to create one hot encodings of various features, and the latter is for converting a categorical feature into values.\n",
    "\n",
    "### One Hot Encoding for Unordered Categorical Variables\n",
    "Consider we have a feature `committee` for a data frame of SUSA members. Let's say for sake of simplicity there are four committees, `CX`, `DC`, `RP`, and `WD`. There is no inherent ordering to the features, but each member is only in one committee. Thus we can replace this categorical variable with a single boolean for `committee`. If a member is a part of `CX`, then they will have a $1$ for `DC` and $0$ for all other variables. We have written this function for you in `oneHotFeature`.\n",
    "\n",
    "### Ordered Categorical Variables\n",
    "Consider we have a feature `attendance` for a data frame of SUSA members. Let's say there are $3$ possible values, `Good`, `Ok`, `Poor`. These inherently have an ordering, `Good` is better than `Okay` which is better than `Poor`. We can assign a numerical value to these, such as $0$ for `Poor`, $1$ for `Ok`, and $2$ for `Good`. We have written this function for you in `categoricalToQuantitative`.\n",
    "\n",
    "\n",
    "Please read over the following functions and read the comments carefully! They describe in detail what the functions do, and are **very** crucial to the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning Functions\n",
    "\n",
    "def oneHotFeature(df, features, withNA=True):\n",
    "    \"\"\"\n",
    "    This function is for unordered categorical features \n",
    "\n",
    "    This function takes in input as: \n",
    "    Data frame 'df'\n",
    "    List of features to one hot encode 'features'\n",
    "    Boolean for how to deal with NA's 'withNA'\n",
    "\n",
    "    This function creates a set of output features from a categorical feature\n",
    "    The output features are one hot encodings with names featureName_{value}\n",
    "    Returns a new data frame (does not modify original dataframe) with appended features\n",
    "    Usually the NA values are also considered\n",
    "    Will add a column featureName_none one hot encoding of NA values\n",
    "    If the boolean withNA is false, it will not consider NA values\n",
    "\n",
    "    If a feature is not found, it will ignore that feature and attempt to one hot the other features\n",
    "\n",
    "    Code from Numpy and Pandas SUSA guide\n",
    "    crash-course/Python/Numpy and Pandas.ipynb\n",
    "    \"\"\"\n",
    "    # Copy over data\n",
    "    newDf = df.copy()\n",
    "    for feature in features:\n",
    "        try:\n",
    "            if withNA:\n",
    "                newDf[feature] = newDf[feature].fillna('none')\n",
    "            col_onehot = pd.get_dummies(newDf[feature], prefix=feature) \n",
    "            newDf = newDf.drop(feature, axis=1)\n",
    "            newDf = newDf.join(col_onehot)\n",
    "        except:\n",
    "            print(\"No such feature\", feature, \"found in the dataframe when trying to one-hot encode\")\n",
    "    return newDf\n",
    "\n",
    "\n",
    "\n",
    "def categoricalToQuantitative(df,feature, mapping,assumeInOrder = False):\n",
    "    \"\"\"\n",
    "    This function is for ordered categorical features \n",
    "\n",
    "    This function takes in input as: \n",
    "    Data frame 'df'\n",
    "    A single categorical feature to to be mapped 'feature'\n",
    "    A mapping dictionary 'mapping'\n",
    "\n",
    "    This function creates takes a dataframe and categorical feature, and maps the categorical values\n",
    "    using the dictionary mapping\n",
    "    Returns a new data frame (does not modify original dataframe) with modified values for the feature column\n",
    "    For mappings with NA values, use 'NA' in the dictionary, this function properly deals with them\n",
    "\n",
    "    If the mapping is just from 0 to n-1 for n values\n",
    "    Then set default to True, and mapping is instead a list of ordering from worst to best\n",
    "\n",
    "    If a feature is not found, the function will fail\n",
    "    \"\"\"\n",
    "    newDf = df.copy()\n",
    "    try:\n",
    "        currFeature = df[feature]\n",
    "    except:\n",
    "        print(\"No such feature\", feature, \"found in the dataframe when trying to map\")\n",
    "        return newDf\n",
    "    # Check if input mapping and all unique values for feature are equal\n",
    "    newDf[feature] = newDf[feature].fillna('nan')\n",
    "    if assumeInOrder:\n",
    "        keys = mapping\n",
    "    else:\n",
    "        keys = mapping.keys()\n",
    "    uniqueSet = set(newDf[feature].unique())\n",
    "    keySet = set(keys)\n",
    "    if 'NA' in keySet:\n",
    "        keySet.add('nan')\n",
    "        keySet.remove('NA')\n",
    "    diff = uniqueSet.difference(keySet)\n",
    "    diff2 = keySet.difference(uniqueSet)\n",
    "    if len(diff) != 0:\n",
    "        print(\"Missing value(s)\",diff,\"in mapping\",feature,\"unable to map all values\")\n",
    "        return newDf\n",
    "    if len(diff2) != 0:\n",
    "        print(\"Warning: no such values\",diff2,\"in feature\",feature,\"(they may not appear)\")\n",
    "    # Create mapping\n",
    "    if assumeInOrder:\n",
    "        newMapping ={}\n",
    "        for i in range(len(mapping)):\n",
    "            if mapping[i] == 'NA':\n",
    "                newMapping['nan'] = i \n",
    "            else:\n",
    "                newMapping[mapping[i]] = i\n",
    "    else:    \n",
    "        newMapping = mapping.copy()\n",
    "        if 'NA' in newMapping.keys():\n",
    "            newMapping['nan'] = newMapping['NA']\n",
    "    newDf[feature] = newDf[feature].apply(lambda feat: newMapping[feat] if feat in newMapping.keys() else feat)\n",
    "    return newDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the first function `oneHotFeature` first. Consider the `Heating` feature. There are $5$ possible values, Brick & Tile, Cinder Block, Poured Concrete, Slab, Stone and Wood. There isn't an inherent ordering to these, where one is better than the other. The best way to go about preprocessing the data is through one hot encoding the data. We remove the `Foundation` feature and replace it with $5$ separate boolean features, one for each of the possible values.\n",
    "\n",
    "The dataframe is shown below. Keep in mind that the original dataframe, `train`, is not modified in this function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Foundation_BrkTil</th>\n",
       "      <th>Foundation_CBlock</th>\n",
       "      <th>Foundation_PConc</th>\n",
       "      <th>Foundation_Slab</th>\n",
       "      <th>Foundation_Stone</th>\n",
       "      <th>Foundation_Wood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities       ...        YrSold SaleType SaleCondition  \\\n",
       "0         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "1         Lvl    AllPub       ...          2007       WD        Normal   \n",
       "2         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "3         Lvl    AllPub       ...          2006       WD       Abnorml   \n",
       "4         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "5         Lvl    AllPub       ...          2009       WD        Normal   \n",
       "6         Lvl    AllPub       ...          2007       WD        Normal   \n",
       "7         Lvl    AllPub       ...          2009       WD        Normal   \n",
       "8         Lvl    AllPub       ...          2008       WD       Abnorml   \n",
       "9         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "\n",
       "  SalePrice Foundation_BrkTil Foundation_CBlock Foundation_PConc  \\\n",
       "0    208500                 0                 0                1   \n",
       "1    181500                 0                 1                0   \n",
       "2    223500                 0                 0                1   \n",
       "3    140000                 1                 0                0   \n",
       "4    250000                 0                 0                1   \n",
       "5    143000                 0                 0                0   \n",
       "6    307000                 0                 0                1   \n",
       "7    200000                 0                 1                0   \n",
       "8    129900                 1                 0                0   \n",
       "9    118000                 1                 0                0   \n",
       "\n",
       "   Foundation_Slab  Foundation_Stone  Foundation_Wood  \n",
       "0                0                 0                0  \n",
       "1                0                 0                0  \n",
       "2                0                 0                0  \n",
       "3                0                 0                0  \n",
       "4                0                 0                0  \n",
       "5                0                 0                1  \n",
       "6                0                 0                0  \n",
       "7                0                 0                0  \n",
       "8                0                 0                0  \n",
       "9                0                 0                0  \n",
       "\n",
       "[10 rows x 86 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotFeature(train,['Foundation']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     PConc\n",
       "1    CBlock\n",
       "2     PConc\n",
       "3    BrkTil\n",
       "4     PConc\n",
       "5      Wood\n",
       "6     PConc\n",
       "7    CBlock\n",
       "8    BrkTil\n",
       "9    BrkTil\n",
       "Name: Foundation, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train is not modified\n",
    "train['Foundation'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may try this with the other function `categoricalToQuantitative`, mapping a categorical data where there is an quantitative correspondence. Consider the feature `FireplaceQu`. There are $6$ possible values, `Ex`, `Gd`, `TA`, `Fa`, `Po`, `NA`, corresponding to Excellent, Good, Average, Fair, Poor, and No fireplace. These could be mapped to the values from $0$ to $5$, in order of quality. Thus we can make a dictionary of values, where `Ex` corresponds to $5$, `Gd` corresponds to $4$, ..., `NA` corresponds to zero. This is written out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1     TA\n",
      "2     TA\n",
      "3     Gd\n",
      "4     TA\n",
      "5    NaN\n",
      "6     Gd\n",
      "7     TA\n",
      "8     TA\n",
      "9     TA\n",
      "Name: FireplaceQu, dtype: object\n",
      "0    0\n",
      "1    3\n",
      "2    3\n",
      "3    4\n",
      "4    3\n",
      "5    0\n",
      "6    4\n",
      "7    3\n",
      "8    3\n",
      "9    3\n",
      "Name: FireplaceQu, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "mapping['NA'] = 0\n",
    "mapping['Po'] = 1\n",
    "mapping['Fa'] = 2\n",
    "mapping['TA'] = 3\n",
    "mapping['Gd'] = 4\n",
    "mapping['Ex'] = 5\n",
    "\n",
    "print(train['FireplaceQu'].head(10))\n",
    "print(categoricalToQuantitative(train,'FireplaceQu',mapping)['FireplaceQu'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is a bit annoying to type out the entire dictionary like that if we would like to order from $0$ to $5$. Another variable in `categoricalToQuantitative` is `default`. If `assumeInOrder` is true, then mapping is instead a list of variables rather than a dictionary, and we can just pass in the order of values from worst to best. This maps from $0$ to $n-1$ when there are $n$ possible values. This is more convenient, but it may be better at times to be able to customize how you want to map the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    3\n",
      "2    3\n",
      "3    4\n",
      "4    3\n",
      "5    0\n",
      "6    4\n",
      "7    3\n",
      "8    3\n",
      "9    3\n",
      "Name: FireplaceQu, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mapping = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "#Notice these mappings are the same\n",
    "print(categoricalToQuantitative(train,'FireplaceQu',mapping,assumeInOrder=True)['FireplaceQu'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to remove a feature, use the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-85f8c8cf4ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe.drop(feature, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above two functions to clean the dataset! This may take a while, but doing a good job should take a while. Decide what variables are not worth keeping, decide what categorical features need to be changed, and how they should be changed. Consider how to deal with NA values, and keep all these commands together. We would recommend to save the final cleaned file as a csv so that you may easily reopen and send it, and also keep all the commands together neatly in the code block below.\n",
    "\n",
    "Some recommendations:\n",
    "> 1. Convert all features into quantitative values\n",
    "> 2. While cleaning, keep in mind some features that you feel are very helpful.\n",
    "> 3. Remove features that do not seem important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such feature LotConfig found in the dataframe when trying to one-hot encode\n",
      "Warning: no such values {'NoSewr', 'ELO'} in feature Utilities (they may not appear)\n",
      "Warning: no such values {'Po'} in feature ExterQual (they may not appear)\n",
      "Warning: no such values {'Po'} in feature BsmtQual (they may not appear)\n",
      "Warning: no such values {'Ex'} in feature BsmtCond (they may not appear)\n",
      "Warning: no such values {'Po'} in feature KitchenQual (they may not appear)\n",
      "Warning: no such values {'Sal'} in feature Functional (they may not appear)\n",
      "Warning: no such values {'TA'} in feature PoolQC (they may not appear)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>...</th>\n",
       "      <th>ConditionWd Sdng</th>\n",
       "      <th>ConditionVinylSd</th>\n",
       "      <th>ConditionBrkFace</th>\n",
       "      <th>ConditionWd Shng</th>\n",
       "      <th>ConditionPlywood</th>\n",
       "      <th>ConditionMetalSd</th>\n",
       "      <th>ConditionStucco</th>\n",
       "      <th>ConditionCemntBd</th>\n",
       "      <th>ConditionHdBoard</th>\n",
       "      <th>ConditionCmentBd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1995</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1973</td>\n",
       "      <td>1973</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1931</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>190</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1939</td>\n",
       "      <td>1950</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  LotShape  Utilities  LandSlope  \\\n",
       "0          60         65.0     8450         3          3          2   \n",
       "1          20         80.0     9600         3          3          2   \n",
       "2          60         68.0    11250         2          3          2   \n",
       "3          70         60.0     9550         2          3          2   \n",
       "4          60         84.0    14260         2          3          2   \n",
       "5          50         85.0    14115         2          3          2   \n",
       "6          20         75.0    10084         3          3          2   \n",
       "7          60          NaN    10382         2          3          2   \n",
       "8          50         51.0     6120         3          3          2   \n",
       "9         190         50.0     7420         3          3          2   \n",
       "\n",
       "   OverallQual  OverallCond  YearBuilt  YearRemodAdd        ...         \\\n",
       "0            7            5       2003          2003        ...          \n",
       "1            6            8       1976          1976        ...          \n",
       "2            7            5       2001          2002        ...          \n",
       "3            7            5       1915          1970        ...          \n",
       "4            8            5       2000          2000        ...          \n",
       "5            5            5       1993          1995        ...          \n",
       "6            8            5       2004          2005        ...          \n",
       "7            7            6       1973          1973        ...          \n",
       "8            7            5       1931          1950        ...          \n",
       "9            5            6       1939          1950        ...          \n",
       "\n",
       "   ConditionWd Sdng  ConditionVinylSd  ConditionBrkFace  ConditionWd Shng  \\\n",
       "0                 0                 1                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 1                 0                 0   \n",
       "3                 1                 0                 0                 1   \n",
       "4                 0                 1                 0                 0   \n",
       "5                 0                 1                 0                 0   \n",
       "6                 0                 1                 0                 0   \n",
       "7                 0                 0                 0                 0   \n",
       "8                 0                 0                 1                 1   \n",
       "9                 0                 0                 0                 0   \n",
       "\n",
       "   ConditionPlywood  ConditionMetalSd  ConditionStucco  ConditionCemntBd  \\\n",
       "0                 0                 0                0                 0   \n",
       "1                 0                 1                0                 0   \n",
       "2                 0                 0                0                 0   \n",
       "3                 0                 0                0                 0   \n",
       "4                 0                 0                0                 0   \n",
       "5                 0                 0                0                 0   \n",
       "6                 0                 0                0                 0   \n",
       "7                 0                 0                0                 0   \n",
       "8                 0                 0                0                 0   \n",
       "9                 0                 1                0                 0   \n",
       "\n",
       "   ConditionHdBoard  ConditionCmentBd  \n",
       "0                 0                 0  \n",
       "1                 0                 0  \n",
       "2                 0                 0  \n",
       "3                 0                 0  \n",
       "4                 0                 0  \n",
       "5                 0                 0  \n",
       "6                 0                 0  \n",
       "7                 1                 0  \n",
       "8                 0                 0  \n",
       "9                 0                 0  \n",
       "\n",
       "[10 rows x 150 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA CLEANING\n",
    "# To start off data cleaning\n",
    "clean = train.copy()\n",
    "\n",
    "clean = categoricalToQuantitative(clean,'FireplaceQu',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = oneHotFeature(clean,['Foundation'])\n",
    "\n",
    "# DATA CLEANING SOLUTION\n",
    "\n",
    "# ====================== DO NOT INCLUDE IN FINAL WORKBOOK ========================\n",
    "# ================================================================================\n",
    "unorderedFeatures = ['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood',\n",
    "                     'BldgType','HouseStyle','RoofStyle','RoofMatl','MasVnrType','Heating','Electrical',\n",
    "                     'GarageType','GarageFinish','MiscFeature','SaleType','SaleCondition']\n",
    "\n",
    "unimportantFeatures = ['LotConfig','BsmtUnfSF','3SsnPorch','Id']\n",
    "for feat in unimportantFeatures:\n",
    "    clean = clean.drop(feat, axis=1)\n",
    "\n",
    "clean = oneHotFeature(clean,unorderedFeatures)\n",
    "clean = categoricalToQuantitative(clean,'LotShape',['IR3','IR2','IR1','Reg'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'Utilities',['ELO','NoSeWa','NoSewr','AllPub'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'LandSlope',['Sev','Mod','Gtl'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'ExterQual',['Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'ExterCond',['Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtQual',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtCond',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtExposure',['NA','No','Mn','Av','Gd'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtFinType1',['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtFinType2',['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'HeatingQC',['Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'CentralAir',['N','Y'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'KitchenQual',['Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'Functional',['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'GarageQual',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'GarageCond',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'PavedDrive',['N','P','Y'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'PoolQC',['NA','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'Fence',['NA','MnWw','GdWo','MnPrv','GdPrv'],assumeInOrder=True)\n",
    "\n",
    "# For dealing with\n",
    "# `Condition1, `Condition2`\n",
    "#'Exterior1st','Exterior2nd'\n",
    "\n",
    "def kHotFeature(df, features,prefix, withNA=True):\n",
    "    #Copy over data\n",
    "    newDf = df.copy()\n",
    "    allHot = []\n",
    "    for feature in features:\n",
    "        try:\n",
    "            if withNA:\n",
    "                newDf[feature] = newDf[feature].fillna('none')\n",
    "            col_onehot = pd.get_dummies(newDf[feature]) \n",
    "            allHot.append(col_onehot)\n",
    "            newDf = newDf.drop(feature, axis=1)\n",
    "        except:\n",
    "            print(\"No such feature\", feature, \"found in the dataframe when trying to k-hot encode\")\n",
    "            return newDf\n",
    "          \n",
    "    #Get all unique names\n",
    "    allNames = set()\n",
    "    for hotTable in allHot:\n",
    "        allNames = allNames.union(set(hotTable.columns.values))\n",
    "    for col in allNames:\n",
    "        for hotTable in allHot:\n",
    "            if col in hotTable.keys():\n",
    "                hotTable[col] = hotTable[col].apply(lambda val: bool(val))\n",
    "\n",
    "    for col in allNames:\n",
    "        validCols = pd.DataFrame()\n",
    "        for i in range(len(allHot)):\n",
    "            hotTable = allHot[i]\n",
    "            if col in hotTable.keys():\n",
    "                validCols[str(i)] = hotTable[col]\n",
    "        newDf[prefix+col] = validCols.any(axis=1)*1\n",
    "    return newDf\n",
    "\n",
    "clean = kHotFeature(clean,['Condition1','Condition2'],prefix=\"Condition\")\n",
    "clean = kHotFeature(clean,['Exterior1st','Exterior2nd'],prefix=\"Exterior\")\n",
    "\n",
    "\n",
    "\n",
    "names = list(clean.columns.values)\n",
    "lowOccurenceFeatures = []\n",
    "for name,val in zip(names,clean.sum()):\n",
    "    if val < 15:\n",
    "        lowOccurenceFeatures.append(name)\n",
    "for feat in lowOccurenceFeatures:\n",
    "    clean = clean.drop(feat, axis=1)\n",
    "    \n",
    "# ================================================================================\n",
    "# ================================================================================\n",
    "trainCleaned = clean.copy()\n",
    "trainNames = set(trainCleaned.columns.values)\n",
    "clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No such feature LotConfig found in the dataframe when trying to one-hot encode\n",
      "Warning: no such values {'NoSewr', 'ELO', 'NoSeWa'} in feature Utilities (they may not appear)\n",
      "Warning: no such values {'Po'} in feature ExterQual (they may not appear)\n",
      "Warning: no such values {'Po'} in feature BsmtQual (they may not appear)\n",
      "Warning: no such values {'Ex'} in feature BsmtCond (they may not appear)\n",
      "Warning: no such values {'Po'} in feature KitchenQual (they may not appear)\n",
      "Warning: no such values {'Sal'} in feature Functional (they may not appear)\n",
      "Warning: no such values {'Ex'} in feature GarageQual (they may not appear)\n",
      "Warning: no such values {'Fa', 'TA'} in feature PoolQC (they may not appear)\n",
      "{'SalePrice'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>...</th>\n",
       "      <th>ConditionWd Sdng</th>\n",
       "      <th>ConditionVinylSd</th>\n",
       "      <th>ConditionBrkFace</th>\n",
       "      <th>ConditionWd Shng</th>\n",
       "      <th>ConditionPlywood</th>\n",
       "      <th>ConditionMetalSd</th>\n",
       "      <th>ConditionStucco</th>\n",
       "      <th>ConditionCemntBd</th>\n",
       "      <th>ConditionHdBoard</th>\n",
       "      <th>ConditionCmentBd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7980</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1992</td>\n",
       "      <td>2007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8402</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10176</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  LotShape  Utilities  LandSlope  \\\n",
       "0          20         80.0    11622         3          4          2   \n",
       "1          20         81.0    14267         2          4          2   \n",
       "2          60         74.0    13830         2          4          2   \n",
       "3          60         78.0     9978         2          4          2   \n",
       "4         120         43.0     5005         2          4          2   \n",
       "5          60         75.0    10000         2          4          2   \n",
       "6          20          NaN     7980         2          4          2   \n",
       "7          60         63.0     8402         2          4          2   \n",
       "8          20         85.0    10176         3          4          2   \n",
       "9          20         70.0     8400         3          4          2   \n",
       "\n",
       "   OverallQual  OverallCond  YearBuilt  YearRemodAdd        ...         \\\n",
       "0            5            6       1961          1961        ...          \n",
       "1            6            6       1958          1958        ...          \n",
       "2            5            5       1997          1998        ...          \n",
       "3            6            6       1998          1998        ...          \n",
       "4            8            5       1992          1992        ...          \n",
       "5            6            5       1993          1994        ...          \n",
       "6            6            7       1992          2007        ...          \n",
       "7            6            5       1998          1998        ...          \n",
       "8            7            5       1990          1990        ...          \n",
       "9            4            5       1970          1970        ...          \n",
       "\n",
       "   ConditionWd Sdng  ConditionVinylSd  ConditionBrkFace  ConditionWd Shng  \\\n",
       "0                 0                 1                 0                 0   \n",
       "1                 1                 0                 0                 0   \n",
       "2                 0                 1                 0                 0   \n",
       "3                 0                 1                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "5                 0                 0                 0                 0   \n",
       "6                 0                 0                 0                 0   \n",
       "7                 0                 1                 0                 0   \n",
       "8                 0                 0                 0                 0   \n",
       "9                 0                 0                 0                 0   \n",
       "\n",
       "   ConditionPlywood  ConditionMetalSd  ConditionStucco  ConditionCemntBd  \\\n",
       "0                 0                 0                0                 0   \n",
       "1                 0                 0                0                 0   \n",
       "2                 0                 0                0                 0   \n",
       "3                 0                 0                0                 0   \n",
       "4                 0                 0                0                 0   \n",
       "5                 0                 0                0                 0   \n",
       "6                 0                 0                0                 0   \n",
       "7                 0                 0                0                 0   \n",
       "8                 0                 0                0                 0   \n",
       "9                 1                 0                0                 0   \n",
       "\n",
       "   ConditionHdBoard  ConditionCmentBd  \n",
       "0                 0                 0  \n",
       "1                 0                 0  \n",
       "2                 0                 0  \n",
       "3                 0                 0  \n",
       "4                 1                 0  \n",
       "5                 1                 0  \n",
       "6                 1                 0  \n",
       "7                 0                 0  \n",
       "8                 1                 0  \n",
       "9                 0                 0  \n",
       "\n",
       "[10 rows x 149 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA CLEANING\n",
    "# To start off data cleaning\n",
    "clean = test.copy()\n",
    "\n",
    "clean = categoricalToQuantitative(clean,'FireplaceQu',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = oneHotFeature(clean,['Foundation'])\n",
    "\n",
    "# DATA CLEANING SOLUTION\n",
    "\n",
    "# ====================== DO NOT INCLUDE IN FINAL WORKBOOK ========================\n",
    "# ================================================================================\n",
    "unorderedFeatures = ['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood',\n",
    "                     'BldgType','HouseStyle','RoofStyle','RoofMatl','MasVnrType','Heating','Electrical',\n",
    "                     'GarageType','GarageFinish','MiscFeature','SaleType','SaleCondition']\n",
    "\n",
    "unimportantFeatures = ['LotConfig','BsmtUnfSF','3SsnPorch','Id']\n",
    "for feat in unimportantFeatures:\n",
    "    clean = clean.drop(feat, axis=1)\n",
    "\n",
    "clean = oneHotFeature(clean,unorderedFeatures)\n",
    "clean = categoricalToQuantitative(clean,'LotShape',['IR3','IR2','IR1','Reg'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'Utilities',['NA','ELO','NoSeWa','NoSewr','AllPub'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'LandSlope',['Sev','Mod','Gtl'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'ExterQual',['Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'ExterCond',['Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtQual',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtCond',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtExposure',['NA','No','Mn','Av','Gd'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtFinType1',['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'BsmtFinType2',['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'HeatingQC',['Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'CentralAir',['N','Y'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'KitchenQual',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'Functional',['NA','Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'GarageQual',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'GarageCond',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'PavedDrive',['N','P','Y'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'PoolQC',['NA','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'Fence',['NA','MnWw','GdWo','MnPrv','GdPrv'],assumeInOrder=True)\n",
    "\n",
    "# For dealing with\n",
    "# `Condition1, `Condition2`\n",
    "#'Exterior1st','Exterior2nd'\n",
    "\n",
    "def kHotFeature(df, features,prefix, withNA=True):\n",
    "    #Copy over data\n",
    "    newDf = df.copy()\n",
    "    allHot = []\n",
    "    for feature in features:\n",
    "        try:\n",
    "            if withNA:\n",
    "                newDf[feature] = newDf[feature].fillna('none')\n",
    "            col_onehot = pd.get_dummies(newDf[feature]) \n",
    "            allHot.append(col_onehot)\n",
    "            newDf = newDf.drop(feature, axis=1)\n",
    "        except:\n",
    "            print(\"No such feature\", feature, \"found in the dataframe when trying to k-hot encode\")\n",
    "            return newDf\n",
    "          \n",
    "    #Get all unique names\n",
    "    allNames = set()\n",
    "    for hotTable in allHot:\n",
    "        allNames = allNames.union(set(hotTable.columns.values))\n",
    "    for col in allNames:\n",
    "        for hotTable in allHot:\n",
    "            if col in hotTable.keys():\n",
    "                hotTable[col] = hotTable[col].apply(lambda val: bool(val))\n",
    "\n",
    "    for col in allNames:\n",
    "        validCols = pd.DataFrame()\n",
    "        for i in range(len(allHot)):\n",
    "            hotTable = allHot[i]\n",
    "            if col in hotTable.keys():\n",
    "                validCols[str(i)] = hotTable[col]\n",
    "        newDf[prefix+col] = validCols.any(axis=1)*1\n",
    "    return newDf\n",
    "\n",
    "clean = kHotFeature(clean,['Condition1','Condition2'],prefix=\"Condition\")\n",
    "clean = kHotFeature(clean,['Exterior1st','Exterior2nd'],prefix=\"Condition\")\n",
    "\n",
    "\n",
    "testCleaned = clean.copy()\n",
    "testNames = set(testCleaned.columns.values)\n",
    "for testFeat in testNames.difference(trainNames):\n",
    "    testCleaned = testCleaned.drop(testFeat, axis=1)\n",
    "    \n",
    "print(trainNames.difference(testNames))\n",
    "for trainFeat in trainNames.difference(testNames):\n",
    "    if trainFeat != 'SalePrice':\n",
    "        trainCleaned = trainCleaned.drop(trainFeat, axis=1)\n",
    "    \n",
    "    \n",
    "# ================================================================================\n",
    "# ================================================================================\n",
    "\n",
    "testCleaned.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Conditionnone', 'MSZoning_none', 'SaleType_none'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testNames.difference(trainNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the dataframe as csv, run this line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "trainCleaned.to_csv('DATA/house-prices/train_cleaned.csv')\n",
    "testCleaned.to_csv('DATA/house-prices/test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 150)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainCleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sqrt = lambda x: np.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainIndex = (int)(trainCleaned.shape[0]*0.8)\n",
    "x_train = trainCleaned.loc[:trainIndex, trainCleaned.columns != 'SalePrice'].as_matrix()\n",
    "y_train = trainCleaned.loc[:trainIndex, trainCleaned.columns == 'SalePrice'].as_matrix()\n",
    "y_train = y_train.reshape(y_train.shape[0],)\n",
    "x_val = trainCleaned.loc[trainIndex+1:, trainCleaned.columns != 'SalePrice'].as_matrix()\n",
    "y_val = trainCleaned.loc[trainIndex+1:, trainCleaned.columns == 'SalePrice'].as_matrix()\n",
    "\n",
    "\n",
    "y_val = y_val.reshape(y_val.shape[0],)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215245.0\n",
      "0.0\n",
      "63887.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "x_train=np.nan_to_num(x_train)\n",
    "x_val=np.nan_to_num(x_val)\n",
    "print(np.max(x_train))\n",
    "print(np.min(x_train))\n",
    "print(np.max(x_val))\n",
    "print(np.min(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 5000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_244 (Dense)            (None, 100)               15000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 75)                300       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)   (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 25)                100       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)   (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 28,961\n",
      "Trainable params: 28,441\n",
      "Non-trainable params: 520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Decoder Leaky2\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(x_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(75))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(1024))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(512))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(256))\n",
    "#model.add(Activation('leakyrelu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(25))\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(256, input_shape=(x_train.shape[1],)))\n",
    "# #model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(512))\n",
    "# #model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(),\n",
    "             metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_239 (Dense)            (None, 200)               30000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 512)               102912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 466,769\n",
      "Trainable params: 464,065\n",
      "Non-trainable params: 2,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Fat Leaky\n",
    "batch_size = 50\n",
    "epochs = 4000\n",
    "learning_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_shape=(x_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Dense(1024))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('linear'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(256, input_shape=(x_train.shape[1],)))\n",
    "# #model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(512))\n",
    "# #model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(),\n",
    "             metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1169 samples, validate on 291 samples\n",
      "Epoch 1/5000\n",
      "1169/1169 [==============================] - 7s 6ms/step - loss: 38833104750.5902 - mean_absolute_error: 180635.8584 - val_loss: 39865425504.7698 - val_mean_absolute_error: 182062.2979\n",
      "Epoch 2/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 38832808319.6715 - mean_absolute_error: 180635.3186 - val_loss: 39864759672.5223 - val_mean_absolute_error: 182060.7237\n",
      "Epoch 3/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 38832428378.0051 - mean_absolute_error: 180634.5952 - val_loss: 39863513658.0619 - val_mean_absolute_error: 182057.7364\n",
      "Epoch 4/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 38832014475.2780 - mean_absolute_error: 180633.9191 - val_loss: 39862356453.6082 - val_mean_absolute_error: 182055.0846\n",
      "Epoch 5/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38831549496.9376 - mean_absolute_error: 180633.0070 - val_loss: 39862133784.6323 - val_mean_absolute_error: 182054.6897\n",
      "Epoch 6/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 38831051368.6775 - mean_absolute_error: 180632.0271 - val_loss: 39859974348.0962 - val_mean_absolute_error: 182049.0599\n",
      "Epoch 7/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 38830543282.4773 - mean_absolute_error: 180630.9351 - val_loss: 39859348610.1993 - val_mean_absolute_error: 182047.3318\n",
      "Epoch 8/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 38829974968.6091 - mean_absolute_error: 180629.7343 - val_loss: 39857963866.6117 - val_mean_absolute_error: 182043.7789\n",
      "Epoch 9/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38829297758.6039 - mean_absolute_error: 180628.2521 - val_loss: 39856565131.8763 - val_mean_absolute_error: 182040.0978\n",
      "Epoch 10/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 38828488712.7596 - mean_absolute_error: 180626.7452 - val_loss: 39855985723.8213 - val_mean_absolute_error: 182038.8806\n",
      "Epoch 11/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 38827794707.0522 - mean_absolute_error: 180625.2815 - val_loss: 39855907590.1581 - val_mean_absolute_error: 182039.0664\n",
      "Epoch 12/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 38827140687.2746 - mean_absolute_error: 180623.6783 - val_loss: 39853827047.3677 - val_mean_absolute_error: 182033.5623\n",
      "Epoch 13/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 38826099535.9316 - mean_absolute_error: 180621.8143 - val_loss: 39851696683.9863 - val_mean_absolute_error: 182028.8029\n",
      "Epoch 14/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 38825292701.0163 - mean_absolute_error: 180620.0805 - val_loss: 39853340805.7182 - val_mean_absolute_error: 182034.0006\n",
      "Epoch 15/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 38824186010.1694 - mean_absolute_error: 180617.7383 - val_loss: 39851659827.0241 - val_mean_absolute_error: 182030.0244\n",
      "Epoch 16/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 38823092315.1001 - mean_absolute_error: 180615.3165 - val_loss: 39849336093.0309 - val_mean_absolute_error: 182024.1182\n",
      "Epoch 17/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38822082593.2866 - mean_absolute_error: 180613.3755 - val_loss: 39846596713.5670 - val_mean_absolute_error: 182016.4452\n",
      "Epoch 18/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 38820798761.8272 - mean_absolute_error: 180610.8535 - val_loss: 39844204051.3540 - val_mean_absolute_error: 182011.1991\n",
      "Epoch 19/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 38819561240.7459 - mean_absolute_error: 180607.7926 - val_loss: 39841954657.6495 - val_mean_absolute_error: 182005.2919\n",
      "Epoch 20/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 38818381305.4303 - mean_absolute_error: 180605.2844 - val_loss: 39844219907.5189 - val_mean_absolute_error: 182011.7648\n",
      "Epoch 21/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 38817054989.7964 - mean_absolute_error: 180602.7126 - val_loss: 39843045150.7904 - val_mean_absolute_error: 182010.3877\n",
      "Epoch 22/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 38815801028.6535 - mean_absolute_error: 180600.0366 - val_loss: 39840177767.8076 - val_mean_absolute_error: 182002.2359\n",
      "Epoch 23/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 38814104082.8332 - mean_absolute_error: 180596.5490 - val_loss: 39835267283.1340 - val_mean_absolute_error: 181989.6829\n",
      "Epoch 24/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 38812993187.3670 - mean_absolute_error: 180593.8548 - val_loss: 39833293721.9519 - val_mean_absolute_error: 181985.7050\n",
      "Epoch 25/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 38811691433.7177 - mean_absolute_error: 180590.8445 - val_loss: 39836194872.3024 - val_mean_absolute_error: 181992.9636\n",
      "Epoch 26/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 38810235048.1848 - mean_absolute_error: 180586.8400 - val_loss: 39832910387.0241 - val_mean_absolute_error: 181985.3633\n",
      "Epoch 27/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 38808496441.5945 - mean_absolute_error: 180583.6637 - val_loss: 39829934326.3230 - val_mean_absolute_error: 181977.4034\n",
      "Epoch 28/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 38806849583.3020 - mean_absolute_error: 180579.8491 - val_loss: 39824642512.4948 - val_mean_absolute_error: 181963.5151\n",
      "Epoch 29/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38805105162.0736 - mean_absolute_error: 180577.0934 - val_loss: 39819945610.9966 - val_mean_absolute_error: 181953.3308\n",
      "Epoch 30/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 38802890997.2695 - mean_absolute_error: 180572.0986 - val_loss: 39818538121.2371 - val_mean_absolute_error: 181951.5821\n",
      "Epoch 31/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 38800789903.4388 - mean_absolute_error: 180568.7325 - val_loss: 39818824165.6082 - val_mean_absolute_error: 181951.4868\n",
      "Epoch 32/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 38799542505.0060 - mean_absolute_error: 180565.4480 - val_loss: 39818922364.0412 - val_mean_absolute_error: 181951.5420\n",
      "Epoch 33/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 38798017731.3396 - mean_absolute_error: 180561.2225 - val_loss: 39807945731.5189 - val_mean_absolute_error: 181924.4527\n",
      "Epoch 34/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 38796017432.7459 - mean_absolute_error: 180557.9432 - val_loss: 39807051818.2268 - val_mean_absolute_error: 181923.0142\n",
      "Epoch 35/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 38794077447.6647 - mean_absolute_error: 180552.6739 - val_loss: 39812418380.5361 - val_mean_absolute_error: 181937.5249\n",
      "Epoch 36/5000\n",
      "1169/1169 [==============================] - 0s 411us/step - loss: 38791102288.8075 - mean_absolute_error: 180547.4945 - val_loss: 39810070879.8900 - val_mean_absolute_error: 181935.0112\n",
      "Epoch 37/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 38789431465.9367 - mean_absolute_error: 180543.2934 - val_loss: 39811685217.6495 - val_mean_absolute_error: 181937.2796\n",
      "Epoch 38/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 38786860420.0513 - mean_absolute_error: 180539.1006 - val_loss: 39805239035.6014 - val_mean_absolute_error: 181926.4743\n",
      "Epoch 39/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 38784766351.4388 - mean_absolute_error: 180533.4538 - val_loss: 39802672877.5258 - val_mean_absolute_error: 181914.8749\n",
      "Epoch 40/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38782472118.4192 - mean_absolute_error: 180528.7333 - val_loss: 39796575129.9519 - val_mean_absolute_error: 181897.9210\n",
      "Epoch 41/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 38780990172.3045 - mean_absolute_error: 180524.9175 - val_loss: 39785924699.4914 - val_mean_absolute_error: 181871.5546\n",
      "Epoch 42/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 38778468809.2524 - mean_absolute_error: 180519.3933 - val_loss: 39796596489.6770 - val_mean_absolute_error: 181900.5322\n",
      "Epoch 43/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 38776300280.3353 - mean_absolute_error: 180514.6726 - val_loss: 39787863648.7698 - val_mean_absolute_error: 181876.8260\n",
      "Epoch 44/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 38774553544.8144 - mean_absolute_error: 180510.2906 - val_loss: 39793838727.4777 - val_mean_absolute_error: 181892.2181\n",
      "Epoch 45/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 38770079297.2592 - mean_absolute_error: 180502.5347 - val_loss: 39787549861.3883 - val_mean_absolute_error: 181879.0940\n",
      "Epoch 46/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 38769432928.1369 - mean_absolute_error: 180498.7956 - val_loss: 39795307551.6701 - val_mean_absolute_error: 181903.3892\n",
      "Epoch 47/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 38766594764.5372 - mean_absolute_error: 180492.6297 - val_loss: 39791441188.0687 - val_mean_absolute_error: 181891.3424\n",
      "Epoch 48/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 38764734381.6595 - mean_absolute_error: 180488.7305 - val_loss: 39780927234.6392 - val_mean_absolute_error: 181862.2013\n",
      "Epoch 49/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 38761916465.0539 - mean_absolute_error: 180483.8974 - val_loss: 39785030370.9691 - val_mean_absolute_error: 181876.1426\n",
      "Epoch 50/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 38758988820.1471 - mean_absolute_error: 180478.0839 - val_loss: 39768353499.9313 - val_mean_absolute_error: 181836.7315\n",
      "Epoch 51/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 38755298890.0188 - mean_absolute_error: 180472.1478 - val_loss: 39760210525.2509 - val_mean_absolute_error: 181818.5584\n",
      "Epoch 52/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 38754255214.1523 - mean_absolute_error: 180466.7491 - val_loss: 39765911819.4364 - val_mean_absolute_error: 181832.5587\n",
      "Epoch 53/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 38751263058.1215 - mean_absolute_error: 180461.3578 - val_loss: 39761074457.5120 - val_mean_absolute_error: 181823.7025\n",
      "Epoch 54/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38748282184.4859 - mean_absolute_error: 180453.1664 - val_loss: 39766596618.5567 - val_mean_absolute_error: 181840.2818\n",
      "Epoch 55/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 38746845436.2772 - mean_absolute_error: 180450.9409 - val_loss: 39748364858.0619 - val_mean_absolute_error: 181794.8069\n",
      "Epoch 56/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 38740653503.6168 - mean_absolute_error: 180439.5107 - val_loss: 39760399750.5979 - val_mean_absolute_error: 181824.1454\n",
      "Epoch 57/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 38740525924.9547 - mean_absolute_error: 180437.6277 - val_loss: 39756481159.4777 - val_mean_absolute_error: 181809.2554\n",
      "Epoch 58/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 38736969924.2156 - mean_absolute_error: 180428.8893 - val_loss: 39754638811.0515 - val_mean_absolute_error: 181802.6624\n",
      "Epoch 59/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 38736008224.4106 - mean_absolute_error: 180425.9088 - val_loss: 39745243093.7732 - val_mean_absolute_error: 181783.2973\n",
      "Epoch 60/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 38729958204.6604 - mean_absolute_error: 180417.4541 - val_loss: 39731321113.5120 - val_mean_absolute_error: 181744.4277\n",
      "Epoch 61/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 38729044066.1078 - mean_absolute_error: 180415.8149 - val_loss: 39735309231.0653 - val_mean_absolute_error: 181758.6851\n",
      "Epoch 62/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 38723572454.8161 - mean_absolute_error: 180400.7440 - val_loss: 39732892098.4192 - val_mean_absolute_error: 181748.9787\n",
      "Epoch 63/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 38722581958.6245 - mean_absolute_error: 180399.2601 - val_loss: 39740652800.8797 - val_mean_absolute_error: 181780.2874\n",
      "Epoch 64/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 38721789524.5304 - mean_absolute_error: 180395.0676 - val_loss: 39742314721.2096 - val_mean_absolute_error: 181789.0248\n",
      "Epoch 65/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 38716828609.8067 - mean_absolute_error: 180384.5822 - val_loss: 39736818684.4811 - val_mean_absolute_error: 181768.9369\n",
      "Epoch 66/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 38713778848.7391 - mean_absolute_error: 180376.9672 - val_loss: 39733571837.3608 - val_mean_absolute_error: 181761.1759\n",
      "Epoch 67/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 38708970880.5475 - mean_absolute_error: 180369.6224 - val_loss: 39727663835.9313 - val_mean_absolute_error: 181744.6900\n",
      "Epoch 68/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 38706657989.5295 - mean_absolute_error: 180363.4692 - val_loss: 39720849985.0997 - val_mean_absolute_error: 181727.7985\n",
      "Epoch 69/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 38701760499.7365 - mean_absolute_error: 180355.1819 - val_loss: 39730323174.4880 - val_mean_absolute_error: 181762.1450\n",
      "Epoch 70/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 38699717137.0813 - mean_absolute_error: 180353.3817 - val_loss: 39732031002.3918 - val_mean_absolute_error: 181753.7708\n",
      "Epoch 71/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 38697657774.0975 - mean_absolute_error: 180339.7630 - val_loss: 39706655733.4433 - val_mean_absolute_error: 181694.3274\n",
      "Epoch 72/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 38698144048.8349 - mean_absolute_error: 180342.0399 - val_loss: 39717264296.0275 - val_mean_absolute_error: 181715.2578\n",
      "Epoch 73/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 38690644857.9778 - mean_absolute_error: 180326.6034 - val_loss: 39689124980.1237 - val_mean_absolute_error: 181648.7745\n",
      "Epoch 74/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 38685149332.9136 - mean_absolute_error: 180319.1798 - val_loss: 39716040204.3162 - val_mean_absolute_error: 181726.6903\n",
      "Epoch 75/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 38683849091.1754 - mean_absolute_error: 180316.5655 - val_loss: 39686801253.1684 - val_mean_absolute_error: 181656.7699\n",
      "Epoch 76/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 38679014036.4756 - mean_absolute_error: 180307.5340 - val_loss: 39691207690.5567 - val_mean_absolute_error: 181666.7208\n",
      "Epoch 77/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 38675626525.3447 - mean_absolute_error: 180297.0187 - val_loss: 39663992332.3162 - val_mean_absolute_error: 181588.0453\n",
      "Epoch 78/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 38676711345.1634 - mean_absolute_error: 180296.1754 - val_loss: 39680861250.8591 - val_mean_absolute_error: 181631.3472\n",
      "Epoch 79/5000\n",
      "1169/1169 [==============================] - 0s 378us/step - loss: 38669337872.4243 - mean_absolute_error: 180281.5218 - val_loss: 39675029884.0412 - val_mean_absolute_error: 181624.0736\n",
      "Epoch 80/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 38667341929.1155 - mean_absolute_error: 180275.9260 - val_loss: 39684881115.9313 - val_mean_absolute_error: 181654.7104\n",
      "Epoch 81/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 38661573592.5817 - mean_absolute_error: 180266.1449 - val_loss: 39684803256.7423 - val_mean_absolute_error: 181646.4880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/5000\n",
      "1169/1169 [==============================] - 0s 378us/step - loss: 38658012350.0838 - mean_absolute_error: 180253.4131 - val_loss: 39681644086.5430 - val_mean_absolute_error: 181654.4363\n",
      "Epoch 83/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 38656099672.2532 - mean_absolute_error: 180254.2537 - val_loss: 39685659348.8935 - val_mean_absolute_error: 181661.2267\n",
      "Epoch 84/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 38651840566.3097 - mean_absolute_error: 180247.1476 - val_loss: 39662428751.1753 - val_mean_absolute_error: 181598.0554\n",
      "Epoch 85/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 38649068895.2609 - mean_absolute_error: 180238.5435 - val_loss: 39664332032.8797 - val_mean_absolute_error: 181602.1729\n",
      "Epoch 86/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 38642874047.3978 - mean_absolute_error: 180227.7686 - val_loss: 39646270741.9931 - val_mean_absolute_error: 181551.9675\n",
      "Epoch 87/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 38644760425.3345 - mean_absolute_error: 180224.0304 - val_loss: 39662592710.8179 - val_mean_absolute_error: 181584.3878\n",
      "Epoch 88/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 38638609326.5355 - mean_absolute_error: 180211.2924 - val_loss: 39668717279.4502 - val_mean_absolute_error: 181608.9332\n",
      "Epoch 89/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 38631532489.6903 - mean_absolute_error: 180204.0618 - val_loss: 39643016237.7457 - val_mean_absolute_error: 181561.5593\n",
      "Epoch 90/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 38628215313.0813 - mean_absolute_error: 180190.4696 - val_loss: 39660690991.5052 - val_mean_absolute_error: 181597.5268\n",
      "Epoch 91/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 38626667632.9991 - mean_absolute_error: 180187.2880 - val_loss: 39659389096.9072 - val_mean_absolute_error: 181584.6339\n",
      "Epoch 92/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 38622871089.4919 - mean_absolute_error: 180178.7033 - val_loss: 39644991628.7560 - val_mean_absolute_error: 181545.7307\n",
      "Epoch 93/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 38618326064.1779 - mean_absolute_error: 180169.0709 - val_loss: 39625753258.6667 - val_mean_absolute_error: 181505.7195\n",
      "Epoch 94/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 38609569727.1788 - mean_absolute_error: 180151.4886 - val_loss: 39647019205.0584 - val_mean_absolute_error: 181555.4076\n",
      "Epoch 95/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 38610218363.2917 - mean_absolute_error: 180155.8434 - val_loss: 39645005486.1856 - val_mean_absolute_error: 181549.1108\n",
      "Epoch 96/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 38604834166.0359 - mean_absolute_error: 180138.2755 - val_loss: 39600703206.4880 - val_mean_absolute_error: 181454.0144\n",
      "Epoch 97/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 38604335824.0411 - mean_absolute_error: 180137.6606 - val_loss: 39630949400.6323 - val_mean_absolute_error: 181528.2794\n",
      "Epoch 98/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 38595423327.4799 - mean_absolute_error: 180121.8157 - val_loss: 39583980744.5773 - val_mean_absolute_error: 181404.0248\n",
      "Epoch 99/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 38592963400.9239 - mean_absolute_error: 180116.0170 - val_loss: 39644164623.8351 - val_mean_absolute_error: 181553.7934\n",
      "Epoch 100/5000\n",
      "1169/1169 [==============================] - 0s 378us/step - loss: 38592947519.7263 - mean_absolute_error: 180111.0134 - val_loss: 39603647977.1272 - val_mean_absolute_error: 181458.9461\n",
      "Epoch 101/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 38581812231.8837 - mean_absolute_error: 180091.8709 - val_loss: 39622785418.1168 - val_mean_absolute_error: 181506.7705\n",
      "Epoch 102/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38582924795.1822 - mean_absolute_error: 180094.6632 - val_loss: 39609070898.1443 - val_mean_absolute_error: 181459.7149\n",
      "Epoch 103/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 38575958627.4217 - mean_absolute_error: 180079.4785 - val_loss: 39601980553.2371 - val_mean_absolute_error: 181441.2216\n",
      "Epoch 104/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 38570787446.6929 - mean_absolute_error: 180073.5765 - val_loss: 39579778023.3677 - val_mean_absolute_error: 181400.3303\n",
      "Epoch 105/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 38568858721.2318 - mean_absolute_error: 180067.2511 - val_loss: 39561059486.3505 - val_mean_absolute_error: 181372.6670\n",
      "Epoch 106/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 38565749829.2010 - mean_absolute_error: 180051.5166 - val_loss: 39595562416.8247 - val_mean_absolute_error: 181468.3661\n",
      "Epoch 107/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 38553772326.3234 - mean_absolute_error: 180038.7407 - val_loss: 39583459785.4570 - val_mean_absolute_error: 181427.9287\n",
      "Epoch 108/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 38548963454.1386 - mean_absolute_error: 180033.2440 - val_loss: 39575270438.7079 - val_mean_absolute_error: 181391.6909\n",
      "Epoch 109/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38551778525.6185 - mean_absolute_error: 180024.1099 - val_loss: 39593429977.2921 - val_mean_absolute_error: 181436.5953\n",
      "Epoch 110/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 38546766680.6912 - mean_absolute_error: 180008.6523 - val_loss: 39567754679.8625 - val_mean_absolute_error: 181377.4644\n",
      "Epoch 111/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 38542751770.2789 - mean_absolute_error: 180012.5626 - val_loss: 39557894348.0962 - val_mean_absolute_error: 181357.8849\n",
      "Epoch 112/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 38535989212.9615 - mean_absolute_error: 179995.6600 - val_loss: 39566297798.8179 - val_mean_absolute_error: 181368.0484\n",
      "Epoch 113/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38532885560.9376 - mean_absolute_error: 179989.3050 - val_loss: 39548793212.0412 - val_mean_absolute_error: 181327.1515\n",
      "Epoch 114/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 38526965632.1095 - mean_absolute_error: 179967.2372 - val_loss: 39528853996.6460 - val_mean_absolute_error: 181280.9387\n",
      "Epoch 115/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 38520346948.1061 - mean_absolute_error: 179955.9975 - val_loss: 39571246576.1649 - val_mean_absolute_error: 181381.7198\n",
      "Epoch 116/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 38518424659.2164 - mean_absolute_error: 179957.1369 - val_loss: 39516975716.2887 - val_mean_absolute_error: 181258.3301\n",
      "Epoch 117/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38509379626.0462 - mean_absolute_error: 179936.3505 - val_loss: 39509569754.1718 - val_mean_absolute_error: 181242.8722\n",
      "Epoch 118/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 38510283678.7682 - mean_absolute_error: 179938.2685 - val_loss: 39527193174.2131 - val_mean_absolute_error: 181275.6771\n",
      "Epoch 119/5000\n",
      "1169/1169 [==============================] - 0s 399us/step - loss: 38500988791.3499 - mean_absolute_error: 179912.3745 - val_loss: 39524281671.2577 - val_mean_absolute_error: 181276.4305\n",
      "Epoch 120/5000\n",
      "1169/1169 [==============================] - 1s 433us/step - loss: 38494002390.6108 - mean_absolute_error: 179901.1678 - val_loss: 39481918995.3540 - val_mean_absolute_error: 181165.7234\n",
      "Epoch 121/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 38490663801.9778 - mean_absolute_error: 179891.9142 - val_loss: 39491864012.9759 - val_mean_absolute_error: 181201.4850\n",
      "Epoch 122/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 38483713434.8263 - mean_absolute_error: 179884.4998 - val_loss: 39511628951.3127 - val_mean_absolute_error: 181255.9162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 38476908892.6330 - mean_absolute_error: 179869.6053 - val_loss: 39472934264.5223 - val_mean_absolute_error: 181164.0437\n",
      "Epoch 124/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 38475157083.5381 - mean_absolute_error: 179868.1913 - val_loss: 39477563589.0584 - val_mean_absolute_error: 181169.2103\n",
      "Epoch 125/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 38474687812.9820 - mean_absolute_error: 179854.8278 - val_loss: 39487946097.4845 - val_mean_absolute_error: 181195.5021\n",
      "Epoch 126/5000\n",
      "1169/1169 [==============================] - 0s 383us/step - loss: 38462528293.8854 - mean_absolute_error: 179842.9345 - val_loss: 39451202162.3643 - val_mean_absolute_error: 181129.6974\n",
      "Epoch 127/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 38461536685.2216 - mean_absolute_error: 179837.4816 - val_loss: 39487783270.9278 - val_mean_absolute_error: 181179.9873\n",
      "Epoch 128/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 38455637478.1591 - mean_absolute_error: 179816.4162 - val_loss: 39481126165.9931 - val_mean_absolute_error: 181154.7501\n",
      "Epoch 129/5000\n",
      "1169/1169 [==============================] - 0s 314us/step - loss: 38444858975.0419 - mean_absolute_error: 179810.1762 - val_loss: 39437730601.3471 - val_mean_absolute_error: 181062.9485\n",
      "Epoch 130/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 38446198503.6920 - mean_absolute_error: 179804.8913 - val_loss: 39465172365.6357 - val_mean_absolute_error: 181135.8101\n",
      "Epoch 131/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 38447409101.1942 - mean_absolute_error: 179797.2798 - val_loss: 39466055884.0962 - val_mean_absolute_error: 181158.8082\n",
      "Epoch 132/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 38439172980.7220 - mean_absolute_error: 179780.6386 - val_loss: 39469598565.1684 - val_mean_absolute_error: 181152.3079\n",
      "Epoch 133/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 38434552026.9906 - mean_absolute_error: 179766.6808 - val_loss: 39433294865.5945 - val_mean_absolute_error: 181032.9072\n",
      "Epoch 134/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 38426944469.0778 - mean_absolute_error: 179752.3535 - val_loss: 39428152548.7285 - val_mean_absolute_error: 181039.5637\n",
      "Epoch 135/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 38424788970.9769 - mean_absolute_error: 179749.2513 - val_loss: 39413333037.7457 - val_mean_absolute_error: 181011.2632\n",
      "Epoch 136/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38422083824.0137 - mean_absolute_error: 179740.9328 - val_loss: 39459400095.2302 - val_mean_absolute_error: 181145.3206\n",
      "Epoch 137/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 38416305769.5535 - mean_absolute_error: 179733.8587 - val_loss: 39399183222.7629 - val_mean_absolute_error: 180973.0751\n",
      "Epoch 138/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 38400353755.6476 - mean_absolute_error: 179716.4824 - val_loss: 39458868642.7491 - val_mean_absolute_error: 181127.1478\n",
      "Epoch 139/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 38399656111.1925 - mean_absolute_error: 179698.3602 - val_loss: 39455037594.8316 - val_mean_absolute_error: 181117.1106\n",
      "Epoch 140/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 38397212470.5287 - mean_absolute_error: 179684.8244 - val_loss: 39393577276.7010 - val_mean_absolute_error: 180968.3364\n",
      "Epoch 141/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 38384066849.0676 - mean_absolute_error: 179670.0032 - val_loss: 39444881745.8144 - val_mean_absolute_error: 181099.5002\n",
      "Epoch 142/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 38380261383.0077 - mean_absolute_error: 179656.8972 - val_loss: 39413965025.2096 - val_mean_absolute_error: 181027.4113\n",
      "Epoch 143/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 38378049770.7579 - mean_absolute_error: 179648.9880 - val_loss: 39460844139.3265 - val_mean_absolute_error: 181137.2054\n",
      "Epoch 144/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 38380511454.4944 - mean_absolute_error: 179646.2894 - val_loss: 39441152654.5155 - val_mean_absolute_error: 181097.6978\n",
      "Epoch 145/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 38363568767.4525 - mean_absolute_error: 179617.4341 - val_loss: 39468671841.6495 - val_mean_absolute_error: 181162.1513\n",
      "Epoch 146/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 38366996495.7673 - mean_absolute_error: 179611.8266 - val_loss: 39410999450.8316 - val_mean_absolute_error: 181040.3336\n",
      "Epoch 147/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 38350508715.2506 - mean_absolute_error: 179585.4095 - val_loss: 39412240341.7732 - val_mean_absolute_error: 181019.6514\n",
      "Epoch 148/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 38355732697.2387 - mean_absolute_error: 179586.6052 - val_loss: 39401457797.7182 - val_mean_absolute_error: 180995.1450\n",
      "Epoch 149/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 38337347421.0710 - mean_absolute_error: 179569.1095 - val_loss: 39371088632.0825 - val_mean_absolute_error: 180907.9986\n",
      "Epoch 150/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 38349239939.8323 - mean_absolute_error: 179573.3252 - val_loss: 39314134976.6598 - val_mean_absolute_error: 180800.5059\n",
      "Epoch 151/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 38331207939.2849 - mean_absolute_error: 179547.8565 - val_loss: 39315165711.8351 - val_mean_absolute_error: 180761.6765\n",
      "Epoch 152/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 38330343066.6074 - mean_absolute_error: 179539.6821 - val_loss: 39317740223.7801 - val_mean_absolute_error: 180779.7802\n",
      "Epoch 153/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38326515719.0077 - mean_absolute_error: 179537.6035 - val_loss: 39315830952.9072 - val_mean_absolute_error: 180787.2143\n",
      "Epoch 154/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 38320572727.8426 - mean_absolute_error: 179517.0885 - val_loss: 39336100614.1581 - val_mean_absolute_error: 180846.6580\n",
      "Epoch 155/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 38315161249.6151 - mean_absolute_error: 179503.5838 - val_loss: 39342476713.7869 - val_mean_absolute_error: 180868.6781\n",
      "Epoch 156/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 38305024467.7639 - mean_absolute_error: 179490.7800 - val_loss: 39351179109.1684 - val_mean_absolute_error: 180880.1042\n",
      "Epoch 157/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 38296953478.4602 - mean_absolute_error: 179469.7947 - val_loss: 39303271899.0515 - val_mean_absolute_error: 180757.2833\n",
      "Epoch 158/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 38289046357.1873 - mean_absolute_error: 179454.7885 - val_loss: 39286119751.2577 - val_mean_absolute_error: 180727.3518\n",
      "Epoch 159/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38286987136.1095 - mean_absolute_error: 179455.2548 - val_loss: 39357771374.8454 - val_mean_absolute_error: 180888.2513\n",
      "Epoch 160/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 38278722895.4936 - mean_absolute_error: 179432.7663 - val_loss: 39311722270.7904 - val_mean_absolute_error: 180800.1030\n",
      "Epoch 161/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 38271712768.4380 - mean_absolute_error: 179417.0094 - val_loss: 39259332903.5876 - val_mean_absolute_error: 180647.2163\n",
      "Epoch 162/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 38264195665.9025 - mean_absolute_error: 179404.6223 - val_loss: 39232646992.0550 - val_mean_absolute_error: 180586.7593\n",
      "Epoch 163/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 38262820778.1557 - mean_absolute_error: 179401.5336 - val_loss: 39254353589.2234 - val_mean_absolute_error: 180643.4355\n",
      "Epoch 164/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38243457092.3251 - mean_absolute_error: 179372.8772 - val_loss: 39274547291.4914 - val_mean_absolute_error: 180698.1787\n",
      "Epoch 165/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 38253718739.1069 - mean_absolute_error: 179372.2612 - val_loss: 39272922629.2784 - val_mean_absolute_error: 180680.0569\n",
      "Epoch 166/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 38234977188.0240 - mean_absolute_error: 179346.3217 - val_loss: 39270772004.0687 - val_mean_absolute_error: 180656.6385\n",
      "Epoch 167/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 38237033408.0547 - mean_absolute_error: 179345.4261 - val_loss: 39310865932.3162 - val_mean_absolute_error: 180753.1877\n",
      "Epoch 168/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 38231848537.7861 - mean_absolute_error: 179317.5102 - val_loss: 39258281083.1615 - val_mean_absolute_error: 180654.3110\n",
      "Epoch 169/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38215992564.3935 - mean_absolute_error: 179305.9505 - val_loss: 39256810823.2577 - val_mean_absolute_error: 180663.9331\n",
      "Epoch 170/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38227943084.1266 - mean_absolute_error: 179318.3580 - val_loss: 39291146795.9863 - val_mean_absolute_error: 180763.5905\n",
      "Epoch 171/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 38220878191.9042 - mean_absolute_error: 179299.6154 - val_loss: 39208406849.9794 - val_mean_absolute_error: 180583.1692\n",
      "Epoch 172/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 38208033990.8435 - mean_absolute_error: 179285.5104 - val_loss: 39183650435.9588 - val_mean_absolute_error: 180506.1216\n",
      "Epoch 173/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 38203273710.0428 - mean_absolute_error: 179263.9766 - val_loss: 39275670397.8007 - val_mean_absolute_error: 180695.5872\n",
      "Epoch 174/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 38202585406.8503 - mean_absolute_error: 179251.2699 - val_loss: 39234442926.1856 - val_mean_absolute_error: 180599.9912\n",
      "Epoch 175/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 38194471633.7930 - mean_absolute_error: 179234.8047 - val_loss: 39195919469.0859 - val_mean_absolute_error: 180500.8345\n",
      "Epoch 176/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 38182089376.7391 - mean_absolute_error: 179230.0163 - val_loss: 39232126208.8797 - val_mean_absolute_error: 180577.6464\n",
      "Epoch 177/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 38168056491.2506 - mean_absolute_error: 179203.7335 - val_loss: 39172235995.9313 - val_mean_absolute_error: 180460.4543\n",
      "Epoch 178/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 38165604399.3020 - mean_absolute_error: 179178.4313 - val_loss: 39196368037.3883 - val_mean_absolute_error: 180501.6586\n",
      "Epoch 179/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38172001902.8092 - mean_absolute_error: 179201.0053 - val_loss: 39248156524.2062 - val_mean_absolute_error: 180626.7718\n",
      "Epoch 180/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 38156853885.7006 - mean_absolute_error: 179154.6557 - val_loss: 39191737157.4983 - val_mean_absolute_error: 180499.8847\n",
      "Epoch 181/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 38152668050.5047 - mean_absolute_error: 179164.1488 - val_loss: 39232459842.8591 - val_mean_absolute_error: 180613.2678\n",
      "Epoch 182/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 38132080188.0034 - mean_absolute_error: 179132.0617 - val_loss: 39203360577.9794 - val_mean_absolute_error: 180538.8622\n",
      "Epoch 183/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 38144478990.2344 - mean_absolute_error: 179116.8593 - val_loss: 39178774450.5842 - val_mean_absolute_error: 180447.5182\n",
      "Epoch 184/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 38136427326.4123 - mean_absolute_error: 179128.7682 - val_loss: 39195327920.8247 - val_mean_absolute_error: 180494.1379\n",
      "Epoch 185/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 38123208402.6690 - mean_absolute_error: 179095.5970 - val_loss: 39191066828.0962 - val_mean_absolute_error: 180477.5514\n",
      "Epoch 186/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 38121430582.7476 - mean_absolute_error: 179078.8274 - val_loss: 39101691925.1134 - val_mean_absolute_error: 180254.1462\n",
      "Epoch 187/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 38120306773.8443 - mean_absolute_error: 179057.7270 - val_loss: 39181653980.8110 - val_mean_absolute_error: 180423.6883\n",
      "Epoch 188/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38111154969.6219 - mean_absolute_error: 179057.1409 - val_loss: 39117886819.4089 - val_mean_absolute_error: 180300.7956\n",
      "Epoch 189/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 38098640181.2147 - mean_absolute_error: 179033.0538 - val_loss: 39170914177.3196 - val_mean_absolute_error: 180423.8408\n",
      "Epoch 190/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 38078559718.1591 - mean_absolute_error: 178996.1475 - val_loss: 39134047066.6117 - val_mean_absolute_error: 180345.1226\n",
      "Epoch 191/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 38078195662.9461 - mean_absolute_error: 179008.1206 - val_loss: 39100430462.6804 - val_mean_absolute_error: 180276.2854\n",
      "Epoch 192/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 38071987761.4919 - mean_absolute_error: 178977.2612 - val_loss: 39070671361.7595 - val_mean_absolute_error: 180214.1738\n",
      "Epoch 193/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 38083928582.5697 - mean_absolute_error: 178990.6932 - val_loss: 39065341381.9381 - val_mean_absolute_error: 180158.1734\n",
      "Epoch 194/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 38042269405.1805 - mean_absolute_error: 178927.6462 - val_loss: 39022008432.6048 - val_mean_absolute_error: 180069.0589\n",
      "Epoch 195/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 38067980563.0522 - mean_absolute_error: 178955.8176 - val_loss: 39024012059.2715 - val_mean_absolute_error: 180085.1871\n",
      "Epoch 196/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 38045526583.6236 - mean_absolute_error: 178917.3881 - val_loss: 39005435439.5052 - val_mean_absolute_error: 180064.9367\n",
      "Epoch 197/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 38062271289.1565 - mean_absolute_error: 178918.5480 - val_loss: 39140787541.3333 - val_mean_absolute_error: 180362.3704\n",
      "Epoch 198/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 38032805166.2070 - mean_absolute_error: 178873.3909 - val_loss: 39063699737.5120 - val_mean_absolute_error: 180211.2431\n",
      "Epoch 199/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 38015580438.5560 - mean_absolute_error: 178876.8321 - val_loss: 39062302339.9588 - val_mean_absolute_error: 180207.4566\n",
      "Epoch 200/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 38030954828.8657 - mean_absolute_error: 178885.9846 - val_loss: 39068327914.8866 - val_mean_absolute_error: 180187.6521\n",
      "Epoch 201/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38003813213.9470 - mean_absolute_error: 178841.9675 - val_loss: 39063739353.2921 - val_mean_absolute_error: 180223.2594\n",
      "Epoch 202/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 37988115882.5937 - mean_absolute_error: 178814.5911 - val_loss: 38989853615.0653 - val_mean_absolute_error: 180017.3435\n",
      "Epoch 203/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 38014719469.1668 - mean_absolute_error: 178826.4377 - val_loss: 38951625077.0034 - val_mean_absolute_error: 179927.0750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 37997872754.3131 - mean_absolute_error: 178824.2437 - val_loss: 38998618660.9485 - val_mean_absolute_error: 180021.9912\n",
      "Epoch 205/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 37985207783.9110 - mean_absolute_error: 178785.2789 - val_loss: 39115247411.9038 - val_mean_absolute_error: 180349.5385\n",
      "Epoch 206/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 37962099737.4029 - mean_absolute_error: 178745.7272 - val_loss: 39088703072.7698 - val_mean_absolute_error: 180293.0345\n",
      "Epoch 207/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 37964332067.9145 - mean_absolute_error: 178757.8532 - val_loss: 39106334079.5601 - val_mean_absolute_error: 180305.2924\n",
      "Epoch 208/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 37975448107.3601 - mean_absolute_error: 178768.5219 - val_loss: 39050771431.3677 - val_mean_absolute_error: 180168.0887\n",
      "Epoch 209/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 37958822793.7451 - mean_absolute_error: 178716.6562 - val_loss: 39025934772.3436 - val_mean_absolute_error: 180118.3231\n",
      "Epoch 210/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 37955016418.4363 - mean_absolute_error: 178708.9547 - val_loss: 38939957430.9828 - val_mean_absolute_error: 179861.3675\n",
      "Epoch 211/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 37940729682.5594 - mean_absolute_error: 178695.3082 - val_loss: 39011881283.7388 - val_mean_absolute_error: 180018.4321\n",
      "Epoch 212/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 37943534349.3584 - mean_absolute_error: 178680.1290 - val_loss: 39003538365.1409 - val_mean_absolute_error: 180011.3600\n",
      "Epoch 213/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 37919051255.6784 - mean_absolute_error: 178656.8112 - val_loss: 38985005288.2474 - val_mean_absolute_error: 180002.4806\n",
      "Epoch 214/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 37926237074.5047 - mean_absolute_error: 178654.4436 - val_loss: 39060730911.6701 - val_mean_absolute_error: 180234.2785\n",
      "Epoch 215/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 37900610280.5680 - mean_absolute_error: 178600.3859 - val_loss: 39055022199.6426 - val_mean_absolute_error: 180188.9765\n",
      "Epoch 216/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 37894633032.2669 - mean_absolute_error: 178617.7549 - val_loss: 38987537636.7285 - val_mean_absolute_error: 180014.4064\n",
      "Epoch 217/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 37902328669.9470 - mean_absolute_error: 178608.3895 - val_loss: 38940429498.5017 - val_mean_absolute_error: 179909.0195\n",
      "Epoch 218/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 37890701681.6561 - mean_absolute_error: 178575.5222 - val_loss: 38945895244.5361 - val_mean_absolute_error: 179931.6124\n",
      "Epoch 219/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 37878875541.5706 - mean_absolute_error: 178555.8168 - val_loss: 38918385108.0137 - val_mean_absolute_error: 179868.0670\n",
      "Epoch 220/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 37878687920.9444 - mean_absolute_error: 178569.9381 - val_loss: 38970436576.3299 - val_mean_absolute_error: 179968.6972\n",
      "Epoch 221/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 37861760608.7938 - mean_absolute_error: 178521.7153 - val_loss: 38995740798.6804 - val_mean_absolute_error: 180083.2650\n",
      "Epoch 222/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 37863499211.8802 - mean_absolute_error: 178527.4269 - val_loss: 38948342942.3505 - val_mean_absolute_error: 179987.3129\n",
      "Epoch 223/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 37862128043.4696 - mean_absolute_error: 178520.6552 - val_loss: 38944412274.3643 - val_mean_absolute_error: 179960.6370\n",
      "Epoch 224/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 37819344531.5997 - mean_absolute_error: 178431.5488 - val_loss: 38803602006.2131 - val_mean_absolute_error: 179601.7862\n",
      "Epoch 225/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 37845730399.4799 - mean_absolute_error: 178486.9848 - val_loss: 38860390125.5258 - val_mean_absolute_error: 179689.9091\n",
      "Epoch 226/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 37830929997.5227 - mean_absolute_error: 178448.1961 - val_loss: 38846266005.5533 - val_mean_absolute_error: 179639.0535\n",
      "Epoch 227/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 37811905382.7066 - mean_absolute_error: 178427.8841 - val_loss: 38937611274.5567 - val_mean_absolute_error: 179858.9066\n",
      "Epoch 228/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 37811507070.3576 - mean_absolute_error: 178402.5612 - val_loss: 38920041489.5945 - val_mean_absolute_error: 179844.2735\n",
      "Epoch 229/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 37787274547.4628 - mean_absolute_error: 178353.6358 - val_loss: 38840806220.5361 - val_mean_absolute_error: 179736.2428\n",
      "Epoch 230/5000\n",
      "1169/1169 [==============================] - 0s 299us/step - loss: 37804382083.6133 - mean_absolute_error: 178390.0669 - val_loss: 38888259091.3540 - val_mean_absolute_error: 179851.1437\n",
      "Epoch 231/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 37784052128.9581 - mean_absolute_error: 178335.3901 - val_loss: 38759355043.6289 - val_mean_absolute_error: 179487.4593\n",
      "Epoch 232/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 37811491702.4739 - mean_absolute_error: 178387.0553 - val_loss: 38770354471.5876 - val_mean_absolute_error: 179470.5107\n",
      "Epoch 233/5000\n",
      "1169/1169 [==============================] - 0s 405us/step - loss: 37791513061.2831 - mean_absolute_error: 178342.2920 - val_loss: 38846380792.0825 - val_mean_absolute_error: 179674.0533\n",
      "Epoch 234/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 37744886686.7682 - mean_absolute_error: 178281.2263 - val_loss: 38890793727.1203 - val_mean_absolute_error: 179821.8222\n",
      "Epoch 235/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 37771816315.2917 - mean_absolute_error: 178313.9014 - val_loss: 38801896113.7045 - val_mean_absolute_error: 179575.8168\n",
      "Epoch 236/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 37757395049.1155 - mean_absolute_error: 178267.8266 - val_loss: 38772508953.5120 - val_mean_absolute_error: 179483.3673\n",
      "Epoch 237/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 37723510144.5475 - mean_absolute_error: 178235.3894 - val_loss: 38814048959.7801 - val_mean_absolute_error: 179563.4905\n",
      "Epoch 238/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 37760480577.4782 - mean_absolute_error: 178274.2631 - val_loss: 38850113613.4158 - val_mean_absolute_error: 179707.2168\n",
      "Epoch 239/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 37724515602.1762 - mean_absolute_error: 178220.0891 - val_loss: 38819284154.5017 - val_mean_absolute_error: 179611.2083\n",
      "Epoch 240/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 37704291488.3011 - mean_absolute_error: 178181.1104 - val_loss: 38832664055.2028 - val_mean_absolute_error: 179679.8652\n",
      "Epoch 241/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 37719461765.3653 - mean_absolute_error: 178195.2636 - val_loss: 38842354290.3643 - val_mean_absolute_error: 179695.4267\n",
      "Epoch 242/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 37689185470.0838 - mean_absolute_error: 178151.5629 - val_loss: 38671567917.7457 - val_mean_absolute_error: 179317.1050\n",
      "Epoch 243/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 37702393868.2635 - mean_absolute_error: 178127.3957 - val_loss: 38691002656.5498 - val_mean_absolute_error: 179314.1009\n",
      "Epoch 244/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 37680753226.8948 - mean_absolute_error: 178115.5611 - val_loss: 38835379583.5601 - val_mean_absolute_error: 179670.1495\n",
      "Epoch 245/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 37699621207.3773 - mean_absolute_error: 178148.1122 - val_loss: 38721905716.7835 - val_mean_absolute_error: 179359.9601\n",
      "Epoch 246/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 37654030931.6544 - mean_absolute_error: 178054.9145 - val_loss: 38629514757.2784 - val_mean_absolute_error: 179176.5457\n",
      "Epoch 247/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 37672986375.2267 - mean_absolute_error: 178069.8690 - val_loss: 38689103294.9003 - val_mean_absolute_error: 179320.8008\n",
      "Epoch 248/5000\n",
      "1169/1169 [==============================] - 0s 405us/step - loss: 37655209812.3114 - mean_absolute_error: 178036.4688 - val_loss: 38754206829.0859 - val_mean_absolute_error: 179491.1991\n",
      "Epoch 249/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 37638570474.5389 - mean_absolute_error: 178035.3821 - val_loss: 38756715797.9931 - val_mean_absolute_error: 179491.3172\n",
      "Epoch 250/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 37636495056.9170 - mean_absolute_error: 178019.5625 - val_loss: 38577387864.8522 - val_mean_absolute_error: 179030.5686\n",
      "Epoch 251/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 37617497311.3704 - mean_absolute_error: 177969.7433 - val_loss: 38488221273.7320 - val_mean_absolute_error: 178814.5250\n",
      "Epoch 252/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 37619599088.4517 - mean_absolute_error: 177971.2171 - val_loss: 38748501072.9347 - val_mean_absolute_error: 179459.7542\n",
      "Epoch 253/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 37614246194.5868 - mean_absolute_error: 177983.4982 - val_loss: 38757980230.3780 - val_mean_absolute_error: 179432.6481\n",
      "Epoch 254/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 37594760832.3285 - mean_absolute_error: 177913.2955 - val_loss: 38769364984.9622 - val_mean_absolute_error: 179474.9528\n",
      "Epoch 255/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 37598070277.6938 - mean_absolute_error: 177907.5543 - val_loss: 38634263766.6529 - val_mean_absolute_error: 179171.3080\n",
      "Epoch 256/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 37592917120.7665 - mean_absolute_error: 177925.4255 - val_loss: 38717781713.3746 - val_mean_absolute_error: 179389.9027\n",
      "Epoch 257/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 37549835617.0128 - mean_absolute_error: 177840.5040 - val_loss: 38771008121.4021 - val_mean_absolute_error: 179510.3526\n",
      "Epoch 258/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 37561219466.1831 - mean_absolute_error: 177852.7056 - val_loss: 38727526484.4536 - val_mean_absolute_error: 179358.9726\n",
      "Epoch 259/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 37547493703.6099 - mean_absolute_error: 177814.7302 - val_loss: 38692440964.8385 - val_mean_absolute_error: 179330.6413\n",
      "Epoch 260/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 37526024798.1660 - mean_absolute_error: 177773.9514 - val_loss: 38662677028.9485 - val_mean_absolute_error: 179251.1176\n",
      "Epoch 261/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 37507532896.3559 - mean_absolute_error: 177750.1167 - val_loss: 38678575955.5739 - val_mean_absolute_error: 179294.1389\n",
      "Epoch 262/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 37547431286.0359 - mean_absolute_error: 177808.9449 - val_loss: 38570613643.8763 - val_mean_absolute_error: 179031.2802\n",
      "Epoch 263/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 37507157712.9170 - mean_absolute_error: 177744.7737 - val_loss: 38560859484.3711 - val_mean_absolute_error: 178987.7063\n",
      "Epoch 264/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 37473349239.5689 - mean_absolute_error: 177663.1942 - val_loss: 38532428261.6082 - val_mean_absolute_error: 178941.1705\n",
      "Epoch 265/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 37516244932.4346 - mean_absolute_error: 177758.4917 - val_loss: 38524368248.5223 - val_mean_absolute_error: 178897.2650\n",
      "Epoch 266/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 37487832849.7382 - mean_absolute_error: 177671.8846 - val_loss: 38524571472.0550 - val_mean_absolute_error: 178908.9298\n",
      "Epoch 267/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 37490732821.2421 - mean_absolute_error: 177699.3811 - val_loss: 38595309807.2852 - val_mean_absolute_error: 179091.2099\n",
      "Epoch 268/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 37478645322.0188 - mean_absolute_error: 177658.5256 - val_loss: 38537862541.6357 - val_mean_absolute_error: 178948.5456\n",
      "Epoch 269/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 37455571236.5714 - mean_absolute_error: 177610.3321 - val_loss: 38480767032.3024 - val_mean_absolute_error: 178791.2138\n",
      "Epoch 270/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 37472208466.7784 - mean_absolute_error: 177624.5651 - val_loss: 38524245699.2990 - val_mean_absolute_error: 178911.4387\n",
      "Epoch 271/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 37439137602.7921 - mean_absolute_error: 177576.3031 - val_loss: 38627651731.7938 - val_mean_absolute_error: 179205.1105\n",
      "Epoch 272/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 37417916973.1121 - mean_absolute_error: 177541.5092 - val_loss: 38511306892.7560 - val_mean_absolute_error: 178972.1989\n",
      "Epoch 273/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 37458669820.2772 - mean_absolute_error: 177606.0064 - val_loss: 38465808503.6426 - val_mean_absolute_error: 178866.5920\n",
      "Epoch 274/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 37460685689.9778 - mean_absolute_error: 177587.3111 - val_loss: 38524056586.5567 - val_mean_absolute_error: 178941.9278\n",
      "Epoch 275/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 37394519326.4397 - mean_absolute_error: 177497.0019 - val_loss: 38411105445.3883 - val_mean_absolute_error: 178678.6701\n",
      "Epoch 276/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 37383217929.8546 - mean_absolute_error: 177483.7278 - val_loss: 38554159251.7938 - val_mean_absolute_error: 179054.3309\n",
      "Epoch 277/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 37400147486.2207 - mean_absolute_error: 177478.0660 - val_loss: 38581327449.7320 - val_mean_absolute_error: 179105.5040\n",
      "Epoch 278/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 37386350921.3618 - mean_absolute_error: 177497.7063 - val_loss: 38507524229.7182 - val_mean_absolute_error: 178932.9040\n",
      "Epoch 279/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 37380297583.4662 - mean_absolute_error: 177455.3220 - val_loss: 38540425835.3265 - val_mean_absolute_error: 178994.4221\n",
      "Epoch 280/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 37369829258.6210 - mean_absolute_error: 177427.9499 - val_loss: 38502505771.1065 - val_mean_absolute_error: 178929.2370\n",
      "Epoch 281/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 37358454715.6749 - mean_absolute_error: 177401.0997 - val_loss: 38584596360.3574 - val_mean_absolute_error: 179099.9552\n",
      "Epoch 282/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 37316701300.5030 - mean_absolute_error: 177320.2772 - val_loss: 38385712814.1856 - val_mean_absolute_error: 178672.4673\n",
      "Epoch 283/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 37332047850.9769 - mean_absolute_error: 177356.8643 - val_loss: 38468375140.2887 - val_mean_absolute_error: 178830.3363\n",
      "Epoch 284/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 37342978909.9470 - mean_absolute_error: 177377.7748 - val_loss: 38513353689.2921 - val_mean_absolute_error: 178908.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 37299715177.9914 - mean_absolute_error: 177310.4501 - val_loss: 38285658843.9313 - val_mean_absolute_error: 178417.5414\n",
      "Epoch 286/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 37355363588.1608 - mean_absolute_error: 177369.7120 - val_loss: 38329650559.5601 - val_mean_absolute_error: 178457.9731\n",
      "Epoch 287/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 37260895602.5321 - mean_absolute_error: 177220.8495 - val_loss: 38387769435.4914 - val_mean_absolute_error: 178526.6625\n",
      "Epoch 288/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 37311500827.5928 - mean_absolute_error: 177291.7972 - val_loss: 38366133962.3368 - val_mean_absolute_error: 178477.9933\n",
      "Epoch 289/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 37273803853.9607 - mean_absolute_error: 177236.6577 - val_loss: 38316186317.8557 - val_mean_absolute_error: 178439.6196\n",
      "Epoch 290/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 37258866250.0188 - mean_absolute_error: 177227.3490 - val_loss: 38470411183.0653 - val_mean_absolute_error: 178755.7229\n",
      "Epoch 291/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 37284972507.2096 - mean_absolute_error: 177218.0855 - val_loss: 38411404326.7079 - val_mean_absolute_error: 178594.1265\n",
      "Epoch 292/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 37250996113.6287 - mean_absolute_error: 177163.4840 - val_loss: 38372368939.9863 - val_mean_absolute_error: 178553.3868\n",
      "Epoch 293/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 37261754220.8383 - mean_absolute_error: 177184.5494 - val_loss: 38260556339.0241 - val_mean_absolute_error: 178353.9155\n",
      "Epoch 294/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 37254540502.6108 - mean_absolute_error: 177167.9677 - val_loss: 38241966277.0584 - val_mean_absolute_error: 178316.5042\n",
      "Epoch 295/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 37219477246.4671 - mean_absolute_error: 177109.7553 - val_loss: 38357197088.5498 - val_mean_absolute_error: 178576.3432\n",
      "Epoch 296/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 37219917992.1848 - mean_absolute_error: 177102.9279 - val_loss: 38324006996.4536 - val_mean_absolute_error: 178506.5206\n",
      "Epoch 297/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 37210883912.0479 - mean_absolute_error: 177079.3879 - val_loss: 38424959665.7045 - val_mean_absolute_error: 178675.7500\n",
      "Epoch 298/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 37195581469.7827 - mean_absolute_error: 177009.3440 - val_loss: 38212496788.6735 - val_mean_absolute_error: 178155.7489\n",
      "Epoch 299/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 37183791801.2660 - mean_absolute_error: 177016.3935 - val_loss: 38290102701.3058 - val_mean_absolute_error: 178413.4932\n",
      "Epoch 300/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 37182928531.5997 - mean_absolute_error: 176985.9616 - val_loss: 38161555082.9966 - val_mean_absolute_error: 178091.7044\n",
      "Epoch 301/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 37151267700.7220 - mean_absolute_error: 176944.8443 - val_loss: 38136195381.6632 - val_mean_absolute_error: 178020.6725\n",
      "Epoch 302/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 37198538603.0864 - mean_absolute_error: 177011.9226 - val_loss: 38196570639.8351 - val_mean_absolute_error: 178127.4750\n",
      "Epoch 303/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 37130598370.2173 - mean_absolute_error: 176897.0796 - val_loss: 38193941106.3643 - val_mean_absolute_error: 178094.9123\n",
      "Epoch 304/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 37130829736.4038 - mean_absolute_error: 176901.8620 - val_loss: 38211539732.2337 - val_mean_absolute_error: 178138.1645\n",
      "Epoch 305/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 37143339400.4311 - mean_absolute_error: 176895.4150 - val_loss: 38323783384.4124 - val_mean_absolute_error: 178475.0017\n",
      "Epoch 306/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 37090749938.4226 - mean_absolute_error: 176818.7307 - val_loss: 38276640585.0172 - val_mean_absolute_error: 178335.3659\n",
      "Epoch 307/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 37107896884.1198 - mean_absolute_error: 176888.3230 - val_loss: 38138863953.8144 - val_mean_absolute_error: 177944.9296\n",
      "Epoch 308/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 37103497615.4388 - mean_absolute_error: 176790.2779 - val_loss: 38119656416.3299 - val_mean_absolute_error: 177927.0801\n",
      "Epoch 309/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 37107212892.4140 - mean_absolute_error: 176831.3372 - val_loss: 38137064908.9759 - val_mean_absolute_error: 177992.4754\n",
      "Epoch 310/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 37090419241.6082 - mean_absolute_error: 176812.4696 - val_loss: 38286045486.6254 - val_mean_absolute_error: 178387.2276\n",
      "Epoch 311/5000\n",
      "1169/1169 [==============================] - 0s 390us/step - loss: 37124928423.5278 - mean_absolute_error: 176841.9005 - val_loss: 38304557119.3402 - val_mean_absolute_error: 178400.2861\n",
      "Epoch 312/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 37065840788.9136 - mean_absolute_error: 176693.3179 - val_loss: 38283714067.3540 - val_mean_absolute_error: 178277.4860\n",
      "Epoch 313/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 37037010646.1728 - mean_absolute_error: 176716.4538 - val_loss: 38314208752.1649 - val_mean_absolute_error: 178446.5038\n",
      "Epoch 314/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 37013583127.4320 - mean_absolute_error: 176658.5451 - val_loss: 38167362859.1065 - val_mean_absolute_error: 178127.2503\n",
      "Epoch 315/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 37032408035.0932 - mean_absolute_error: 176688.9694 - val_loss: 37902087959.7526 - val_mean_absolute_error: 177502.2858\n",
      "Epoch 316/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 37012610406.2686 - mean_absolute_error: 176602.7653 - val_loss: 38134563927.9725 - val_mean_absolute_error: 178033.7978\n",
      "Epoch 317/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 36966066782.1660 - mean_absolute_error: 176516.0529 - val_loss: 38229911629.4158 - val_mean_absolute_error: 178242.3041\n",
      "Epoch 318/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 36973283546.9906 - mean_absolute_error: 176569.3773 - val_loss: 38128331315.0241 - val_mean_absolute_error: 178013.2272\n",
      "Epoch 319/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 36969991848.6227 - mean_absolute_error: 176545.9307 - val_loss: 38156435357.4708 - val_mean_absolute_error: 178001.9789\n",
      "Epoch 320/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 36959756909.9333 - mean_absolute_error: 176541.1576 - val_loss: 38221941988.7285 - val_mean_absolute_error: 178314.0076\n",
      "Epoch 321/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 36945040009.9641 - mean_absolute_error: 176511.3033 - val_loss: 38086487057.5945 - val_mean_absolute_error: 177987.4515\n",
      "Epoch 322/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 36942536047.0282 - mean_absolute_error: 176548.8043 - val_loss: 38033000265.0172 - val_mean_absolute_error: 177800.8789\n",
      "Epoch 323/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 36947084273.1086 - mean_absolute_error: 176490.6185 - val_loss: 37986027935.2302 - val_mean_absolute_error: 177622.5026\n",
      "Epoch 324/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 36938357501.5911 - mean_absolute_error: 176470.7345 - val_loss: 38213827059.6838 - val_mean_absolute_error: 178206.1786\n",
      "Epoch 325/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 36928166478.3986 - mean_absolute_error: 176412.5444 - val_loss: 37970884769.8694 - val_mean_absolute_error: 177475.5855\n",
      "Epoch 326/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 36884636499.4354 - mean_absolute_error: 176360.3622 - val_loss: 37973289297.8144 - val_mean_absolute_error: 177483.9890\n",
      "Epoch 327/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 36912271398.5423 - mean_absolute_error: 176424.2868 - val_loss: 37935638535.0378 - val_mean_absolute_error: 177402.6685\n",
      "Epoch 328/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 36898186596.5167 - mean_absolute_error: 176367.6377 - val_loss: 38014834033.4845 - val_mean_absolute_error: 177715.6661\n",
      "Epoch 329/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 36884670663.7194 - mean_absolute_error: 176344.5590 - val_loss: 38064719611.6014 - val_mean_absolute_error: 177823.7116\n",
      "Epoch 330/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 36828695114.8948 - mean_absolute_error: 176223.0427 - val_loss: 37869749906.0344 - val_mean_absolute_error: 177402.1584\n",
      "Epoch 331/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 36836401432.3080 - mean_absolute_error: 176294.9920 - val_loss: 37930343455.6701 - val_mean_absolute_error: 177543.9165\n",
      "Epoch 332/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 36833503512.3080 - mean_absolute_error: 176273.2581 - val_loss: 38091503679.3402 - val_mean_absolute_error: 177896.0972\n",
      "Epoch 333/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 36830856415.3704 - mean_absolute_error: 176271.6581 - val_loss: 37904993550.9553 - val_mean_absolute_error: 177444.8063\n",
      "Epoch 334/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 36864836577.3413 - mean_absolute_error: 176231.9019 - val_loss: 37903758649.1821 - val_mean_absolute_error: 177347.5551\n",
      "Epoch 335/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 36781404338.6963 - mean_absolute_error: 176102.6961 - val_loss: 37880490420.3436 - val_mean_absolute_error: 177328.4521\n",
      "Epoch 336/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 36810375903.8084 - mean_absolute_error: 176181.4382 - val_loss: 37968918105.7320 - val_mean_absolute_error: 177532.1151\n",
      "Epoch 337/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 36821476041.0334 - mean_absolute_error: 176194.2234 - val_loss: 37975536404.2337 - val_mean_absolute_error: 177574.2251\n",
      "Epoch 338/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 36792335704.2532 - mean_absolute_error: 176094.2696 - val_loss: 37730866383.6151 - val_mean_absolute_error: 177020.4584\n",
      "Epoch 339/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 36752438278.1317 - mean_absolute_error: 176076.1833 - val_loss: 37760150010.7216 - val_mean_absolute_error: 177101.4752\n",
      "Epoch 340/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 36806235122.8606 - mean_absolute_error: 176147.6619 - val_loss: 37871109369.8419 - val_mean_absolute_error: 177302.7372\n",
      "Epoch 341/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 36743959757.8512 - mean_absolute_error: 176017.3441 - val_loss: 38005548732.2612 - val_mean_absolute_error: 177679.9195\n",
      "Epoch 342/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 36751613682.2036 - mean_absolute_error: 176047.6869 - val_loss: 37893622168.1924 - val_mean_absolute_error: 177453.2894\n",
      "Epoch 343/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 36795174968.0616 - mean_absolute_error: 176091.4805 - val_loss: 37864365932.2062 - val_mean_absolute_error: 177365.4531\n",
      "Epoch 344/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 36714995175.9110 - mean_absolute_error: 175947.8841 - val_loss: 37762984506.0619 - val_mean_absolute_error: 177135.4707\n",
      "Epoch 345/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 36710264040.1300 - mean_absolute_error: 175970.0257 - val_loss: 37939488212.0137 - val_mean_absolute_error: 177519.9785\n",
      "Epoch 346/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 36678995754.2652 - mean_absolute_error: 175966.9039 - val_loss: 37628820722.8041 - val_mean_absolute_error: 176864.2267\n",
      "Epoch 347/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 36698228932.2156 - mean_absolute_error: 175921.9301 - val_loss: 37767279260.5911 - val_mean_absolute_error: 177175.0022\n",
      "Epoch 348/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 36670569409.8067 - mean_absolute_error: 175868.0822 - val_loss: 37769869473.8694 - val_mean_absolute_error: 177072.1841\n",
      "Epoch 349/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 36687065392.8349 - mean_absolute_error: 175902.4308 - val_loss: 37680326184.4674 - val_mean_absolute_error: 176929.3620\n",
      "Epoch 350/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 36632842334.6039 - mean_absolute_error: 175815.9176 - val_loss: 37858759845.3883 - val_mean_absolute_error: 177361.9241\n",
      "Epoch 351/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 36630147790.2891 - mean_absolute_error: 175824.9400 - val_loss: 37833638563.6289 - val_mean_absolute_error: 177322.1072\n",
      "Epoch 352/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 36631450689.6972 - mean_absolute_error: 175790.5241 - val_loss: 37929694739.3540 - val_mean_absolute_error: 177573.4077\n",
      "Epoch 353/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 36656216661.4063 - mean_absolute_error: 175822.0332 - val_loss: 37724523446.1031 - val_mean_absolute_error: 177032.2449\n",
      "Epoch 354/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 36606639728.5612 - mean_absolute_error: 175726.6525 - val_loss: 37758438150.1581 - val_mean_absolute_error: 177101.0474\n",
      "Epoch 355/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 36602256763.2917 - mean_absolute_error: 175715.7840 - val_loss: 37828882854.2680 - val_mean_absolute_error: 177302.3208\n",
      "Epoch 356/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 36572672266.2926 - mean_absolute_error: 175653.0589 - val_loss: 37619592181.4433 - val_mean_absolute_error: 176809.6459\n",
      "Epoch 357/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 36568771113.6082 - mean_absolute_error: 175627.0682 - val_loss: 37813672294.9278 - val_mean_absolute_error: 177191.8196\n",
      "Epoch 358/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 36583126488.1437 - mean_absolute_error: 175633.8533 - val_loss: 37615921898.0069 - val_mean_absolute_error: 176767.6426\n",
      "Epoch 359/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 36598151824.9718 - mean_absolute_error: 175699.5223 - val_loss: 37696260511.2302 - val_mean_absolute_error: 176910.6984\n",
      "Epoch 360/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 36532561711.5210 - mean_absolute_error: 175477.7058 - val_loss: 37650181236.1237 - val_mean_absolute_error: 176769.8473\n",
      "Epoch 361/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 36528007231.0693 - mean_absolute_error: 175576.8943 - val_loss: 37718481409.7595 - val_mean_absolute_error: 176969.9919\n",
      "Epoch 362/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 36525637302.6382 - mean_absolute_error: 175452.5195 - val_loss: 37480936001.0997 - val_mean_absolute_error: 176406.3254\n",
      "Epoch 363/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 36465433898.7032 - mean_absolute_error: 175502.3634 - val_loss: 37530625921.3196 - val_mean_absolute_error: 176577.6835\n",
      "Epoch 364/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 36507489205.5432 - mean_absolute_error: 175522.6592 - val_loss: 37575533972.6735 - val_mean_absolute_error: 176592.4690\n",
      "Epoch 365/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 36459832984.8554 - mean_absolute_error: 175394.3573 - val_loss: 37759890351.0653 - val_mean_absolute_error: 177148.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 36473808126.9051 - mean_absolute_error: 175420.9496 - val_loss: 37762626563.5189 - val_mean_absolute_error: 177052.4795\n",
      "Epoch 367/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 36457671905.1223 - mean_absolute_error: 175379.0828 - val_loss: 37563189248.0000 - val_mean_absolute_error: 176587.3885\n",
      "Epoch 368/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 36436602820.4346 - mean_absolute_error: 175357.0522 - val_loss: 37617634926.8454 - val_mean_absolute_error: 176741.5507\n",
      "Epoch 369/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 36457358377.1702 - mean_absolute_error: 175399.1077 - val_loss: 37582583660.2062 - val_mean_absolute_error: 176706.6992\n",
      "Epoch 370/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 36398142445.6048 - mean_absolute_error: 175311.2184 - val_loss: 37600866543.2852 - val_mean_absolute_error: 176792.4983\n",
      "Epoch 371/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 36406901836.2087 - mean_absolute_error: 175339.2993 - val_loss: 37690889395.4639 - val_mean_absolute_error: 176997.5809\n",
      "Epoch 372/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 36387761228.2087 - mean_absolute_error: 175245.9220 - val_loss: 37743907266.4192 - val_mean_absolute_error: 177086.6403\n",
      "Epoch 373/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 36396460934.2412 - mean_absolute_error: 175206.1221 - val_loss: 37870431221.4433 - val_mean_absolute_error: 177569.1473\n",
      "Epoch 374/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 36384197997.2763 - mean_absolute_error: 175180.4534 - val_loss: 37563295307.6564 - val_mean_absolute_error: 176682.0242\n",
      "Epoch 375/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 36376394766.8914 - mean_absolute_error: 175193.2172 - val_loss: 37514964365.6357 - val_mean_absolute_error: 176567.5877\n",
      "Epoch 376/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 36371852378.2241 - mean_absolute_error: 175169.5228 - val_loss: 37362825398.9828 - val_mean_absolute_error: 176142.1216\n",
      "Epoch 377/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 36360324251.0453 - mean_absolute_error: 175144.9858 - val_loss: 37478730783.6701 - val_mean_absolute_error: 176353.9023\n",
      "Epoch 378/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 36344175178.8948 - mean_absolute_error: 175120.7810 - val_loss: 37481966982.5979 - val_mean_absolute_error: 176428.2460\n",
      "Epoch 379/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 36320594832.7528 - mean_absolute_error: 175049.1437 - val_loss: 37402195918.7354 - val_mean_absolute_error: 176220.5833\n",
      "Epoch 380/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 36281215240.5406 - mean_absolute_error: 175006.1043 - val_loss: 37439128150.2131 - val_mean_absolute_error: 176345.8303\n",
      "Epoch 381/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 36329187834.3062 - mean_absolute_error: 175059.3364 - val_loss: 37317806136.3024 - val_mean_absolute_error: 176009.6260\n",
      "Epoch 382/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 36325317324.5372 - mean_absolute_error: 175058.5574 - val_loss: 37268136900.1787 - val_mean_absolute_error: 175978.1380\n",
      "Epoch 383/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 36291621834.5663 - mean_absolute_error: 175000.1386 - val_loss: 37248311127.0928 - val_mean_absolute_error: 175945.7788\n",
      "Epoch 384/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 36276933256.2121 - mean_absolute_error: 174972.8011 - val_loss: 37532004746.1168 - val_mean_absolute_error: 176600.8433\n",
      "Epoch 385/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 36263071439.1651 - mean_absolute_error: 174978.6896 - val_loss: 37587938954.9966 - val_mean_absolute_error: 176681.5987\n",
      "Epoch 386/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 36256141674.6484 - mean_absolute_error: 174884.3892 - val_loss: 37233661107.4639 - val_mean_absolute_error: 175800.6074\n",
      "Epoch 387/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 36247536083.7639 - mean_absolute_error: 174893.3725 - val_loss: 37279376542.3505 - val_mean_absolute_error: 175868.3542\n",
      "Epoch 388/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 36254579761.9299 - mean_absolute_error: 174932.3424 - val_loss: 37354109990.7079 - val_mean_absolute_error: 176076.5322\n",
      "Epoch 389/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 36211010476.7836 - mean_absolute_error: 174841.5510 - val_loss: 37411694028.9759 - val_mean_absolute_error: 176229.1306\n",
      "Epoch 390/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 36165976267.2233 - mean_absolute_error: 174770.9460 - val_loss: 37263074173.8007 - val_mean_absolute_error: 175906.4267\n",
      "Epoch 391/5000\n",
      "1169/1169 [==============================] - 0s 387us/step - loss: 36193693874.6963 - mean_absolute_error: 174799.1222 - val_loss: 37424632631.4227 - val_mean_absolute_error: 176235.0677\n",
      "Epoch 392/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 36143297615.7126 - mean_absolute_error: 174696.7234 - val_loss: 37397445649.5945 - val_mean_absolute_error: 176186.1617\n",
      "Epoch 393/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 36128283456.1642 - mean_absolute_error: 174620.3750 - val_loss: 37109360386.6392 - val_mean_absolute_error: 175451.3194\n",
      "Epoch 394/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 36174591800.2806 - mean_absolute_error: 174675.6755 - val_loss: 37093914004.6735 - val_mean_absolute_error: 175386.0896\n",
      "Epoch 395/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 36136902866.2310 - mean_absolute_error: 174630.2799 - val_loss: 37211801980.0412 - val_mean_absolute_error: 175755.8810\n",
      "Epoch 396/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 36121424380.0582 - mean_absolute_error: 174607.7796 - val_loss: 37061947919.8351 - val_mean_absolute_error: 175379.8562\n",
      "Epoch 397/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 36074254816.0274 - mean_absolute_error: 174517.2234 - val_loss: 37253007979.3265 - val_mean_absolute_error: 175823.1772\n",
      "Epoch 398/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 36102593288.1027 - mean_absolute_error: 174567.1374 - val_loss: 37288263827.7938 - val_mean_absolute_error: 175936.2322\n",
      "Epoch 399/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 36038559740.4962 - mean_absolute_error: 174462.5454 - val_loss: 37162326156.7560 - val_mean_absolute_error: 175734.8144\n",
      "Epoch 400/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 36070721835.5791 - mean_absolute_error: 174530.6091 - val_loss: 37243880789.3333 - val_mean_absolute_error: 175819.4648\n",
      "Epoch 401/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 36055745927.5552 - mean_absolute_error: 174456.4623 - val_loss: 36984498190.0756 - val_mean_absolute_error: 175206.5776\n",
      "Epoch 402/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 36071413628.6056 - mean_absolute_error: 174537.7934 - val_loss: 37088659751.5876 - val_mean_absolute_error: 175491.8039\n",
      "Epoch 403/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 36081804180.2566 - mean_absolute_error: 174456.2610 - val_loss: 37167399313.1546 - val_mean_absolute_error: 175677.0697\n",
      "Epoch 404/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 35979789141.1873 - mean_absolute_error: 174348.5914 - val_loss: 37171100323.6289 - val_mean_absolute_error: 175772.4667\n",
      "Epoch 405/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 35980709810.9153 - mean_absolute_error: 174327.1242 - val_loss: 37192746079.0103 - val_mean_absolute_error: 175891.7291\n",
      "Epoch 406/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 36026197937.1634 - mean_absolute_error: 174385.8337 - val_loss: 37144423779.4089 - val_mean_absolute_error: 175738.3950\n",
      "Epoch 407/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 35978035659.0043 - mean_absolute_error: 174271.3453 - val_loss: 37511957345.6495 - val_mean_absolute_error: 176621.8709\n",
      "Epoch 408/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 35920212805.4200 - mean_absolute_error: 174156.1207 - val_loss: 36966679365.4983 - val_mean_absolute_error: 175288.8033\n",
      "Epoch 409/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 35950832700.4414 - mean_absolute_error: 174225.9456 - val_loss: 37255419805.4708 - val_mean_absolute_error: 175999.3729\n",
      "Epoch 410/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 35977315148.4277 - mean_absolute_error: 174292.0854 - val_loss: 37087143647.4502 - val_mean_absolute_error: 175584.9227\n",
      "Epoch 411/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35933630432.4654 - mean_absolute_error: 174128.3264 - val_loss: 36798407043.0790 - val_mean_absolute_error: 174887.4453\n",
      "Epoch 412/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 35897450194.6690 - mean_absolute_error: 174177.7285 - val_loss: 36953569751.5326 - val_mean_absolute_error: 175202.7676\n",
      "Epoch 413/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 35914418864.5064 - mean_absolute_error: 174152.4530 - val_loss: 36995160197.7182 - val_mean_absolute_error: 175303.5683\n",
      "Epoch 414/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35891702297.8409 - mean_absolute_error: 174127.5843 - val_loss: 36875108725.0034 - val_mean_absolute_error: 175088.1695\n",
      "Epoch 415/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 35880423732.3388 - mean_absolute_error: 174129.5999 - val_loss: 37364068851.6838 - val_mean_absolute_error: 176215.4529\n",
      "Epoch 416/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35829139145.9093 - mean_absolute_error: 173970.3195 - val_loss: 37031432656.4948 - val_mean_absolute_error: 175341.1099\n",
      "Epoch 417/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 35871763381.5432 - mean_absolute_error: 174078.2605 - val_loss: 37444960678.2680 - val_mean_absolute_error: 176349.3416\n",
      "Epoch 418/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35856501158.2139 - mean_absolute_error: 173994.2134 - val_loss: 37181215290.0619 - val_mean_absolute_error: 175727.3042\n",
      "Epoch 419/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 35848288259.5038 - mean_absolute_error: 174000.8656 - val_loss: 36885783069.9107 - val_mean_absolute_error: 175081.0425\n",
      "Epoch 420/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 35837419957.9812 - mean_absolute_error: 173969.0914 - val_loss: 37068473875.3540 - val_mean_absolute_error: 175418.2603\n",
      "Epoch 421/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 35820165822.5218 - mean_absolute_error: 173913.1973 - val_loss: 36845660554.1168 - val_mean_absolute_error: 174835.6735\n",
      "Epoch 422/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 35781441548.2635 - mean_absolute_error: 173752.5157 - val_loss: 37095996475.8213 - val_mean_absolute_error: 175570.1029\n",
      "Epoch 423/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 35818337864.2669 - mean_absolute_error: 173883.4035 - val_loss: 36988292929.9794 - val_mean_absolute_error: 175209.2989\n",
      "Epoch 424/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 35778935887.7126 - mean_absolute_error: 173813.3248 - val_loss: 36992830777.1821 - val_mean_absolute_error: 175180.6913\n",
      "Epoch 425/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 35711070185.2250 - mean_absolute_error: 173706.7281 - val_loss: 37083301726.1306 - val_mean_absolute_error: 175504.9607\n",
      "Epoch 426/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 35705714528.5749 - mean_absolute_error: 173651.6688 - val_loss: 37215858547.2440 - val_mean_absolute_error: 175912.9283\n",
      "Epoch 427/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 35778359085.7690 - mean_absolute_error: 173860.9042 - val_loss: 36943655489.0997 - val_mean_absolute_error: 175141.0027\n",
      "Epoch 428/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 35696151961.0744 - mean_absolute_error: 173627.5704 - val_loss: 36854579622.2680 - val_mean_absolute_error: 174967.6390\n",
      "Epoch 429/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 35749385663.6168 - mean_absolute_error: 173777.2570 - val_loss: 36806440439.2028 - val_mean_absolute_error: 174826.0617\n",
      "Epoch 430/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35666174002.8058 - mean_absolute_error: 173553.3181 - val_loss: 36709003116.2062 - val_mean_absolute_error: 174658.4269\n",
      "Epoch 431/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35641553847.2951 - mean_absolute_error: 173586.2965 - val_loss: 36556973629.5808 - val_mean_absolute_error: 174216.9794\n",
      "Epoch 432/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35643628061.3447 - mean_absolute_error: 173552.2501 - val_loss: 36810446383.5052 - val_mean_absolute_error: 174886.3781\n",
      "Epoch 433/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 35644250590.2754 - mean_absolute_error: 173519.4305 - val_loss: 36735622056.0275 - val_mean_absolute_error: 174676.4505\n",
      "Epoch 434/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 35606164086.6929 - mean_absolute_error: 173530.6495 - val_loss: 37163904770.6392 - val_mean_absolute_error: 175607.7271\n",
      "Epoch 435/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 35658544542.3302 - mean_absolute_error: 173541.8858 - val_loss: 36889529002.6667 - val_mean_absolute_error: 175002.7157\n",
      "Epoch 436/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 35604355072.0000 - mean_absolute_error: 173380.7887 - val_loss: 36839471603.6838 - val_mean_absolute_error: 174964.3307\n",
      "Epoch 437/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 35611226024.4038 - mean_absolute_error: 173464.9713 - val_loss: 36736055718.2680 - val_mean_absolute_error: 174547.8302\n",
      "Epoch 438/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 35582278790.0222 - mean_absolute_error: 173404.0703 - val_loss: 36782964855.6426 - val_mean_absolute_error: 174741.4161\n",
      "Epoch 439/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 35551563024.4243 - mean_absolute_error: 173308.9551 - val_loss: 37101980225.0997 - val_mean_absolute_error: 175360.4304\n",
      "Epoch 440/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 35577192661.7348 - mean_absolute_error: 173307.7648 - val_loss: 36566443053.7457 - val_mean_absolute_error: 174244.5339\n",
      "Epoch 441/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 35582250895.8768 - mean_absolute_error: 173276.9658 - val_loss: 36453424870.4880 - val_mean_absolute_error: 174047.0228\n",
      "Epoch 442/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 35558542203.7297 - mean_absolute_error: 173375.2887 - val_loss: 36523494593.5395 - val_mean_absolute_error: 174271.7388\n",
      "Epoch 443/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 35551897745.4098 - mean_absolute_error: 173276.1444 - val_loss: 36671353296.4948 - val_mean_absolute_error: 174578.6641\n",
      "Epoch 444/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 35511209484.7015 - mean_absolute_error: 173247.1259 - val_loss: 36810174428.8110 - val_mean_absolute_error: 174920.5175\n",
      "Epoch 445/5000\n",
      "1169/1169 [==============================] - 0s 417us/step - loss: 35495482123.6065 - mean_absolute_error: 173219.9554 - val_loss: 36821472407.3127 - val_mean_absolute_error: 174860.3507\n",
      "Epoch 446/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 35448827087.6031 - mean_absolute_error: 173082.4570 - val_loss: 36792127283.9038 - val_mean_absolute_error: 174799.8756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 35471004559.0009 - mean_absolute_error: 173141.7952 - val_loss: 36952388576.3299 - val_mean_absolute_error: 175158.1289\n",
      "Epoch 448/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 35473147916.2635 - mean_absolute_error: 173137.2255 - val_loss: 36606716593.7045 - val_mean_absolute_error: 174296.7737\n",
      "Epoch 449/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 35427423136.5201 - mean_absolute_error: 173032.9741 - val_loss: 36689789730.3093 - val_mean_absolute_error: 174565.7334\n",
      "Epoch 450/5000\n",
      "1169/1169 [==============================] - 0s 378us/step - loss: 35410549727.5894 - mean_absolute_error: 173087.8997 - val_loss: 36663316043.6564 - val_mean_absolute_error: 174550.9962\n",
      "Epoch 451/5000\n",
      "1169/1169 [==============================] - 0s 395us/step - loss: 35400281405.9743 - mean_absolute_error: 173059.1156 - val_loss: 36600393474.6392 - val_mean_absolute_error: 174310.7942\n",
      "Epoch 452/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 35335828321.4508 - mean_absolute_error: 172875.5195 - val_loss: 36626113736.5773 - val_mean_absolute_error: 174329.1752\n",
      "Epoch 453/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 35453423796.4482 - mean_absolute_error: 173093.5439 - val_loss: 36205705990.1581 - val_mean_absolute_error: 173338.4937\n",
      "Epoch 454/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 35398280478.4397 - mean_absolute_error: 172974.2435 - val_loss: 36706359690.1168 - val_mean_absolute_error: 174462.2447\n",
      "Epoch 455/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 35346473524.1198 - mean_absolute_error: 172841.6996 - val_loss: 36547497646.1856 - val_mean_absolute_error: 174095.1217\n",
      "Epoch 456/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 35312833724.3319 - mean_absolute_error: 172807.8828 - val_loss: 36563747639.4227 - val_mean_absolute_error: 174226.7949\n",
      "Epoch 457/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 35311071992.3353 - mean_absolute_error: 172861.8573 - val_loss: 36519517025.6495 - val_mean_absolute_error: 174169.1409\n",
      "Epoch 458/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 35262228015.7399 - mean_absolute_error: 172718.5005 - val_loss: 36404267268.3986 - val_mean_absolute_error: 173803.5870\n",
      "Epoch 459/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 35307673489.6287 - mean_absolute_error: 172746.9509 - val_loss: 36596712613.3883 - val_mean_absolute_error: 174178.3210\n",
      "Epoch 460/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35235351936.5475 - mean_absolute_error: 172719.2265 - val_loss: 36373985153.3196 - val_mean_absolute_error: 173825.0628\n",
      "Epoch 461/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 35327009325.1121 - mean_absolute_error: 172744.2517 - val_loss: 36172833668.8385 - val_mean_absolute_error: 173178.2001\n",
      "Epoch 462/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 35245529781.7622 - mean_absolute_error: 172663.9527 - val_loss: 36362258629.0584 - val_mean_absolute_error: 173618.7563\n",
      "Epoch 463/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 35220939953.8204 - mean_absolute_error: 172640.9462 - val_loss: 36462677481.1272 - val_mean_absolute_error: 173889.7905\n",
      "Epoch 464/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 35332349300.2840 - mean_absolute_error: 172723.0682 - val_loss: 36670393122.3093 - val_mean_absolute_error: 174377.5821\n",
      "Epoch 465/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 35220764913.7656 - mean_absolute_error: 172502.1365 - val_loss: 36399763997.9107 - val_mean_absolute_error: 173845.1059\n",
      "Epoch 466/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 35287552172.5646 - mean_absolute_error: 172659.2852 - val_loss: 36634112612.2887 - val_mean_absolute_error: 174333.7369\n",
      "Epoch 467/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 35203270720.8212 - mean_absolute_error: 172521.9893 - val_loss: 36321455353.8419 - val_mean_absolute_error: 173608.2476\n",
      "Epoch 468/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35152378886.1317 - mean_absolute_error: 172333.0883 - val_loss: 36231279668.7835 - val_mean_absolute_error: 173510.3145\n",
      "Epoch 469/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 35104927442.6690 - mean_absolute_error: 172413.0505 - val_loss: 36046006497.2096 - val_mean_absolute_error: 172964.2054\n",
      "Epoch 470/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 35155399290.1968 - mean_absolute_error: 172363.0384 - val_loss: 35982047386.8316 - val_mean_absolute_error: 172760.7045\n",
      "Epoch 471/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 35072360356.8999 - mean_absolute_error: 172364.4686 - val_loss: 36044984693.0034 - val_mean_absolute_error: 173025.8948\n",
      "Epoch 472/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 35040094624.9581 - mean_absolute_error: 172180.2193 - val_loss: 36310986885.7182 - val_mean_absolute_error: 173516.6516\n",
      "Epoch 473/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 35152365214.1112 - mean_absolute_error: 172466.4444 - val_loss: 36490313939.1340 - val_mean_absolute_error: 173892.6942\n",
      "Epoch 474/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 35118903101.5364 - mean_absolute_error: 172305.4510 - val_loss: 36384971075.7388 - val_mean_absolute_error: 173691.1039\n",
      "Epoch 475/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 35078942870.6655 - mean_absolute_error: 172267.4851 - val_loss: 36115991583.6701 - val_mean_absolute_error: 173145.2114\n",
      "Epoch 476/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 35020636026.8537 - mean_absolute_error: 172168.0483 - val_loss: 36370935139.4089 - val_mean_absolute_error: 173791.7979\n",
      "Epoch 477/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 35040816777.0881 - mean_absolute_error: 172166.4813 - val_loss: 36320775628.9759 - val_mean_absolute_error: 173565.8072\n",
      "Epoch 478/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35029208089.4029 - mean_absolute_error: 172179.7853 - val_loss: 36036484134.7079 - val_mean_absolute_error: 172991.6135\n",
      "Epoch 479/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 34990373471.9179 - mean_absolute_error: 172122.4847 - val_loss: 36459161339.6014 - val_mean_absolute_error: 174064.3571\n",
      "Epoch 480/5000\n",
      "1169/1169 [==============================] - 0s 389us/step - loss: 35110751719.9110 - mean_absolute_error: 172236.0967 - val_loss: 35693893266.0344 - val_mean_absolute_error: 172126.3186\n",
      "Epoch 481/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 34946897490.7784 - mean_absolute_error: 171950.1132 - val_loss: 35493020935.9175 - val_mean_absolute_error: 171674.3183\n",
      "Epoch 482/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 35015392934.8708 - mean_absolute_error: 171998.5655 - val_loss: 35852335181.4158 - val_mean_absolute_error: 172394.9399\n",
      "Epoch 483/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 34948050337.8340 - mean_absolute_error: 171947.0326 - val_loss: 35953401004.4261 - val_mean_absolute_error: 172736.3936\n",
      "Epoch 484/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 34982868194.8743 - mean_absolute_error: 171923.3440 - val_loss: 36160273953.4296 - val_mean_absolute_error: 173156.0605\n",
      "Epoch 485/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 35006554441.3618 - mean_absolute_error: 171997.7158 - val_loss: 36438162048.4399 - val_mean_absolute_error: 173957.0945\n",
      "Epoch 486/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 34919481739.9350 - mean_absolute_error: 171893.2621 - val_loss: 35664477891.2990 - val_mean_absolute_error: 172027.6945\n",
      "Epoch 487/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 34864035098.9358 - mean_absolute_error: 171795.7677 - val_loss: 36237607517.2509 - val_mean_absolute_error: 173471.1046\n",
      "Epoch 488/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 34872927062.9393 - mean_absolute_error: 171740.4669 - val_loss: 36025189844.0137 - val_mean_absolute_error: 172924.6690\n",
      "Epoch 489/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 34793529442.1078 - mean_absolute_error: 171551.7213 - val_loss: 35892592527.3952 - val_mean_absolute_error: 172707.6395\n",
      "Epoch 490/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 34883988966.1591 - mean_absolute_error: 171807.0803 - val_loss: 35969536696.7423 - val_mean_absolute_error: 172958.8896\n",
      "Epoch 491/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 34854816013.7964 - mean_absolute_error: 171695.8218 - val_loss: 36031289850.7216 - val_mean_absolute_error: 172962.1579\n",
      "Epoch 492/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 34831632932.3524 - mean_absolute_error: 171684.8262 - val_loss: 36268483693.0859 - val_mean_absolute_error: 173717.3332\n",
      "Epoch 493/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 34813099972.4346 - mean_absolute_error: 171646.3969 - val_loss: 35994840095.6701 - val_mean_absolute_error: 172612.3142\n",
      "Epoch 494/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 34746099839.8905 - mean_absolute_error: 171566.0714 - val_loss: 35997417162.3368 - val_mean_absolute_error: 172563.9559\n",
      "Epoch 495/5000\n",
      "1169/1169 [==============================] - 0s 386us/step - loss: 34755912372.0103 - mean_absolute_error: 171607.6120 - val_loss: 36110257732.6186 - val_mean_absolute_error: 172965.1349\n",
      "Epoch 496/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 34774042473.3345 - mean_absolute_error: 171510.8757 - val_loss: 36135470773.2234 - val_mean_absolute_error: 173114.0150\n",
      "Epoch 497/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 34772662862.3986 - mean_absolute_error: 171475.3916 - val_loss: 36100368918.8728 - val_mean_absolute_error: 173051.5090\n",
      "Epoch 498/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 34743409069.2216 - mean_absolute_error: 171487.0526 - val_loss: 36069488717.4158 - val_mean_absolute_error: 172991.4650\n",
      "Epoch 499/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 34717286902.8024 - mean_absolute_error: 171454.5171 - val_loss: 35657492733.3608 - val_mean_absolute_error: 171921.0174\n",
      "Epoch 500/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 34631576412.1950 - mean_absolute_error: 171241.1010 - val_loss: 35826262776.0825 - val_mean_absolute_error: 172438.9269\n",
      "Epoch 501/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 34744306247.3909 - mean_absolute_error: 171376.9626 - val_loss: 35940010582.2131 - val_mean_absolute_error: 172592.7501\n",
      "Epoch 502/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 34764562160.4517 - mean_absolute_error: 171403.6043 - val_loss: 35638562386.6942 - val_mean_absolute_error: 171972.1045\n",
      "Epoch 503/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 34762581544.7323 - mean_absolute_error: 171447.4718 - val_loss: 36206228279.4227 - val_mean_absolute_error: 173509.5965\n",
      "Epoch 504/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 34603171447.5689 - mean_absolute_error: 171215.4671 - val_loss: 35829698764.0962 - val_mean_absolute_error: 172527.1702\n",
      "Epoch 505/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 34664242061.2489 - mean_absolute_error: 171294.1455 - val_loss: 35930813957.2784 - val_mean_absolute_error: 172696.7887\n",
      "Epoch 506/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 34652273545.7451 - mean_absolute_error: 171315.0599 - val_loss: 35745619412.0137 - val_mean_absolute_error: 172214.0425\n",
      "Epoch 507/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 34622442929.6014 - mean_absolute_error: 171172.2866 - val_loss: 35521980042.9966 - val_mean_absolute_error: 171687.3635\n",
      "Epoch 508/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 34620885740.0719 - mean_absolute_error: 171243.2490 - val_loss: 35604876200.0275 - val_mean_absolute_error: 171794.5915\n",
      "Epoch 509/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 34570392823.8973 - mean_absolute_error: 171120.6935 - val_loss: 35763161242.8316 - val_mean_absolute_error: 172202.6450\n",
      "Epoch 510/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 34652700521.3345 - mean_absolute_error: 171210.7088 - val_loss: 35653781123.9588 - val_mean_absolute_error: 171815.8139\n",
      "Epoch 511/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 34542525051.9487 - mean_absolute_error: 171071.6162 - val_loss: 35773283064.0825 - val_mean_absolute_error: 172152.8596\n",
      "Epoch 512/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 34529607333.1189 - mean_absolute_error: 170997.0117 - val_loss: 35788973678.8454 - val_mean_absolute_error: 172230.7110\n",
      "Epoch 513/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 34624960801.0676 - mean_absolute_error: 171045.6427 - val_loss: 35885530361.8419 - val_mean_absolute_error: 172418.5753\n",
      "Epoch 514/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 34539428966.4876 - mean_absolute_error: 170990.6771 - val_loss: 35820470272.0000 - val_mean_absolute_error: 172190.4554\n",
      "Epoch 515/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 34514117515.4970 - mean_absolute_error: 170926.7797 - val_loss: 35722255103.1203 - val_mean_absolute_error: 172199.3300\n",
      "Epoch 516/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 34520678906.3062 - mean_absolute_error: 170875.6214 - val_loss: 35817218625.0997 - val_mean_absolute_error: 172403.2221\n",
      "Epoch 517/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 34572037366.1454 - mean_absolute_error: 170960.0062 - val_loss: 35760667440.3849 - val_mean_absolute_error: 172284.4337\n",
      "Epoch 518/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 34388927972.4072 - mean_absolute_error: 170730.6490 - val_loss: 35581767848.9072 - val_mean_absolute_error: 171828.4576\n",
      "Epoch 519/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 34452593985.4782 - mean_absolute_error: 170748.6539 - val_loss: 35592725282.3093 - val_mean_absolute_error: 171799.0642\n",
      "Epoch 520/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 34455235518.3028 - mean_absolute_error: 170780.1411 - val_loss: 35742478110.7904 - val_mean_absolute_error: 172157.0970\n",
      "Epoch 521/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 34379177969.9846 - mean_absolute_error: 170603.8703 - val_loss: 35753412410.9416 - val_mean_absolute_error: 172213.9380\n",
      "Epoch 522/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 34371418774.2275 - mean_absolute_error: 170625.1873 - val_loss: 35321513927.6976 - val_mean_absolute_error: 171106.6314\n",
      "Epoch 523/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 34446551336.0753 - mean_absolute_error: 170710.5275 - val_loss: 35620515396.6186 - val_mean_absolute_error: 171830.3610\n",
      "Epoch 524/5000\n",
      "1169/1169 [==============================] - 0s 388us/step - loss: 34406362754.0804 - mean_absolute_error: 170654.1791 - val_loss: 35281889716.3436 - val_mean_absolute_error: 170995.1700\n",
      "Epoch 525/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 34357924421.6390 - mean_absolute_error: 170529.8067 - val_loss: 35751419108.7285 - val_mean_absolute_error: 172242.2017\n",
      "Epoch 526/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 34334158388.9957 - mean_absolute_error: 170518.1348 - val_loss: 35736645702.3780 - val_mean_absolute_error: 172298.3890\n",
      "Epoch 527/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 34418915709.9196 - mean_absolute_error: 170478.0923 - val_loss: 35653040578.4192 - val_mean_absolute_error: 171896.2910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 34255815099.2370 - mean_absolute_error: 170305.9055 - val_loss: 35517639247.1753 - val_mean_absolute_error: 171623.6028\n",
      "Epoch 529/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 34272211462.5697 - mean_absolute_error: 170311.6671 - val_loss: 36093473084.7010 - val_mean_absolute_error: 172967.2048\n",
      "Epoch 530/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 34245651877.3379 - mean_absolute_error: 170317.3800 - val_loss: 35748517001.2371 - val_mean_absolute_error: 172310.4480\n",
      "Epoch 531/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 34238148471.3499 - mean_absolute_error: 170317.5821 - val_loss: 35400062750.7904 - val_mean_absolute_error: 171331.2041\n",
      "Epoch 532/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 34309990107.4286 - mean_absolute_error: 170423.9146 - val_loss: 35464290325.1134 - val_mean_absolute_error: 171326.4561\n",
      "Epoch 533/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 34173611131.5107 - mean_absolute_error: 170164.1475 - val_loss: 35573389734.2680 - val_mean_absolute_error: 171619.1988\n",
      "Epoch 534/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 34266885858.4363 - mean_absolute_error: 170265.6313 - val_loss: 35368053735.3677 - val_mean_absolute_error: 171153.0858\n",
      "Epoch 535/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 34172879517.2352 - mean_absolute_error: 170178.8050 - val_loss: 35339858778.6117 - val_mean_absolute_error: 171310.7292\n",
      "Epoch 536/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 34275899379.7365 - mean_absolute_error: 170245.1554 - val_loss: 35657788377.2921 - val_mean_absolute_error: 172058.1551\n",
      "Epoch 537/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 34147555315.7365 - mean_absolute_error: 169994.4645 - val_loss: 35597858703.3952 - val_mean_absolute_error: 171928.6901\n",
      "Epoch 538/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 34091942497.6698 - mean_absolute_error: 170045.8317 - val_loss: 35130525625.6220 - val_mean_absolute_error: 170501.9246\n",
      "Epoch 539/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 34092438672.5338 - mean_absolute_error: 169934.1855 - val_loss: 35596057969.4845 - val_mean_absolute_error: 171696.0848\n",
      "Epoch 540/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 34185906535.1446 - mean_absolute_error: 170121.7510 - val_loss: 35439632939.9863 - val_mean_absolute_error: 171213.0205\n",
      "Epoch 541/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 34127519255.2130 - mean_absolute_error: 170043.1876 - val_loss: 34363621298.5842 - val_mean_absolute_error: 168644.3819\n",
      "Epoch 542/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 34078827685.5569 - mean_absolute_error: 169992.6699 - val_loss: 35169970647.5326 - val_mean_absolute_error: 170563.6975\n",
      "Epoch 543/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 34019529178.7716 - mean_absolute_error: 169879.2963 - val_loss: 35286497209.6220 - val_mean_absolute_error: 170858.1610\n",
      "Epoch 544/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 34027503156.9957 - mean_absolute_error: 169770.4765 - val_loss: 35123311007.2302 - val_mean_absolute_error: 170556.2118\n",
      "Epoch 545/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 33982445907.8734 - mean_absolute_error: 169616.0752 - val_loss: 34764827137.7595 - val_mean_absolute_error: 169770.4862\n",
      "Epoch 546/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 34078069086.3849 - mean_absolute_error: 169842.7165 - val_loss: 35148287873.3196 - val_mean_absolute_error: 170849.3855\n",
      "Epoch 547/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 34027393195.6886 - mean_absolute_error: 169791.3366 - val_loss: 34923541993.1272 - val_mean_absolute_error: 170116.6712\n",
      "Epoch 548/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 34009960553.1155 - mean_absolute_error: 169699.9334 - val_loss: 35253809996.5361 - val_mean_absolute_error: 170916.0083\n",
      "Epoch 549/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 34004590066.4226 - mean_absolute_error: 169713.2742 - val_loss: 35126734953.5670 - val_mean_absolute_error: 170594.7445\n",
      "Epoch 550/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 34043143496.4859 - mean_absolute_error: 169862.5535 - val_loss: 35174167872.2199 - val_mean_absolute_error: 170608.9283\n",
      "Epoch 551/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 34000413113.4850 - mean_absolute_error: 169647.6466 - val_loss: 35629194968.4124 - val_mean_absolute_error: 171560.9560\n",
      "Epoch 552/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 33974972927.5620 - mean_absolute_error: 169671.1477 - val_loss: 35069352893.1409 - val_mean_absolute_error: 170365.1008\n",
      "Epoch 553/5000\n",
      "1169/1169 [==============================] - 0s 305us/step - loss: 33865051371.6339 - mean_absolute_error: 169509.5420 - val_loss: 35480226397.2509 - val_mean_absolute_error: 171455.8532\n",
      "Epoch 554/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 33973667878.5423 - mean_absolute_error: 169652.8575 - val_loss: 35203688609.8694 - val_mean_absolute_error: 170762.9236\n",
      "Epoch 555/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 33894833152.8760 - mean_absolute_error: 169408.3005 - val_loss: 34906540046.0756 - val_mean_absolute_error: 170091.6752\n",
      "Epoch 556/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 33796085600.5748 - mean_absolute_error: 169350.9195 - val_loss: 34636516425.8969 - val_mean_absolute_error: 169445.3306\n",
      "Epoch 557/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 33922094418.9974 - mean_absolute_error: 169551.9659 - val_loss: 35182076262.9278 - val_mean_absolute_error: 170766.9906\n",
      "Epoch 558/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 33814943787.7981 - mean_absolute_error: 169250.4795 - val_loss: 34880238046.5704 - val_mean_absolute_error: 169970.7851\n",
      "Epoch 559/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 33813933839.9863 - mean_absolute_error: 169356.1738 - val_loss: 34934384140.3162 - val_mean_absolute_error: 170028.6339\n",
      "Epoch 560/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 33733323974.8435 - mean_absolute_error: 169210.3090 - val_loss: 35056464955.8213 - val_mean_absolute_error: 170496.5805\n",
      "Epoch 561/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 33826791851.4696 - mean_absolute_error: 169286.6155 - val_loss: 35051114643.7938 - val_mean_absolute_error: 170181.8757\n",
      "Epoch 562/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 33707791310.0701 - mean_absolute_error: 169027.4936 - val_loss: 34785649034.1168 - val_mean_absolute_error: 169737.0703\n",
      "Epoch 563/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 33847739888.6707 - mean_absolute_error: 169323.9323 - val_loss: 34812539689.3471 - val_mean_absolute_error: 169843.0403\n",
      "Epoch 564/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 33698405587.1069 - mean_absolute_error: 169074.0878 - val_loss: 34825340618.3368 - val_mean_absolute_error: 169835.3364\n",
      "Epoch 565/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 33752235553.7246 - mean_absolute_error: 169148.3000 - val_loss: 34796552698.7216 - val_mean_absolute_error: 169955.9284\n",
      "Epoch 566/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 33736123464.7049 - mean_absolute_error: 169158.8849 - val_loss: 35302629650.4742 - val_mean_absolute_error: 171152.5429\n",
      "Epoch 567/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 33707850717.8375 - mean_absolute_error: 169032.4134 - val_loss: 35030123847.2577 - val_mean_absolute_error: 170385.6490\n",
      "Epoch 568/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 33796671654.4328 - mean_absolute_error: 169030.6594 - val_loss: 35062821265.1546 - val_mean_absolute_error: 170766.7682\n",
      "Epoch 569/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 33655804653.8238 - mean_absolute_error: 169010.2983 - val_loss: 35149656676.2887 - val_mean_absolute_error: 170924.4565\n",
      "Epoch 570/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 33647405949.4816 - mean_absolute_error: 168835.2222 - val_loss: 35144632010.3368 - val_mean_absolute_error: 170739.1510\n",
      "Epoch 571/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 33608183888.5885 - mean_absolute_error: 168847.6568 - val_loss: 34650987242.0069 - val_mean_absolute_error: 169601.0976\n",
      "Epoch 572/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 33672557749.3242 - mean_absolute_error: 168969.3120 - val_loss: 34854270497.4296 - val_mean_absolute_error: 169928.3028\n",
      "Epoch 573/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 33618501581.1942 - mean_absolute_error: 168652.3521 - val_loss: 34782036981.4433 - val_mean_absolute_error: 169624.0270\n",
      "Epoch 574/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 33653741941.1600 - mean_absolute_error: 168848.4654 - val_loss: 34577112813.5258 - val_mean_absolute_error: 169280.1254\n",
      "Epoch 575/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 33555464770.1352 - mean_absolute_error: 168695.4224 - val_loss: 34805604907.9863 - val_mean_absolute_error: 169770.7503\n",
      "Epoch 576/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 33520676545.1497 - mean_absolute_error: 168580.5497 - val_loss: 34733617109.7732 - val_mean_absolute_error: 169576.8070\n",
      "Epoch 577/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 33550753588.7767 - mean_absolute_error: 168590.4498 - val_loss: 34881567149.3058 - val_mean_absolute_error: 169881.5852\n",
      "Epoch 578/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 33481402622.9050 - mean_absolute_error: 168600.1483 - val_loss: 34981533104.8247 - val_mean_absolute_error: 170124.4866\n",
      "Epoch 579/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 33586253063.6647 - mean_absolute_error: 168560.4018 - val_loss: 34604570968.8522 - val_mean_absolute_error: 169053.4588\n",
      "Epoch 580/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 33459649372.1950 - mean_absolute_error: 168438.1819 - val_loss: 34272195573.4433 - val_mean_absolute_error: 168373.0610\n",
      "Epoch 581/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 33549159256.6912 - mean_absolute_error: 168508.4524 - val_loss: 34791356401.9244 - val_mean_absolute_error: 169796.7132\n",
      "Epoch 582/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 33455275979.4423 - mean_absolute_error: 168361.7403 - val_loss: 34414234205.2509 - val_mean_absolute_error: 169066.3896\n",
      "Epoch 583/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 33455969249.3413 - mean_absolute_error: 168432.5015 - val_loss: 34910481503.0103 - val_mean_absolute_error: 170126.0084\n",
      "Epoch 584/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 33452113914.7442 - mean_absolute_error: 168421.3540 - val_loss: 34731784705.7595 - val_mean_absolute_error: 169883.3067\n",
      "Epoch 585/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 33455473277.7006 - mean_absolute_error: 168382.3758 - val_loss: 34272412879.6151 - val_mean_absolute_error: 168585.4092\n",
      "Epoch 586/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 33387374450.0941 - mean_absolute_error: 168330.7498 - val_loss: 34256075638.7629 - val_mean_absolute_error: 168353.8608\n",
      "Epoch 587/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 33354665941.9538 - mean_absolute_error: 168214.1443 - val_loss: 34847884228.1787 - val_mean_absolute_error: 169962.8310\n",
      "Epoch 588/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 33324201306.0051 - mean_absolute_error: 168084.1369 - val_loss: 34767368382.0206 - val_mean_absolute_error: 169868.4897\n",
      "Epoch 589/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 33308638820.2977 - mean_absolute_error: 168129.8760 - val_loss: 34594558092.7560 - val_mean_absolute_error: 169412.3324\n",
      "Epoch 590/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 33251815536.1232 - mean_absolute_error: 168060.5160 - val_loss: 34433848520.5773 - val_mean_absolute_error: 169051.6952\n",
      "Epoch 591/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 33341672371.7913 - mean_absolute_error: 168194.6272 - val_loss: 34264604369.3746 - val_mean_absolute_error: 168426.7501\n",
      "Epoch 592/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 33297102674.5594 - mean_absolute_error: 167939.4334 - val_loss: 34187566435.4089 - val_mean_absolute_error: 168315.0495\n",
      "Epoch 593/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 33281469141.2968 - mean_absolute_error: 168060.3864 - val_loss: 34249554370.4192 - val_mean_absolute_error: 168527.6070\n",
      "Epoch 594/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 33261291406.1249 - mean_absolute_error: 167971.5868 - val_loss: 34978730877.8007 - val_mean_absolute_error: 170168.1756\n",
      "Epoch 595/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 33211935201.7793 - mean_absolute_error: 167862.2736 - val_loss: 34413756064.1100 - val_mean_absolute_error: 168793.1889\n",
      "Epoch 596/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 33223274072.0342 - mean_absolute_error: 167894.9772 - val_loss: 34455639775.4502 - val_mean_absolute_error: 168997.5628\n",
      "Epoch 597/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 33308422525.9196 - mean_absolute_error: 168087.1254 - val_loss: 34783206741.3333 - val_mean_absolute_error: 169936.2729\n",
      "Epoch 598/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 33181827954.9701 - mean_absolute_error: 167792.9003 - val_loss: 34467302551.3127 - val_mean_absolute_error: 168917.1334\n",
      "Epoch 599/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 33179963052.1266 - mean_absolute_error: 167742.7385 - val_loss: 34362700803.5189 - val_mean_absolute_error: 168716.6865\n",
      "Epoch 600/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 33134165528.9649 - mean_absolute_error: 167631.3202 - val_loss: 35090093960.3574 - val_mean_absolute_error: 170711.6031\n",
      "Epoch 601/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 33158169779.5723 - mean_absolute_error: 167682.3609 - val_loss: 34567207080.9072 - val_mean_absolute_error: 168976.8201\n",
      "Epoch 602/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 32983067468.4277 - mean_absolute_error: 167314.5533 - val_loss: 34137119093.0034 - val_mean_absolute_error: 168053.0771\n",
      "Epoch 603/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 33146582060.6741 - mean_absolute_error: 167580.3962 - val_loss: 34503827829.0034 - val_mean_absolute_error: 168971.5354\n",
      "Epoch 604/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 33065705058.5458 - mean_absolute_error: 167490.2432 - val_loss: 34264258925.9656 - val_mean_absolute_error: 168595.4632\n",
      "Epoch 605/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 33050315761.1086 - mean_absolute_error: 167514.1201 - val_loss: 34404941831.0378 - val_mean_absolute_error: 168852.2869\n",
      "Epoch 606/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 33063648982.1728 - mean_absolute_error: 167431.4021 - val_loss: 34769264091.0515 - val_mean_absolute_error: 169742.2044\n",
      "Epoch 607/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 33104592536.8554 - mean_absolute_error: 167509.2035 - val_loss: 34119064818.8041 - val_mean_absolute_error: 168015.1778\n",
      "Epoch 608/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 32942379566.8640 - mean_absolute_error: 167345.1978 - val_loss: 34517086954.0069 - val_mean_absolute_error: 168995.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 33102691544.3627 - mean_absolute_error: 167556.5411 - val_loss: 34335455414.9828 - val_mean_absolute_error: 168530.3639\n",
      "Epoch 610/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 33025442695.9932 - mean_absolute_error: 167322.9382 - val_loss: 34374322232.3024 - val_mean_absolute_error: 168637.0328\n",
      "Epoch 611/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 32888590423.5962 - mean_absolute_error: 167094.5311 - val_loss: 34170824478.7904 - val_mean_absolute_error: 168219.0150\n",
      "Epoch 612/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 32964578111.2883 - mean_absolute_error: 167248.4068 - val_loss: 34299119883.4364 - val_mean_absolute_error: 168518.1213\n",
      "Epoch 613/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 32887231592.2395 - mean_absolute_error: 167130.6880 - val_loss: 34235587918.2955 - val_mean_absolute_error: 168407.1101\n",
      "Epoch 614/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 32979398810.1694 - mean_absolute_error: 167267.2017 - val_loss: 33901113773.3058 - val_mean_absolute_error: 167414.2454\n",
      "Epoch 615/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 32935217409.5329 - mean_absolute_error: 167121.9150 - val_loss: 34083581424.1649 - val_mean_absolute_error: 167975.3750\n",
      "Epoch 616/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 32819712537.8409 - mean_absolute_error: 167098.7452 - val_loss: 34427073975.8625 - val_mean_absolute_error: 168655.9975\n",
      "Epoch 617/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 32881212269.7143 - mean_absolute_error: 167064.6188 - val_loss: 34250425087.1203 - val_mean_absolute_error: 168306.0732\n",
      "Epoch 618/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 32826082134.9393 - mean_absolute_error: 166963.6945 - val_loss: 33825989332.8935 - val_mean_absolute_error: 167196.4547\n",
      "Epoch 619/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 32763471863.2404 - mean_absolute_error: 166805.2158 - val_loss: 34625733642.5567 - val_mean_absolute_error: 169265.7414\n",
      "Epoch 620/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 32823067846.8435 - mean_absolute_error: 166874.7550 - val_loss: 33759264690.5842 - val_mean_absolute_error: 167235.1248\n",
      "Epoch 621/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 32837002967.9247 - mean_absolute_error: 167014.5562 - val_loss: 34034295579.2715 - val_mean_absolute_error: 167888.1138\n",
      "Epoch 622/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 32667955468.0445 - mean_absolute_error: 166633.3485 - val_loss: 34429680115.6838 - val_mean_absolute_error: 168635.4784\n",
      "Epoch 623/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 32734267439.3020 - mean_absolute_error: 166716.9066 - val_loss: 34135750993.8144 - val_mean_absolute_error: 168130.0895\n",
      "Epoch 624/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 32788776907.4423 - mean_absolute_error: 166711.1356 - val_loss: 33812807060.6735 - val_mean_absolute_error: 167277.3784\n",
      "Epoch 625/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 32680183471.6305 - mean_absolute_error: 166561.6862 - val_loss: 33781502029.4158 - val_mean_absolute_error: 167175.0446\n",
      "Epoch 626/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 32699545883.8118 - mean_absolute_error: 166636.4908 - val_loss: 34202407200.5498 - val_mean_absolute_error: 168108.1070\n",
      "Epoch 627/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 32635093955.5586 - mean_absolute_error: 166598.1782 - val_loss: 34285846464.6598 - val_mean_absolute_error: 168367.8577\n",
      "Epoch 628/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 32584821494.5834 - mean_absolute_error: 166428.1205 - val_loss: 33403879008.7698 - val_mean_absolute_error: 166301.7880\n",
      "Epoch 629/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 32545813730.8743 - mean_absolute_error: 166489.6263 - val_loss: 33302264096.5498 - val_mean_absolute_error: 165939.6218\n",
      "Epoch 630/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 32600410380.0445 - mean_absolute_error: 166421.5863 - val_loss: 34182773545.3471 - val_mean_absolute_error: 168258.4521\n",
      "Epoch 631/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 32641307412.3661 - mean_absolute_error: 166515.1772 - val_loss: 33776868784.8247 - val_mean_absolute_error: 167043.1548\n",
      "Epoch 632/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 32579913221.6938 - mean_absolute_error: 166383.3506 - val_loss: 33479199810.8591 - val_mean_absolute_error: 166473.1709\n",
      "Epoch 633/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 32670593924.4893 - mean_absolute_error: 166480.4922 - val_loss: 34295805593.0722 - val_mean_absolute_error: 168593.8628\n",
      "Epoch 634/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 32567751665.1086 - mean_absolute_error: 166300.1418 - val_loss: 34034360988.5911 - val_mean_absolute_error: 167900.1255\n",
      "Epoch 635/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 32540385416.6501 - mean_absolute_error: 166270.6670 - val_loss: 33468389467.4914 - val_mean_absolute_error: 166453.6132\n",
      "Epoch 636/5000\n",
      "1169/1169 [==============================] - 0s 393us/step - loss: 32571219568.5612 - mean_absolute_error: 166151.7322 - val_loss: 33953688361.3471 - val_mean_absolute_error: 167743.9433\n",
      "Epoch 637/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 32506984446.2481 - mean_absolute_error: 166172.5347 - val_loss: 33746292813.4158 - val_mean_absolute_error: 167157.2225\n",
      "Epoch 638/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 32469781743.1377 - mean_absolute_error: 166132.3843 - val_loss: 34153363962.7217 - val_mean_absolute_error: 168306.3347\n",
      "Epoch 639/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 32558016331.5518 - mean_absolute_error: 166231.0536 - val_loss: 33862003455.1203 - val_mean_absolute_error: 167725.2820\n",
      "Epoch 640/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 32571130472.6775 - mean_absolute_error: 166144.4241 - val_loss: 33581597579.8763 - val_mean_absolute_error: 166829.1472\n",
      "Epoch 641/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 32392948892.7973 - mean_absolute_error: 165864.7085 - val_loss: 33703822881.4296 - val_mean_absolute_error: 167044.7240\n",
      "Epoch 642/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 32455521512.1300 - mean_absolute_error: 166032.4145 - val_loss: 33385545425.3746 - val_mean_absolute_error: 166542.3261\n",
      "Epoch 643/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 32456787339.0590 - mean_absolute_error: 165972.0638 - val_loss: 34087489697.8694 - val_mean_absolute_error: 168323.4182\n",
      "Epoch 644/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 32525934693.6116 - mean_absolute_error: 166094.8439 - val_loss: 33122316893.2509 - val_mean_absolute_error: 165503.3710\n",
      "Epoch 645/5000\n",
      "1169/1169 [==============================] - 0s 414us/step - loss: 32402662258.9701 - mean_absolute_error: 165959.6742 - val_loss: 33209983004.1512 - val_mean_absolute_error: 165863.8463\n",
      "Epoch 646/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 32347827807.0419 - mean_absolute_error: 165777.3942 - val_loss: 33923576321.7594 - val_mean_absolute_error: 167711.1256\n",
      "Epoch 647/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 32424140458.3747 - mean_absolute_error: 165871.0141 - val_loss: 33444438705.7045 - val_mean_absolute_error: 166417.7598\n",
      "Epoch 648/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 32238383501.6869 - mean_absolute_error: 165709.3475 - val_loss: 33754154444.9759 - val_mean_absolute_error: 167213.4818\n",
      "Epoch 649/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 32433383033.3208 - mean_absolute_error: 165906.9237 - val_loss: 33462977940.6735 - val_mean_absolute_error: 166531.8965\n",
      "Epoch 650/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 32383814681.4029 - mean_absolute_error: 165814.9524 - val_loss: 33492442002.9141 - val_mean_absolute_error: 166443.2099\n",
      "Epoch 651/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 32285977551.8221 - mean_absolute_error: 165632.0867 - val_loss: 33676612900.0687 - val_mean_absolute_error: 166811.5003\n",
      "Epoch 652/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 32320020056.0342 - mean_absolute_error: 165524.0306 - val_loss: 33569510875.0515 - val_mean_absolute_error: 166682.5755\n",
      "Epoch 653/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 32351200731.6476 - mean_absolute_error: 165642.2628 - val_loss: 33820316555.8763 - val_mean_absolute_error: 167237.8208\n",
      "Epoch 654/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 32066076223.5073 - mean_absolute_error: 165359.0877 - val_loss: 33640062532.6186 - val_mean_absolute_error: 166934.9333\n",
      "Epoch 655/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 32273430561.2866 - mean_absolute_error: 165642.7453 - val_loss: 33230365593.9519 - val_mean_absolute_error: 165839.4188\n",
      "Epoch 656/5000\n",
      "1169/1169 [==============================] - 0s 316us/step - loss: 32085957744.9991 - mean_absolute_error: 165206.1353 - val_loss: 33732729817.2921 - val_mean_absolute_error: 167366.1825\n",
      "Epoch 657/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 32156231030.0359 - mean_absolute_error: 165264.9334 - val_loss: 33981706261.1134 - val_mean_absolute_error: 167878.1523\n",
      "Epoch 658/5000\n",
      "1169/1169 [==============================] - 0s 301us/step - loss: 32237335551.1240 - mean_absolute_error: 165395.1553 - val_loss: 33775628597.6632 - val_mean_absolute_error: 167165.7401\n",
      "Epoch 659/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 32095402047.0693 - mean_absolute_error: 165283.4987 - val_loss: 33982061684.1237 - val_mean_absolute_error: 167653.2335\n",
      "Epoch 660/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 32025631012.5714 - mean_absolute_error: 165034.7102 - val_loss: 33503213722.8316 - val_mean_absolute_error: 166853.5409\n",
      "Epoch 661/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 31953364233.4166 - mean_absolute_error: 164883.1628 - val_loss: 33146127103.1203 - val_mean_absolute_error: 165683.2910\n",
      "Epoch 662/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 32096005436.2224 - mean_absolute_error: 165304.9438 - val_loss: 33203868738.8591 - val_mean_absolute_error: 166041.5026\n",
      "Epoch 663/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 32013064283.1001 - mean_absolute_error: 165083.7059 - val_loss: 33286370814.2406 - val_mean_absolute_error: 166136.2107\n",
      "Epoch 664/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 32100225045.0231 - mean_absolute_error: 165093.6230 - val_loss: 32989852013.9656 - val_mean_absolute_error: 165043.3380\n",
      "Epoch 665/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 32009635682.3268 - mean_absolute_error: 164920.2099 - val_loss: 32658242162.3643 - val_mean_absolute_error: 164462.1675\n",
      "Epoch 666/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 31965130776.5269 - mean_absolute_error: 164794.3143 - val_loss: 33329037516.0962 - val_mean_absolute_error: 166166.7801\n",
      "Epoch 667/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 32054471591.5278 - mean_absolute_error: 164968.0268 - val_loss: 33199002704.9347 - val_mean_absolute_error: 165695.1876\n",
      "Epoch 668/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 32070089210.3062 - mean_absolute_error: 164905.6858 - val_loss: 33407209514.2268 - val_mean_absolute_error: 166331.4333\n",
      "Epoch 669/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 31796456189.5911 - mean_absolute_error: 164698.4468 - val_loss: 33730030081.7594 - val_mean_absolute_error: 167280.8091\n",
      "Epoch 670/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 32022509657.3482 - mean_absolute_error: 165013.6190 - val_loss: 33395057013.0034 - val_mean_absolute_error: 166193.7251\n",
      "Epoch 671/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 31892502107.5381 - mean_absolute_error: 164662.8554 - val_loss: 33746462100.6735 - val_mean_absolute_error: 167218.2489\n",
      "Epoch 672/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 31896471240.1574 - mean_absolute_error: 164639.1168 - val_loss: 33496028832.1100 - val_mean_absolute_error: 166361.0738\n",
      "Epoch 673/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 31751515557.3379 - mean_absolute_error: 164370.3167 - val_loss: 33250815169.5395 - val_mean_absolute_error: 165990.2990\n",
      "Epoch 674/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 31818714370.4089 - mean_absolute_error: 164507.5176 - val_loss: 33586496184.7423 - val_mean_absolute_error: 166727.4022\n",
      "Epoch 675/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 31932730092.0719 - mean_absolute_error: 164539.2842 - val_loss: 32971458095.5052 - val_mean_absolute_error: 165321.9793\n",
      "Epoch 676/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 31902394332.9615 - mean_absolute_error: 164623.7349 - val_loss: 32836108288.0000 - val_mean_absolute_error: 164899.7153\n",
      "Epoch 677/5000\n",
      "1169/1169 [==============================] - 0s 395us/step - loss: 31699069576.2121 - mean_absolute_error: 164288.7526 - val_loss: 33287257436.3711 - val_mean_absolute_error: 165853.4509\n",
      "Epoch 678/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 31795824939.5791 - mean_absolute_error: 164459.3432 - val_loss: 33341383866.5017 - val_mean_absolute_error: 165906.9126\n",
      "Epoch 679/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 31662734385.9299 - mean_absolute_error: 164284.6788 - val_loss: 33235376930.3093 - val_mean_absolute_error: 165649.6380\n",
      "Epoch 680/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 31747888656.2053 - mean_absolute_error: 164332.0273 - val_loss: 33147763384.7423 - val_mean_absolute_error: 165530.5827\n",
      "Epoch 681/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 31737226039.4046 - mean_absolute_error: 164405.1917 - val_loss: 32793896903.6976 - val_mean_absolute_error: 164791.1065\n",
      "Epoch 682/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 31712715734.8298 - mean_absolute_error: 164137.4050 - val_loss: 33015012601.8419 - val_mean_absolute_error: 165248.8281\n",
      "Epoch 683/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 31673982865.6287 - mean_absolute_error: 164114.8907 - val_loss: 33139391111.4777 - val_mean_absolute_error: 165496.4551\n",
      "Epoch 684/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 31660556761.0197 - mean_absolute_error: 164007.4287 - val_loss: 32137473140.1237 - val_mean_absolute_error: 163067.4722\n",
      "Epoch 685/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 31699935631.4388 - mean_absolute_error: 164265.5151 - val_loss: 32617771613.2509 - val_mean_absolute_error: 164183.2721\n",
      "Epoch 686/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 31607850619.0727 - mean_absolute_error: 163932.7335 - val_loss: 32580628029.5808 - val_mean_absolute_error: 164211.5951\n",
      "Epoch 687/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 31529273696.1369 - mean_absolute_error: 163839.1081 - val_loss: 33178759245.4158 - val_mean_absolute_error: 165763.3305\n",
      "Epoch 688/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 31692573413.0642 - mean_absolute_error: 164051.1494 - val_loss: 33123119835.9313 - val_mean_absolute_error: 165565.7793\n",
      "Epoch 689/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 31615329293.1394 - mean_absolute_error: 163933.8652 - val_loss: 33280985517.3058 - val_mean_absolute_error: 165937.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 690/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 31643258328.1437 - mean_absolute_error: 164011.7580 - val_loss: 33115043769.6220 - val_mean_absolute_error: 165423.7873\n",
      "Epoch 691/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 31403188679.5004 - mean_absolute_error: 163487.8184 - val_loss: 32483890404.7285 - val_mean_absolute_error: 163675.3293\n",
      "Epoch 692/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 31438112776.7596 - mean_absolute_error: 163626.3819 - val_loss: 32534898779.4914 - val_mean_absolute_error: 163863.2307\n",
      "Epoch 693/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 31567615076.7357 - mean_absolute_error: 164049.1774 - val_loss: 32766946448.2749 - val_mean_absolute_error: 164722.1911\n",
      "Epoch 694/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 31665998305.7793 - mean_absolute_error: 163768.3940 - val_loss: 33078152195.5189 - val_mean_absolute_error: 165286.6618\n",
      "Epoch 695/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 31443707576.3901 - mean_absolute_error: 163461.9358 - val_loss: 32654091626.4467 - val_mean_absolute_error: 164499.7764\n",
      "Epoch 696/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 31504683470.5081 - mean_absolute_error: 163796.2653 - val_loss: 32640817489.8144 - val_mean_absolute_error: 164202.3620\n",
      "Epoch 697/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 31276292491.0590 - mean_absolute_error: 163178.3428 - val_loss: 33030221028.7285 - val_mean_absolute_error: 165145.4084\n",
      "Epoch 698/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 31444467866.1694 - mean_absolute_error: 163773.5789 - val_loss: 32330150366.5704 - val_mean_absolute_error: 163594.7149\n",
      "Epoch 699/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 31204926769.7109 - mean_absolute_error: 163110.1963 - val_loss: 32890472954.7217 - val_mean_absolute_error: 165020.1500\n",
      "Epoch 700/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 31333682733.9880 - mean_absolute_error: 163434.0847 - val_loss: 33052648254.4605 - val_mean_absolute_error: 165282.0758\n",
      "Epoch 701/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 31470529599.9453 - mean_absolute_error: 163520.9625 - val_loss: 32507496201.6770 - val_mean_absolute_error: 163860.7484\n",
      "Epoch 702/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 31255739147.6065 - mean_absolute_error: 163314.2219 - val_loss: 33272860826.8316 - val_mean_absolute_error: 166005.0363\n",
      "Epoch 703/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 31288085813.2147 - mean_absolute_error: 163082.7672 - val_loss: 33284775992.3024 - val_mean_absolute_error: 165768.4127\n",
      "Epoch 704/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 31393942600.7049 - mean_absolute_error: 163299.6768 - val_loss: 33292821451.2165 - val_mean_absolute_error: 165988.8544\n",
      "Epoch 705/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 31499710807.3772 - mean_absolute_error: 163470.9232 - val_loss: 32868597633.3196 - val_mean_absolute_error: 164808.4670\n",
      "Epoch 706/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 31233245967.1104 - mean_absolute_error: 163056.7998 - val_loss: 32855698266.6117 - val_mean_absolute_error: 164741.6823\n",
      "Epoch 707/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 31212259187.8460 - mean_absolute_error: 163000.5241 - val_loss: 32276999973.8282 - val_mean_absolute_error: 163354.3380\n",
      "Epoch 708/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 31388482685.2626 - mean_absolute_error: 163391.4411 - val_loss: 32617963752.2474 - val_mean_absolute_error: 164223.9354\n",
      "Epoch 709/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 31183038125.8785 - mean_absolute_error: 162932.8348 - val_loss: 31748420625.5945 - val_mean_absolute_error: 162130.8236\n",
      "Epoch 710/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 31214931109.5569 - mean_absolute_error: 162958.5626 - val_loss: 32874777146.0619 - val_mean_absolute_error: 164702.2519\n",
      "Epoch 711/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 31246467954.9701 - mean_absolute_error: 162920.3368 - val_loss: 32285615079.3677 - val_mean_absolute_error: 163308.6376\n",
      "Epoch 712/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 31217343182.2891 - mean_absolute_error: 162862.1452 - val_loss: 32303239477.6632 - val_mean_absolute_error: 163327.8469\n",
      "Epoch 713/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 31093992802.7648 - mean_absolute_error: 162678.4578 - val_loss: 32250676375.3127 - val_mean_absolute_error: 163440.4504\n",
      "Epoch 714/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 31052303026.2583 - mean_absolute_error: 162546.7340 - val_loss: 32829861233.4845 - val_mean_absolute_error: 164672.9497\n",
      "Epoch 715/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 31112045828.1608 - mean_absolute_error: 162640.5085 - val_loss: 32456658986.2268 - val_mean_absolute_error: 163828.9531\n",
      "Epoch 716/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 31068547448.6638 - mean_absolute_error: 162583.9594 - val_loss: 31854070597.4983 - val_mean_absolute_error: 162478.3802\n",
      "Epoch 717/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 31099257671.1719 - mean_absolute_error: 162615.2752 - val_loss: 32047825599.7801 - val_mean_absolute_error: 162967.9294\n",
      "Epoch 718/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 31063080515.0111 - mean_absolute_error: 162777.4708 - val_loss: 32128683926.4330 - val_mean_absolute_error: 163033.3431\n",
      "Epoch 719/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 31003478897.2181 - mean_absolute_error: 162440.9825 - val_loss: 31743317889.3196 - val_mean_absolute_error: 162051.0541\n",
      "Epoch 720/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 31065207099.3465 - mean_absolute_error: 162519.9953 - val_loss: 32330953168.4948 - val_mean_absolute_error: 163547.7443\n",
      "Epoch 721/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 30890821434.9085 - mean_absolute_error: 162297.1937 - val_loss: 32441017629.0309 - val_mean_absolute_error: 163912.5039\n",
      "Epoch 722/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 30980419212.5920 - mean_absolute_error: 162291.6303 - val_loss: 32681723073.5395 - val_mean_absolute_error: 164549.7803\n",
      "Epoch 723/5000\n",
      "1169/1169 [==============================] - 0s 384us/step - loss: 31091181969.1908 - mean_absolute_error: 162755.8313 - val_loss: 32001355248.1649 - val_mean_absolute_error: 162948.2472\n",
      "Epoch 724/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 30892703165.8648 - mean_absolute_error: 162121.1117 - val_loss: 32066807357.5808 - val_mean_absolute_error: 163095.9639\n",
      "Epoch 725/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 30932757943.7331 - mean_absolute_error: 162263.5027 - val_loss: 32315311691.6564 - val_mean_absolute_error: 163830.0089\n",
      "Epoch 726/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 30978497477.3105 - mean_absolute_error: 162494.8174 - val_loss: 32058504962.6392 - val_mean_absolute_error: 163031.3294\n",
      "Epoch 727/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 30884744802.5458 - mean_absolute_error: 162146.1518 - val_loss: 32113966569.1272 - val_mean_absolute_error: 162785.7778\n",
      "Epoch 728/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 31058587833.7040 - mean_absolute_error: 162257.5865 - val_loss: 32016102959.5052 - val_mean_absolute_error: 162438.0297\n",
      "Epoch 729/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 30811199267.2575 - mean_absolute_error: 161926.6794 - val_loss: 32315067177.3471 - val_mean_absolute_error: 163163.8887\n",
      "Epoch 730/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 30788074552.9376 - mean_absolute_error: 161868.8016 - val_loss: 31486333758.4605 - val_mean_absolute_error: 161262.3225\n",
      "Epoch 731/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 30739446811.1548 - mean_absolute_error: 161846.8272 - val_loss: 31850944800.5498 - val_mean_absolute_error: 162284.9367\n",
      "Epoch 732/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 30606546945.7519 - mean_absolute_error: 161570.4305 - val_loss: 31957939907.2990 - val_mean_absolute_error: 162710.1963\n",
      "Epoch 733/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 30888077071.1104 - mean_absolute_error: 162130.8076 - val_loss: 32331781637.2783 - val_mean_absolute_error: 163334.6867\n",
      "Epoch 734/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 30756688250.4157 - mean_absolute_error: 161730.4940 - val_loss: 31855654102.6529 - val_mean_absolute_error: 162243.6897\n",
      "Epoch 735/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 30616931195.7297 - mean_absolute_error: 161557.6081 - val_loss: 31893336232.9072 - val_mean_absolute_error: 162353.7877\n",
      "Epoch 736/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 30686572656.1232 - mean_absolute_error: 161675.8701 - val_loss: 31668900747.8763 - val_mean_absolute_error: 161740.3374\n",
      "Epoch 737/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 30614883008.2737 - mean_absolute_error: 161567.6213 - val_loss: 32096305349.0584 - val_mean_absolute_error: 162836.6181\n",
      "Epoch 738/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 30662036950.3918 - mean_absolute_error: 161733.2266 - val_loss: 31829813874.3643 - val_mean_absolute_error: 162201.0402\n",
      "Epoch 739/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 30598024189.3721 - mean_absolute_error: 161503.4088 - val_loss: 32118689053.0309 - val_mean_absolute_error: 162887.7726\n",
      "Epoch 740/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 30835174150.3507 - mean_absolute_error: 161972.5227 - val_loss: 32033470506.2268 - val_mean_absolute_error: 162745.1218\n",
      "Epoch 741/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 30759364672.8212 - mean_absolute_error: 161722.0306 - val_loss: 32457543124.0137 - val_mean_absolute_error: 164090.4175\n",
      "Epoch 742/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 30509827447.7879 - mean_absolute_error: 161319.4128 - val_loss: 31754146763.2165 - val_mean_absolute_error: 162052.6216\n",
      "Epoch 743/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 30706835753.8272 - mean_absolute_error: 161646.9838 - val_loss: 31676814416.9347 - val_mean_absolute_error: 161777.6109\n",
      "Epoch 744/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 30597605957.6390 - mean_absolute_error: 161538.3815 - val_loss: 31353377858.8591 - val_mean_absolute_error: 160939.6466\n",
      "Epoch 745/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 30513866298.2515 - mean_absolute_error: 161305.4893 - val_loss: 31043925537.4296 - val_mean_absolute_error: 160068.8185\n",
      "Epoch 746/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 30570103581.1257 - mean_absolute_error: 161268.5782 - val_loss: 31433834643.7938 - val_mean_absolute_error: 160832.7737\n",
      "Epoch 747/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 30440968626.4773 - mean_absolute_error: 161113.1598 - val_loss: 31474317783.5326 - val_mean_absolute_error: 161042.8800\n",
      "Epoch 748/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 30434235359.5894 - mean_absolute_error: 161147.0343 - val_loss: 31416582291.7938 - val_mean_absolute_error: 160937.2173\n",
      "Epoch 749/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 30432475817.4987 - mean_absolute_error: 161045.1747 - val_loss: 30904601920.2199 - val_mean_absolute_error: 159666.2861\n",
      "Epoch 750/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 30543899415.8700 - mean_absolute_error: 161248.6943 - val_loss: 31536853920.9897 - val_mean_absolute_error: 161223.8166\n",
      "Epoch 751/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 30474567371.6613 - mean_absolute_error: 160890.5054 - val_loss: 31451143558.5979 - val_mean_absolute_error: 161135.4111\n",
      "Epoch 752/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 30313567427.3396 - mean_absolute_error: 160960.9680 - val_loss: 32051000640.2199 - val_mean_absolute_error: 162523.1676\n",
      "Epoch 753/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 30527736538.5526 - mean_absolute_error: 161229.5981 - val_loss: 31915340360.1375 - val_mean_absolute_error: 162273.7751\n",
      "Epoch 754/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 30428855825.9572 - mean_absolute_error: 160789.4759 - val_loss: 32354698335.0103 - val_mean_absolute_error: 163338.2749\n",
      "Epoch 755/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 30407929722.8537 - mean_absolute_error: 160838.3309 - val_loss: 31920271852.6460 - val_mean_absolute_error: 162415.3589\n",
      "Epoch 756/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 30374933003.8255 - mean_absolute_error: 160769.3334 - val_loss: 31789857316.9485 - val_mean_absolute_error: 161862.4901\n",
      "Epoch 757/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 30475564178.2857 - mean_absolute_error: 160791.2003 - val_loss: 30867483412.2337 - val_mean_absolute_error: 159672.3624\n",
      "Epoch 758/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 30431753547.9897 - mean_absolute_error: 160962.4313 - val_loss: 31882859593.8969 - val_mean_absolute_error: 162186.8056\n",
      "Epoch 759/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 30308195169.4508 - mean_absolute_error: 160641.2187 - val_loss: 31185059016.5773 - val_mean_absolute_error: 160447.9111\n",
      "Epoch 760/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 30321554450.3952 - mean_absolute_error: 160471.5077 - val_loss: 31489060075.7663 - val_mean_absolute_error: 161241.6431\n",
      "Epoch 761/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 30130096164.7904 - mean_absolute_error: 160426.7175 - val_loss: 32098720328.1375 - val_mean_absolute_error: 162712.0147\n",
      "Epoch 762/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 30113011417.6766 - mean_absolute_error: 160387.9629 - val_loss: 31860323268.1787 - val_mean_absolute_error: 162189.4690\n",
      "Epoch 763/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 30323342855.4457 - mean_absolute_error: 160482.9993 - val_loss: 31490269310.6804 - val_mean_absolute_error: 161129.6284\n",
      "Epoch 764/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 30056456008.0479 - mean_absolute_error: 159868.9421 - val_loss: 31354482554.2818 - val_mean_absolute_error: 160689.0720\n",
      "Epoch 765/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 30073039266.7100 - mean_absolute_error: 160229.4727 - val_loss: 31402715171.1890 - val_mean_absolute_error: 160814.1961\n",
      "Epoch 766/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 30192747308.8931 - mean_absolute_error: 160282.3787 - val_loss: 31563837784.8522 - val_mean_absolute_error: 161429.2721\n",
      "Epoch 767/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 30174674961.5192 - mean_absolute_error: 160339.3699 - val_loss: 31405498804.3436 - val_mean_absolute_error: 161087.0157\n",
      "Epoch 768/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 30136593342.3028 - mean_absolute_error: 160024.1516 - val_loss: 30883744173.3058 - val_mean_absolute_error: 159509.8632\n",
      "Epoch 769/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 30093871379.9281 - mean_absolute_error: 160368.3131 - val_loss: 31092401957.8282 - val_mean_absolute_error: 160239.0840\n",
      "Epoch 770/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 29978950768.9991 - mean_absolute_error: 159947.5254 - val_loss: 31358787443.2440 - val_mean_absolute_error: 160941.3814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 30139856796.1403 - mean_absolute_error: 160132.1942 - val_loss: 31490053763.9588 - val_mean_absolute_error: 161103.4605\n",
      "Epoch 772/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 30091949633.2592 - mean_absolute_error: 160165.6459 - val_loss: 31386777473.3196 - val_mean_absolute_error: 160545.6216\n",
      "Epoch 773/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 29874775175.7742 - mean_absolute_error: 159750.4135 - val_loss: 30541830875.9313 - val_mean_absolute_error: 158552.8160\n",
      "Epoch 774/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 30061010705.7382 - mean_absolute_error: 159980.6183 - val_loss: 31083721731.5189 - val_mean_absolute_error: 159967.2676\n",
      "Epoch 775/5000\n",
      "1169/1169 [==============================] - 0s 309us/step - loss: 29984364903.1446 - mean_absolute_error: 159646.3580 - val_loss: 30680649523.9038 - val_mean_absolute_error: 158972.2375\n",
      "Epoch 776/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 29867329605.2010 - mean_absolute_error: 159546.1212 - val_loss: 30793658607.2852 - val_mean_absolute_error: 159195.4355\n",
      "Epoch 777/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 29901069474.0530 - mean_absolute_error: 159797.2268 - val_loss: 30755004064.1100 - val_mean_absolute_error: 159276.6718\n",
      "Epoch 778/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 29874503098.3610 - mean_absolute_error: 159555.1404 - val_loss: 31171916353.0997 - val_mean_absolute_error: 160420.2740\n",
      "Epoch 779/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 29855528769.0402 - mean_absolute_error: 159583.1828 - val_loss: 31064648418.9691 - val_mean_absolute_error: 160140.2330\n",
      "Epoch 780/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 29771391920.2874 - mean_absolute_error: 159108.6683 - val_loss: 30925643417.0722 - val_mean_absolute_error: 159915.7455\n",
      "Epoch 781/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 29998940983.4046 - mean_absolute_error: 159809.3817 - val_loss: 30777144583.9175 - val_mean_absolute_error: 159538.0029\n",
      "Epoch 782/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 29813723700.1198 - mean_absolute_error: 159420.9664 - val_loss: 31240886525.3608 - val_mean_absolute_error: 160580.4022\n",
      "Epoch 783/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 29759944047.0282 - mean_absolute_error: 159211.9023 - val_loss: 31273755419.2715 - val_mean_absolute_error: 160658.3885\n",
      "Epoch 784/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 29824186331.2096 - mean_absolute_error: 159356.3353 - val_loss: 30753521699.1890 - val_mean_absolute_error: 159318.5545\n",
      "Epoch 785/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 29569735088.7254 - mean_absolute_error: 158898.9310 - val_loss: 30705243048.0275 - val_mean_absolute_error: 159477.0130\n",
      "Epoch 786/5000\n",
      "1169/1169 [==============================] - 1s 497us/step - loss: 29693391902.6587 - mean_absolute_error: 159102.6581 - val_loss: 29663286268.4811 - val_mean_absolute_error: 156397.7541\n",
      "Epoch 787/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 29786392761.7040 - mean_absolute_error: 159127.3866 - val_loss: 30588587046.7079 - val_mean_absolute_error: 158841.3056\n",
      "Epoch 788/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 29666955637.1600 - mean_absolute_error: 159230.8721 - val_loss: 31255746384.0550 - val_mean_absolute_error: 160824.0229\n",
      "Epoch 789/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 29769173561.3755 - mean_absolute_error: 159139.6382 - val_loss: 30298731446.1031 - val_mean_absolute_error: 157939.4640\n",
      "Epoch 790/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 29813358896.8349 - mean_absolute_error: 159287.4512 - val_loss: 31413052018.3643 - val_mean_absolute_error: 160979.0649\n",
      "Epoch 791/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 29661185930.6210 - mean_absolute_error: 159200.6155 - val_loss: 31224635539.7938 - val_mean_absolute_error: 160496.6284\n",
      "Epoch 792/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 29589049843.2985 - mean_absolute_error: 158823.3929 - val_loss: 31189589811.9038 - val_mean_absolute_error: 160444.3534\n",
      "Epoch 793/5000\n",
      "1169/1169 [==============================] - 0s 388us/step - loss: 29542307007.8358 - mean_absolute_error: 158789.2769 - val_loss: 31741780601.4021 - val_mean_absolute_error: 162009.1996\n",
      "Epoch 794/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 29575978328.2532 - mean_absolute_error: 158767.0004 - val_loss: 31656280451.0790 - val_mean_absolute_error: 161947.8718\n",
      "Epoch 795/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 29477649354.5663 - mean_absolute_error: 158689.0728 - val_loss: 31070387850.9966 - val_mean_absolute_error: 160520.4862\n",
      "Epoch 796/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 29725752823.6784 - mean_absolute_error: 158990.3736 - val_loss: 31087728625.9244 - val_mean_absolute_error: 160172.6472\n",
      "Epoch 797/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 29402212446.6039 - mean_absolute_error: 158428.3472 - val_loss: 30273427709.3608 - val_mean_absolute_error: 158314.3732\n",
      "Epoch 798/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 29432175007.2062 - mean_absolute_error: 158522.4061 - val_loss: 31261343223.2027 - val_mean_absolute_error: 160213.1247\n",
      "Epoch 799/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 29495438298.3336 - mean_absolute_error: 158540.1483 - val_loss: 30890383979.3265 - val_mean_absolute_error: 159392.5585\n",
      "Epoch 800/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 29421301688.1711 - mean_absolute_error: 158525.0874 - val_loss: 30763507859.7938 - val_mean_absolute_error: 159349.6048\n",
      "Epoch 801/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 29457170046.5766 - mean_absolute_error: 158504.8422 - val_loss: 31104432888.0825 - val_mean_absolute_error: 160293.6150\n",
      "Epoch 802/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 29360991439.6031 - mean_absolute_error: 158362.8420 - val_loss: 30414888854.4330 - val_mean_absolute_error: 158501.3928\n",
      "Epoch 803/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 29412293534.7682 - mean_absolute_error: 158246.4958 - val_loss: 30544857763.6289 - val_mean_absolute_error: 158989.0035\n",
      "Epoch 804/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 29389575671.6784 - mean_absolute_error: 158283.0789 - val_loss: 30400272215.0928 - val_mean_absolute_error: 158462.2590\n",
      "Epoch 805/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 29235660672.1095 - mean_absolute_error: 157913.5884 - val_loss: 30629684143.0653 - val_mean_absolute_error: 158768.5871\n",
      "Epoch 806/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 29236277135.8768 - mean_absolute_error: 157993.6720 - val_loss: 30436668665.8419 - val_mean_absolute_error: 158177.4810\n",
      "Epoch 807/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 29287641862.3507 - mean_absolute_error: 158125.3254 - val_loss: 30311017306.6117 - val_mean_absolute_error: 157957.8331\n",
      "Epoch 808/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 29328001857.9162 - mean_absolute_error: 158131.5664 - val_loss: 30564806606.7354 - val_mean_absolute_error: 158847.5026\n",
      "Epoch 809/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 29212467956.8315 - mean_absolute_error: 157822.9829 - val_loss: 30285047413.8832 - val_mean_absolute_error: 157945.9580\n",
      "Epoch 810/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 29203338461.6185 - mean_absolute_error: 157953.9167 - val_loss: 30756912701.5808 - val_mean_absolute_error: 159207.4807\n",
      "Epoch 811/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 29423555951.0282 - mean_absolute_error: 158322.4428 - val_loss: 30720470153.2371 - val_mean_absolute_error: 159599.8299\n",
      "Epoch 812/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 29119374543.6031 - mean_absolute_error: 157634.9721 - val_loss: 31189188242.0344 - val_mean_absolute_error: 160427.3992\n",
      "Epoch 813/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 29191295547.1275 - mean_absolute_error: 157833.7710 - val_loss: 30315453520.9347 - val_mean_absolute_error: 157953.2392\n",
      "Epoch 814/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 29166655023.7399 - mean_absolute_error: 157936.0556 - val_loss: 30914252652.2062 - val_mean_absolute_error: 159380.5341\n",
      "Epoch 815/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 29310552696.4448 - mean_absolute_error: 157838.8928 - val_loss: 31029854095.3952 - val_mean_absolute_error: 159634.7199\n",
      "Epoch 816/5000\n",
      "1169/1169 [==============================] - 0s 379us/step - loss: 28995862321.2729 - mean_absolute_error: 157549.1183 - val_loss: 30605222127.2852 - val_mean_absolute_error: 158994.0210\n",
      "Epoch 817/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 28907686208.6022 - mean_absolute_error: 157454.3446 - val_loss: 30443905368.8522 - val_mean_absolute_error: 158518.5975\n",
      "Epoch 818/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 29011159675.9487 - mean_absolute_error: 157347.7616 - val_loss: 30804727371.6564 - val_mean_absolute_error: 159474.6912\n",
      "Epoch 819/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 28988458498.1899 - mean_absolute_error: 157276.1209 - val_loss: 29991181350.7079 - val_mean_absolute_error: 156987.5365\n",
      "Epoch 820/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 29046768837.0915 - mean_absolute_error: 157343.6367 - val_loss: 30359676942.0756 - val_mean_absolute_error: 158035.6211\n",
      "Epoch 821/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 28976227202.7374 - mean_absolute_error: 157173.1670 - val_loss: 30564665428.4536 - val_mean_absolute_error: 158541.1699\n",
      "Epoch 822/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 28862411189.9812 - mean_absolute_error: 157151.1253 - val_loss: 30732209000.6873 - val_mean_absolute_error: 159172.5851\n",
      "Epoch 823/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 29112082975.0967 - mean_absolute_error: 157408.8512 - val_loss: 29803141310.0206 - val_mean_absolute_error: 156486.1597\n",
      "Epoch 824/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 28954670003.7913 - mean_absolute_error: 157171.9465 - val_loss: 29945182419.1340 - val_mean_absolute_error: 156825.2135\n",
      "Epoch 825/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 29083716116.5851 - mean_absolute_error: 157471.4157 - val_loss: 30175483861.7732 - val_mean_absolute_error: 157322.5377\n",
      "Epoch 826/5000\n",
      "1169/1169 [==============================] - 0s 389us/step - loss: 28874011608.5817 - mean_absolute_error: 157047.8788 - val_loss: 29830885784.1924 - val_mean_absolute_error: 156257.6874\n",
      "Epoch 827/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 28746122752.4380 - mean_absolute_error: 156707.5979 - val_loss: 30326080297.3471 - val_mean_absolute_error: 157783.6906\n",
      "Epoch 828/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 28960733084.1403 - mean_absolute_error: 157159.0820 - val_loss: 29992373927.1478 - val_mean_absolute_error: 157243.4167\n",
      "Epoch 829/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 28803911003.7571 - mean_absolute_error: 156953.6121 - val_loss: 30484020649.7869 - val_mean_absolute_error: 158616.7413\n",
      "Epoch 830/5000\n",
      "1169/1169 [==============================] - 0s 386us/step - loss: 28801531105.1223 - mean_absolute_error: 156833.1761 - val_loss: 30052662254.4055 - val_mean_absolute_error: 157509.9456\n",
      "Epoch 831/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 28686985440.2464 - mean_absolute_error: 156606.4061 - val_loss: 29932389196.5361 - val_mean_absolute_error: 156891.6946\n",
      "Epoch 832/5000\n",
      "1169/1169 [==============================] - 0s 404us/step - loss: 28899755706.1420 - mean_absolute_error: 157018.9676 - val_loss: 29790352753.4845 - val_mean_absolute_error: 156599.1881\n",
      "Epoch 833/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 28553066345.3345 - mean_absolute_error: 156351.9298 - val_loss: 29718275800.4124 - val_mean_absolute_error: 156520.8956\n",
      "Epoch 834/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 28726875072.0547 - mean_absolute_error: 156550.1916 - val_loss: 29919006769.2646 - val_mean_absolute_error: 157029.1211\n",
      "Epoch 835/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 28767903722.9769 - mean_absolute_error: 156611.3242 - val_loss: 31080552666.1718 - val_mean_absolute_error: 160610.0512\n",
      "Epoch 836/5000\n",
      "1169/1169 [==============================] - 0s 379us/step - loss: 28797145140.5577 - mean_absolute_error: 156632.1962 - val_loss: 30461615276.4261 - val_mean_absolute_error: 158928.5525\n",
      "Epoch 837/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 28629121584.6159 - mean_absolute_error: 156296.7831 - val_loss: 30559970863.5052 - val_mean_absolute_error: 159234.6483\n",
      "Epoch 838/5000\n",
      "1169/1169 [==============================] - 0s 388us/step - loss: 28700700134.1591 - mean_absolute_error: 156589.7995 - val_loss: 30662270891.5464 - val_mean_absolute_error: 159239.6452\n",
      "Epoch 839/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 28721989305.2660 - mean_absolute_error: 156646.5077 - val_loss: 30661782193.7045 - val_mean_absolute_error: 159808.9704\n",
      "Epoch 840/5000\n",
      "1169/1169 [==============================] - 0s 392us/step - loss: 28595895710.3302 - mean_absolute_error: 156547.6788 - val_loss: 31385362516.4536 - val_mean_absolute_error: 161703.4805\n",
      "Epoch 841/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 28578658841.8409 - mean_absolute_error: 156018.8234 - val_loss: 30743192910.2955 - val_mean_absolute_error: 159684.7773\n",
      "Epoch 842/5000\n",
      "1169/1169 [==============================] - 0s 421us/step - loss: 28634995288.9102 - mean_absolute_error: 156291.6572 - val_loss: 30448767482.7216 - val_mean_absolute_error: 158421.2463\n",
      "Epoch 843/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 28573719990.8571 - mean_absolute_error: 156246.8355 - val_loss: 30096960445.1409 - val_mean_absolute_error: 157637.8754\n",
      "Epoch 844/5000\n",
      "1169/1169 [==============================] - ETA: 0s - loss: 28387840160.6275 - mean_absolute_error: 156195.64 - 0s 357us/step - loss: 28762581333.6253 - mean_absolute_error: 156726.4833 - val_loss: 29061145068.6460 - val_mean_absolute_error: 154927.7458\n",
      "Epoch 845/5000\n",
      "1169/1169 [==============================] - 0s 399us/step - loss: 28657986219.2506 - mean_absolute_error: 156349.2608 - val_loss: 29174456826.7216 - val_mean_absolute_error: 155094.1132\n",
      "Epoch 846/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 28350303770.7169 - mean_absolute_error: 155614.4035 - val_loss: 29476385035.4364 - val_mean_absolute_error: 155992.9053\n",
      "Epoch 847/5000\n",
      "1169/1169 [==============================] - 0s 394us/step - loss: 28487782706.5868 - mean_absolute_error: 155987.8533 - val_loss: 29855318874.6117 - val_mean_absolute_error: 156929.9212\n",
      "Epoch 848/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 28447130214.9256 - mean_absolute_error: 155799.6826 - val_loss: 29826464166.2680 - val_mean_absolute_error: 156966.1465\n",
      "Epoch 849/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 28359794607.4115 - mean_absolute_error: 155653.8309 - val_loss: 30094558809.7320 - val_mean_absolute_error: 157288.6714\n",
      "Epoch 850/5000\n",
      "1169/1169 [==============================] - 0s 379us/step - loss: 28412640381.2626 - mean_absolute_error: 155843.6983 - val_loss: 29192814387.9038 - val_mean_absolute_error: 154754.2315\n",
      "Epoch 851/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 372us/step - loss: 28296811795.9281 - mean_absolute_error: 155608.5882 - val_loss: 28876381419.7663 - val_mean_absolute_error: 154250.1413\n",
      "Epoch 852/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 28249664285.1257 - mean_absolute_error: 155851.6447 - val_loss: 29218510735.3952 - val_mean_absolute_error: 155373.1184\n",
      "Epoch 853/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 28418814011.5654 - mean_absolute_error: 155804.9928 - val_loss: 29481573991.8076 - val_mean_absolute_error: 155883.3013\n",
      "Epoch 854/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 28128883660.3182 - mean_absolute_error: 155366.1453 - val_loss: 29519285568.2199 - val_mean_absolute_error: 155820.9128\n",
      "Epoch 855/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 28308750889.6082 - mean_absolute_error: 155473.6585 - val_loss: 29511593280.2199 - val_mean_absolute_error: 155914.2080\n",
      "Epoch 856/5000\n",
      "1169/1169 [==============================] - 0s 400us/step - loss: 28234997276.4688 - mean_absolute_error: 155267.2393 - val_loss: 30114277488.6048 - val_mean_absolute_error: 157254.1257\n",
      "Epoch 857/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 28140668582.8708 - mean_absolute_error: 154931.6799 - val_loss: 29049275015.4777 - val_mean_absolute_error: 154739.4665\n",
      "Epoch 858/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 28284797518.3986 - mean_absolute_error: 155637.2825 - val_loss: 29324214497.2096 - val_mean_absolute_error: 155347.4131\n",
      "Epoch 859/5000\n",
      "1169/1169 [==============================] - 0s 383us/step - loss: 28131473541.1463 - mean_absolute_error: 155114.6471 - val_loss: 29221125897.6770 - val_mean_absolute_error: 154757.8530\n",
      "Epoch 860/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 28085014184.6228 - mean_absolute_error: 155090.1141 - val_loss: 29200530421.4433 - val_mean_absolute_error: 155021.6079\n",
      "Epoch 861/5000\n",
      "1169/1169 [==============================] - 0s 390us/step - loss: 28097834515.7092 - mean_absolute_error: 155059.5070 - val_loss: 29349223181.1959 - val_mean_absolute_error: 155450.6284\n",
      "Epoch 862/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 28303775913.9367 - mean_absolute_error: 155357.3830 - val_loss: 29141778565.7182 - val_mean_absolute_error: 154818.0309\n",
      "Epoch 863/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 28281692503.3772 - mean_absolute_error: 155260.4884 - val_loss: 30478036548.6186 - val_mean_absolute_error: 158405.8046\n",
      "Epoch 864/5000\n",
      "1169/1169 [==============================] - 0s 387us/step - loss: 28072468113.8477 - mean_absolute_error: 154867.9195 - val_loss: 29329589427.4639 - val_mean_absolute_error: 155300.7148\n",
      "Epoch 865/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 28212712546.9837 - mean_absolute_error: 155298.0062 - val_loss: 29962825298.6942 - val_mean_absolute_error: 156547.5846\n",
      "Epoch 866/5000\n",
      "1169/1169 [==============================] - 0s 397us/step - loss: 27956176044.5646 - mean_absolute_error: 154867.7581 - val_loss: 29320271660.8660 - val_mean_absolute_error: 155667.4544\n",
      "Epoch 867/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 28239834310.8435 - mean_absolute_error: 155017.7719 - val_loss: 29054696458.5567 - val_mean_absolute_error: 154888.7817\n",
      "Epoch 868/5000\n",
      "1169/1169 [==============================] - 1s 475us/step - loss: 27954993472.6022 - mean_absolute_error: 154592.9544 - val_loss: 29839584160.9897 - val_mean_absolute_error: 156952.6355\n",
      "Epoch 869/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 28043528302.3713 - mean_absolute_error: 154779.1821 - val_loss: 28637200651.4364 - val_mean_absolute_error: 153901.2666\n",
      "Epoch 870/5000\n",
      "1169/1169 [==============================] - 0s 417us/step - loss: 28060779704.8281 - mean_absolute_error: 154521.9883 - val_loss: 30198344053.0034 - val_mean_absolute_error: 158014.4614\n",
      "Epoch 871/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 27993906536.8965 - mean_absolute_error: 154688.6944 - val_loss: 29761778740.7835 - val_mean_absolute_error: 157091.2126\n",
      "Epoch 872/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 27933130885.1463 - mean_absolute_error: 154682.3887 - val_loss: 30166302874.8316 - val_mean_absolute_error: 157782.6159\n",
      "Epoch 873/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 27923108664.2806 - mean_absolute_error: 154521.9792 - val_loss: 29653659141.2784 - val_mean_absolute_error: 156522.5729\n",
      "Epoch 874/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 27922712817.7656 - mean_absolute_error: 154335.5264 - val_loss: 29958577268.1237 - val_mean_absolute_error: 157384.8707\n",
      "Epoch 875/5000\n",
      "1169/1169 [==============================] - 1s 440us/step - loss: 27999265800.7596 - mean_absolute_error: 154556.7820 - val_loss: 29415413788.1512 - val_mean_absolute_error: 155807.1692\n",
      "Epoch 876/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 27848104250.4705 - mean_absolute_error: 154303.8735 - val_loss: 28296132375.7526 - val_mean_absolute_error: 152992.0908\n",
      "Epoch 877/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 27898693372.7151 - mean_absolute_error: 154316.0678 - val_loss: 29409645508.1787 - val_mean_absolute_error: 155917.3978\n",
      "Epoch 878/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 27799081927.9384 - mean_absolute_error: 154122.9429 - val_loss: 29090199354.9416 - val_mean_absolute_error: 154980.5496\n",
      "Epoch 879/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 27916806019.6133 - mean_absolute_error: 154123.8626 - val_loss: 29389971012.6186 - val_mean_absolute_error: 155982.7756\n",
      "Epoch 880/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 27883400523.9897 - mean_absolute_error: 154215.9650 - val_loss: 29074161579.5464 - val_mean_absolute_error: 154545.3301\n",
      "Epoch 881/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 27876078112.8486 - mean_absolute_error: 154457.4727 - val_loss: 29993905183.6701 - val_mean_absolute_error: 157936.9981\n",
      "Epoch 882/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 27694558525.9743 - mean_absolute_error: 153932.8733 - val_loss: 28702589807.7251 - val_mean_absolute_error: 153562.2144\n",
      "Epoch 883/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 27550734435.8597 - mean_absolute_error: 153717.4085 - val_loss: 29394763318.5430 - val_mean_absolute_error: 155653.3640\n",
      "Epoch 884/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 27777611178.5937 - mean_absolute_error: 154189.7731 - val_loss: 28832883448.0825 - val_mean_absolute_error: 154198.8504\n",
      "Epoch 885/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 27745983939.1206 - mean_absolute_error: 154055.4238 - val_loss: 28184965232.6048 - val_mean_absolute_error: 152229.1446\n",
      "Epoch 886/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 27769935130.9358 - mean_absolute_error: 153986.9187 - val_loss: 28370708655.9450 - val_mean_absolute_error: 152145.1714\n",
      "Epoch 887/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 27631698507.7707 - mean_absolute_error: 153691.1597 - val_loss: 27798147881.3471 - val_mean_absolute_error: 151131.5339\n",
      "Epoch 888/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 27639130448.3695 - mean_absolute_error: 153687.9032 - val_loss: 28205666332.1512 - val_mean_absolute_error: 151971.1482\n",
      "Epoch 889/5000\n",
      "1169/1169 [==============================] - 0s 385us/step - loss: 27410201881.1839 - mean_absolute_error: 153199.2856 - val_loss: 27520869428.7835 - val_mean_absolute_error: 150423.8139\n",
      "Epoch 890/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 27722996137.7177 - mean_absolute_error: 153831.5560 - val_loss: 28031550010.0619 - val_mean_absolute_error: 151547.6184\n",
      "Epoch 891/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 27537115200.8212 - mean_absolute_error: 153553.6869 - val_loss: 28534923981.8557 - val_mean_absolute_error: 153334.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 27432185367.2130 - mean_absolute_error: 153461.7476 - val_loss: 29731988180.8935 - val_mean_absolute_error: 156853.0530\n",
      "Epoch 893/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 27447114478.6997 - mean_absolute_error: 153440.4102 - val_loss: 29273146561.5395 - val_mean_absolute_error: 155709.5758\n",
      "Epoch 894/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 27581562063.6031 - mean_absolute_error: 153346.1509 - val_loss: 29114654213.2784 - val_mean_absolute_error: 154476.5191\n",
      "Epoch 895/5000\n",
      "1169/1169 [==============================] - 0s 395us/step - loss: 27408537125.2284 - mean_absolute_error: 152924.7256 - val_loss: 28878021748.1237 - val_mean_absolute_error: 153923.3240\n",
      "Epoch 896/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 27307930533.7759 - mean_absolute_error: 152912.9840 - val_loss: 29190035568.6048 - val_mean_absolute_error: 154555.6316\n",
      "Epoch 897/5000\n",
      "1169/1169 [==============================] - 0s 382us/step - loss: 27480113761.6698 - mean_absolute_error: 153173.5728 - val_loss: 29329972009.3471 - val_mean_absolute_error: 155373.5891\n",
      "Epoch 898/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 27452827905.5329 - mean_absolute_error: 153110.8343 - val_loss: 28616599221.2234 - val_mean_absolute_error: 153168.4997\n",
      "Epoch 899/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 27443084870.5150 - mean_absolute_error: 153238.1822 - val_loss: 28521602192.2749 - val_mean_absolute_error: 153115.5031\n",
      "Epoch 900/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 27372260450.9837 - mean_absolute_error: 153011.3537 - val_loss: 28171950833.0447 - val_mean_absolute_error: 152005.3296\n",
      "Epoch 901/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 27324672422.2139 - mean_absolute_error: 152919.5049 - val_loss: 28670700280.0825 - val_mean_absolute_error: 153370.7417\n",
      "Epoch 902/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 27160484715.9624 - mean_absolute_error: 152702.5783 - val_loss: 28869759813.4983 - val_mean_absolute_error: 153906.2793\n",
      "Epoch 903/5000\n",
      "1169/1169 [==============================] - 0s 395us/step - loss: 27467401098.6210 - mean_absolute_error: 153212.5117 - val_loss: 28057757132.9759 - val_mean_absolute_error: 151584.5650\n",
      "Epoch 904/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 27467384280.1437 - mean_absolute_error: 152999.4695 - val_loss: 29312765522.6942 - val_mean_absolute_error: 155292.5777\n",
      "Epoch 905/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 27248529739.1138 - mean_absolute_error: 152606.4205 - val_loss: 28253162105.4021 - val_mean_absolute_error: 152240.3720\n",
      "Epoch 906/5000\n",
      "1169/1169 [==============================] - 0s 400us/step - loss: 27066384031.8631 - mean_absolute_error: 152434.1923 - val_loss: 27918702162.6942 - val_mean_absolute_error: 151487.0448\n",
      "Epoch 907/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 27336402802.0941 - mean_absolute_error: 152574.2905 - val_loss: 29031486763.1065 - val_mean_absolute_error: 154814.2997\n",
      "Epoch 908/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 27159358426.3336 - mean_absolute_error: 152705.1156 - val_loss: 28027641384.4674 - val_mean_absolute_error: 151864.0651\n",
      "Epoch 909/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 27182224316.5509 - mean_absolute_error: 152393.8928 - val_loss: 27804744299.3265 - val_mean_absolute_error: 151016.1420\n",
      "Epoch 910/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 27122352727.1583 - mean_absolute_error: 152573.6203 - val_loss: 28447405826.6392 - val_mean_absolute_error: 152380.6200\n",
      "Epoch 911/5000\n",
      "1169/1169 [==============================] - 0s 386us/step - loss: 26915506645.5158 - mean_absolute_error: 151818.8888 - val_loss: 29040714016.5498 - val_mean_absolute_error: 153932.7907\n",
      "Epoch 912/5000\n",
      "1169/1169 [==============================] - 0s 311us/step - loss: 27105041908.1745 - mean_absolute_error: 152129.3816 - val_loss: 29380206957.9656 - val_mean_absolute_error: 155085.4480\n",
      "Epoch 913/5000\n",
      "1169/1169 [==============================] - 1s 442us/step - loss: 27010773408.9581 - mean_absolute_error: 151822.5160 - val_loss: 28696478195.6838 - val_mean_absolute_error: 153731.9214\n",
      "Epoch 914/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 27114857644.5646 - mean_absolute_error: 152245.4331 - val_loss: 28620325075.1340 - val_mean_absolute_error: 153482.1087\n",
      "Epoch 915/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 26928983322.9358 - mean_absolute_error: 152014.4636 - val_loss: 27829237281.4296 - val_mean_absolute_error: 151413.4224\n",
      "Epoch 916/5000\n",
      "1169/1169 [==============================] - 0s 397us/step - loss: 27184687012.8999 - mean_absolute_error: 152329.7735 - val_loss: 28455469238.9828 - val_mean_absolute_error: 152823.4957\n",
      "Epoch 917/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 27049913795.1206 - mean_absolute_error: 151928.4168 - val_loss: 28165373578.9966 - val_mean_absolute_error: 152258.3052\n",
      "Epoch 918/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 27086974263.8426 - mean_absolute_error: 152265.2949 - val_loss: 28979267436.2062 - val_mean_absolute_error: 154574.0461\n",
      "Epoch 919/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 27086583406.8092 - mean_absolute_error: 152052.7610 - val_loss: 29035043702.7629 - val_mean_absolute_error: 154603.5530\n",
      "Epoch 920/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 26932372896.0821 - mean_absolute_error: 151735.7135 - val_loss: 28975703226.5017 - val_mean_absolute_error: 154343.9497\n",
      "Epoch 921/5000\n",
      "1169/1169 [==============================] - 0s 317us/step - loss: 26929264780.1540 - mean_absolute_error: 151968.9316 - val_loss: 28146872622.6254 - val_mean_absolute_error: 152301.7121\n",
      "Epoch 922/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 26609615554.0257 - mean_absolute_error: 150956.7710 - val_loss: 28075585282.6392 - val_mean_absolute_error: 151957.4936\n",
      "Epoch 923/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 26875998390.2002 - mean_absolute_error: 151808.5316 - val_loss: 27987483482.6117 - val_mean_absolute_error: 151462.1719\n",
      "Epoch 924/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 26706799928.7186 - mean_absolute_error: 151464.1787 - val_loss: 27125584793.9519 - val_mean_absolute_error: 149387.8489\n",
      "Epoch 925/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 26943609292.7562 - mean_absolute_error: 151887.7956 - val_loss: 27916427608.8522 - val_mean_absolute_error: 151689.8517\n",
      "Epoch 926/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 26723649318.7613 - mean_absolute_error: 151247.0575 - val_loss: 26927548859.3814 - val_mean_absolute_error: 148810.2708\n",
      "Epoch 927/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 26907939578.0873 - mean_absolute_error: 151791.5014 - val_loss: 27591093589.3333 - val_mean_absolute_error: 150409.0205\n",
      "Epoch 928/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 26923382190.0975 - mean_absolute_error: 151714.4852 - val_loss: 27187531220.0137 - val_mean_absolute_error: 149270.9434\n",
      "Epoch 929/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 26556375068.0308 - mean_absolute_error: 150926.7712 - val_loss: 27235781994.4467 - val_mean_absolute_error: 149612.7457\n",
      "Epoch 930/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 26764808682.5389 - mean_absolute_error: 151455.9899 - val_loss: 27070610900.0137 - val_mean_absolute_error: 149062.2758\n",
      "Epoch 931/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 26749679032.6091 - mean_absolute_error: 151374.2603 - val_loss: 27343446776.0825 - val_mean_absolute_error: 150031.2349\n",
      "Epoch 932/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 26768179042.3268 - mean_absolute_error: 151153.5531 - val_loss: 28367086046.5704 - val_mean_absolute_error: 152640.9906\n",
      "Epoch 933/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 26631058767.4936 - mean_absolute_error: 150891.7450 - val_loss: 27359062065.2646 - val_mean_absolute_error: 149943.8932\n",
      "Epoch 934/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 26744905055.2609 - mean_absolute_error: 151233.0512 - val_loss: 27596959089.4845 - val_mean_absolute_error: 150569.3986\n",
      "Epoch 935/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 26373593412.1061 - mean_absolute_error: 150574.8194 - val_loss: 28432965019.7113 - val_mean_absolute_error: 152499.2639\n",
      "Epoch 936/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 26757580263.9110 - mean_absolute_error: 151256.8513 - val_loss: 27650824248.3024 - val_mean_absolute_error: 150498.1204\n",
      "Epoch 937/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 26548779065.8135 - mean_absolute_error: 150483.3341 - val_loss: 27861734065.7045 - val_mean_absolute_error: 150946.0926\n",
      "Epoch 938/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 26561101711.8768 - mean_absolute_error: 150728.6958 - val_loss: 27724611196.9210 - val_mean_absolute_error: 150633.5091\n",
      "Epoch 939/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 26596074057.1429 - mean_absolute_error: 150914.9556 - val_loss: 27436160193.5395 - val_mean_absolute_error: 150207.9678\n",
      "Epoch 940/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 26479433034.2378 - mean_absolute_error: 150550.9949 - val_loss: 28449180267.3265 - val_mean_absolute_error: 152975.5962\n",
      "Epoch 941/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 26498037693.4269 - mean_absolute_error: 150605.6492 - val_loss: 28298494972.4811 - val_mean_absolute_error: 152734.7427\n",
      "Epoch 942/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 26695330247.5004 - mean_absolute_error: 151049.9187 - val_loss: 28507641729.3196 - val_mean_absolute_error: 153132.0125\n",
      "Epoch 943/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 26271437651.4354 - mean_absolute_error: 149942.3451 - val_loss: 27556632590.0756 - val_mean_absolute_error: 150493.7991\n",
      "Epoch 944/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 26562134086.0770 - mean_absolute_error: 150272.0744 - val_loss: 28191149474.7491 - val_mean_absolute_error: 151846.4905\n",
      "Epoch 945/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 26397845737.0060 - mean_absolute_error: 150179.5052 - val_loss: 27589378146.5292 - val_mean_absolute_error: 150226.4257\n",
      "Epoch 946/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 26384954775.3225 - mean_absolute_error: 150111.4642 - val_loss: 27042431778.3093 - val_mean_absolute_error: 148775.8965\n",
      "Epoch 947/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 26139617220.4346 - mean_absolute_error: 149944.4697 - val_loss: 27333181320.3574 - val_mean_absolute_error: 149577.5556\n",
      "Epoch 948/5000\n",
      "1169/1169 [==============================] - 1s 453us/step - loss: 26443859274.2378 - mean_absolute_error: 150219.5853 - val_loss: 27794973981.0309 - val_mean_absolute_error: 151148.6798\n",
      "Epoch 949/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 26284838500.2977 - mean_absolute_error: 150097.8403 - val_loss: 27797096462.0756 - val_mean_absolute_error: 151620.4362\n",
      "Epoch 950/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 26364249766.8708 - mean_absolute_error: 150126.6746 - val_loss: 27545258406.2680 - val_mean_absolute_error: 150553.6750\n",
      "Epoch 951/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 26542043631.7947 - mean_absolute_error: 150523.9706 - val_loss: 27420107617.6495 - val_mean_absolute_error: 149964.9328\n",
      "Epoch 952/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 26139616457.4713 - mean_absolute_error: 149307.6201 - val_loss: 27149826033.9244 - val_mean_absolute_error: 149547.3887\n",
      "Epoch 953/5000\n",
      "1169/1169 [==============================] - 0s 389us/step - loss: 26179274501.4748 - mean_absolute_error: 149673.1042 - val_loss: 27928082973.9107 - val_mean_absolute_error: 151972.8334\n",
      "Epoch 954/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 26240186394.2789 - mean_absolute_error: 149650.3097 - val_loss: 27089971094.4330 - val_mean_absolute_error: 149438.9189\n",
      "Epoch 955/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 26342670619.8118 - mean_absolute_error: 150242.3293 - val_loss: 27443747611.2715 - val_mean_absolute_error: 150234.3402\n",
      "Epoch 956/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 26260586702.7271 - mean_absolute_error: 149830.4357 - val_loss: 27379889310.3505 - val_mean_absolute_error: 149624.9311\n",
      "Epoch 957/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 25978301717.6801 - mean_absolute_error: 149390.5279 - val_loss: 27953388378.6117 - val_mean_absolute_error: 151422.6128\n",
      "Epoch 958/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 26032420336.6707 - mean_absolute_error: 149383.2283 - val_loss: 27084602807.8625 - val_mean_absolute_error: 149202.7749\n",
      "Epoch 959/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 25961898671.6305 - mean_absolute_error: 149197.3970 - val_loss: 27334846555.4914 - val_mean_absolute_error: 149900.5219\n",
      "Epoch 960/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 25885294877.5637 - mean_absolute_error: 149062.5424 - val_loss: 28304729696.7698 - val_mean_absolute_error: 152795.6733\n",
      "Epoch 961/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 26045081885.5637 - mean_absolute_error: 149307.3975 - val_loss: 27831801806.7354 - val_mean_absolute_error: 151634.4502\n",
      "Epoch 962/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 26018270667.8802 - mean_absolute_error: 149584.8625 - val_loss: 27468495333.6082 - val_mean_absolute_error: 150574.1161\n",
      "Epoch 963/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 26202912669.8922 - mean_absolute_error: 149534.6506 - val_loss: 27338930161.9244 - val_mean_absolute_error: 149886.1535\n",
      "Epoch 964/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 25828901177.5945 - mean_absolute_error: 149112.7842 - val_loss: 27861813860.2887 - val_mean_absolute_error: 150593.6668\n",
      "Epoch 965/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 26035561168.0411 - mean_absolute_error: 148978.3084 - val_loss: 28576208149.9931 - val_mean_absolute_error: 152422.0457\n",
      "Epoch 966/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 25979600296.8417 - mean_absolute_error: 149125.6504 - val_loss: 28117184321.9794 - val_mean_absolute_error: 151795.2416\n",
      "Epoch 967/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 25974283005.5911 - mean_absolute_error: 148918.6069 - val_loss: 26360415073.6495 - val_mean_absolute_error: 146954.2021\n",
      "Epoch 968/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 25740558006.6382 - mean_absolute_error: 148809.4910 - val_loss: 27315862109.2509 - val_mean_absolute_error: 149808.6471\n",
      "Epoch 969/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 25875278049.9983 - mean_absolute_error: 148679.9585 - val_loss: 27073027631.5052 - val_mean_absolute_error: 149482.5526\n",
      "Epoch 970/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 25772808127.1788 - mean_absolute_error: 148636.0438 - val_loss: 27136421360.1649 - val_mean_absolute_error: 149353.7856\n",
      "Epoch 971/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 25960424846.5629 - mean_absolute_error: 148888.5595 - val_loss: 26213333132.7560 - val_mean_absolute_error: 146767.9404\n",
      "Epoch 972/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 25971033227.2780 - mean_absolute_error: 149295.1431 - val_loss: 27609066921.7869 - val_mean_absolute_error: 150923.7722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 26113074975.7536 - mean_absolute_error: 148863.4640 - val_loss: 27333574107.0515 - val_mean_absolute_error: 149810.7350\n",
      "Epoch 974/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 25459189190.6245 - mean_absolute_error: 148094.3351 - val_loss: 26628379503.7251 - val_mean_absolute_error: 147829.4704\n",
      "Epoch 975/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 25585052715.7981 - mean_absolute_error: 148683.3587 - val_loss: 27205512469.9931 - val_mean_absolute_error: 148859.5543\n",
      "Epoch 976/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 25749412787.7913 - mean_absolute_error: 148244.0075 - val_loss: 26140014204.9210 - val_mean_absolute_error: 146452.1290\n",
      "Epoch 977/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 25565627468.2087 - mean_absolute_error: 148185.3630 - val_loss: 27153371220.4536 - val_mean_absolute_error: 149267.7659\n",
      "Epoch 978/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 25624736935.3088 - mean_absolute_error: 148040.1518 - val_loss: 27557351740.7010 - val_mean_absolute_error: 150728.4088\n",
      "Epoch 979/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 25593511953.5192 - mean_absolute_error: 148056.6079 - val_loss: 26314333363.4639 - val_mean_absolute_error: 146870.8215\n",
      "Epoch 980/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 25730937856.0000 - mean_absolute_error: 148664.6182 - val_loss: 26429284739.0790 - val_mean_absolute_error: 146535.7909\n",
      "Epoch 981/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 25655514587.6476 - mean_absolute_error: 148088.2377 - val_loss: 27622031233.3196 - val_mean_absolute_error: 150184.8880\n",
      "Epoch 982/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 25626266638.8914 - mean_absolute_error: 148110.4727 - val_loss: 27175289859.5189 - val_mean_absolute_error: 148845.8787\n",
      "Epoch 983/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 25740691529.5808 - mean_absolute_error: 148104.4813 - val_loss: 26665203057.4845 - val_mean_absolute_error: 147335.7950\n",
      "Epoch 984/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 25602977434.6074 - mean_absolute_error: 147907.6695 - val_loss: 26532714686.0206 - val_mean_absolute_error: 146974.1202\n",
      "Epoch 985/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 25472414785.6972 - mean_absolute_error: 147712.3693 - val_loss: 27066934367.0103 - val_mean_absolute_error: 148780.5927\n",
      "Epoch 986/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 25652647503.2746 - mean_absolute_error: 148050.9628 - val_loss: 25508101144.6323 - val_mean_absolute_error: 144677.2748\n",
      "Epoch 987/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 25514385066.3747 - mean_absolute_error: 147564.6961 - val_loss: 26835314406.4880 - val_mean_absolute_error: 148369.3167\n",
      "Epoch 988/5000\n",
      "1169/1169 [==============================] - 0s 386us/step - loss: 25247905404.8246 - mean_absolute_error: 146924.1921 - val_loss: 27064581482.4467 - val_mean_absolute_error: 149150.0011\n",
      "Epoch 989/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 25288699426.6005 - mean_absolute_error: 147337.5542 - val_loss: 26503553326.6254 - val_mean_absolute_error: 147789.3916\n",
      "Epoch 990/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 25239827225.6219 - mean_absolute_error: 147415.4351 - val_loss: 26124793152.2199 - val_mean_absolute_error: 146052.4377\n",
      "Epoch 991/5000\n",
      "1169/1169 [==============================] - 0s 385us/step - loss: 25481852474.2515 - mean_absolute_error: 147797.5148 - val_loss: 26409809490.6942 - val_mean_absolute_error: 146801.6254\n",
      "Epoch 992/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 25408375675.7297 - mean_absolute_error: 147660.9330 - val_loss: 25767106144.7698 - val_mean_absolute_error: 145486.2227\n",
      "Epoch 993/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 25262339796.4209 - mean_absolute_error: 147041.2000 - val_loss: 26057555390.9003 - val_mean_absolute_error: 146228.9558\n",
      "Epoch 994/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 25445281480.1574 - mean_absolute_error: 147441.8118 - val_loss: 27081256995.1890 - val_mean_absolute_error: 149483.7666\n",
      "Epoch 995/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 25327022439.1446 - mean_absolute_error: 147352.0492 - val_loss: 27134541852.1512 - val_mean_absolute_error: 149604.7375\n",
      "Epoch 996/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 25159829442.6826 - mean_absolute_error: 147097.9345 - val_loss: 27703557531.7113 - val_mean_absolute_error: 150710.2312\n",
      "Epoch 997/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 25149913089.7519 - mean_absolute_error: 147177.3509 - val_loss: 26543553778.8041 - val_mean_absolute_error: 147406.9299\n",
      "Epoch 998/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 25167596133.1737 - mean_absolute_error: 147011.2587 - val_loss: 26085719275.7663 - val_mean_absolute_error: 145639.1029\n",
      "Epoch 999/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 24973773111.8426 - mean_absolute_error: 146656.7061 - val_loss: 26320116134.2680 - val_mean_absolute_error: 146594.6854\n",
      "Epoch 1000/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 25195217768.4585 - mean_absolute_error: 146728.7927 - val_loss: 27054921573.1684 - val_mean_absolute_error: 148999.6492\n",
      "Epoch 1001/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 25041184457.9093 - mean_absolute_error: 146522.9715 - val_loss: 27366470898.8041 - val_mean_absolute_error: 149891.6888\n",
      "Epoch 1002/5000\n",
      "1169/1169 [==============================] - 0s 389us/step - loss: 25091110768.3422 - mean_absolute_error: 146905.8533 - val_loss: 26178117153.4296 - val_mean_absolute_error: 146457.7361\n",
      "Epoch 1003/5000\n",
      "1169/1169 [==============================] - 0s 385us/step - loss: 25050830446.8092 - mean_absolute_error: 146598.3964 - val_loss: 26086199915.3265 - val_mean_absolute_error: 146287.7023\n",
      "Epoch 1004/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 25038348557.7964 - mean_absolute_error: 146645.7973 - val_loss: 25992189994.2268 - val_mean_absolute_error: 145588.4542\n",
      "Epoch 1005/5000\n",
      "1169/1169 [==============================] - 0s 392us/step - loss: 24838995170.8743 - mean_absolute_error: 146284.9590 - val_loss: 26161173789.0309 - val_mean_absolute_error: 146327.5302\n",
      "Epoch 1006/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 25110878633.7177 - mean_absolute_error: 146494.8066 - val_loss: 26177392872.2474 - val_mean_absolute_error: 146652.0297\n",
      "Epoch 1007/5000\n",
      "1169/1169 [==============================] - 0s 383us/step - loss: 24994454069.8717 - mean_absolute_error: 146557.5855 - val_loss: 27239311915.9863 - val_mean_absolute_error: 149455.5922\n",
      "Epoch 1008/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 24919287459.3670 - mean_absolute_error: 146181.6623 - val_loss: 27126645869.0859 - val_mean_absolute_error: 149583.9319\n",
      "Epoch 1009/5000\n",
      "1169/1169 [==============================] - 0s 383us/step - loss: 24728493717.3516 - mean_absolute_error: 145917.4863 - val_loss: 26359201348.6186 - val_mean_absolute_error: 147229.2841\n",
      "Epoch 1010/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 24996998956.0171 - mean_absolute_error: 146345.2043 - val_loss: 25574363347.1340 - val_mean_absolute_error: 144232.9624\n",
      "Epoch 1011/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 25138914823.4457 - mean_absolute_error: 146486.3478 - val_loss: 26604951397.1684 - val_mean_absolute_error: 147273.4661\n",
      "Epoch 1012/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 24941201907.2985 - mean_absolute_error: 146126.6829 - val_loss: 27004623213.9656 - val_mean_absolute_error: 148545.9531\n",
      "Epoch 1013/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 24737509648.4243 - mean_absolute_error: 145652.4702 - val_loss: 26030668289.7594 - val_mean_absolute_error: 145946.7170\n",
      "Epoch 1014/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 24681378433.2044 - mean_absolute_error: 145367.6052 - val_loss: 25459498698.3368 - val_mean_absolute_error: 144076.0529\n",
      "Epoch 1015/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 24954326948.8999 - mean_absolute_error: 145964.6023 - val_loss: 25564153461.8832 - val_mean_absolute_error: 144553.9758\n",
      "Epoch 1016/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 24789493127.5552 - mean_absolute_error: 145723.8721 - val_loss: 25406632189.3608 - val_mean_absolute_error: 143914.2201\n",
      "Epoch 1017/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 24723103640.6364 - mean_absolute_error: 145598.9067 - val_loss: 25759979393.3196 - val_mean_absolute_error: 145139.8023\n",
      "Epoch 1018/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 24644788231.0077 - mean_absolute_error: 145572.8532 - val_loss: 25727360496.1649 - val_mean_absolute_error: 145093.6180\n",
      "Epoch 1019/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 24725706102.0359 - mean_absolute_error: 145470.0241 - val_loss: 25769526212.1787 - val_mean_absolute_error: 145183.0651\n",
      "Epoch 1020/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 24847116675.1754 - mean_absolute_error: 145306.5599 - val_loss: 25875707326.9003 - val_mean_absolute_error: 145760.0593\n",
      "Epoch 1021/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 24555753885.4542 - mean_absolute_error: 145405.5923 - val_loss: 25579873804.3162 - val_mean_absolute_error: 144994.5505\n",
      "Epoch 1022/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 24730875485.2900 - mean_absolute_error: 145568.9200 - val_loss: 26421813825.0997 - val_mean_absolute_error: 147417.1927\n",
      "Epoch 1023/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 24653904255.6715 - mean_absolute_error: 145329.8277 - val_loss: 25457864394.3368 - val_mean_absolute_error: 144372.2955\n",
      "Epoch 1024/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 24816505739.4970 - mean_absolute_error: 145274.7284 - val_loss: 25548725328.9347 - val_mean_absolute_error: 144418.8319\n",
      "Epoch 1025/5000\n",
      "1169/1169 [==============================] - 0s 301us/step - loss: 24790116963.4217 - mean_absolute_error: 145691.9944 - val_loss: 27090258518.2131 - val_mean_absolute_error: 148973.4686\n",
      "Epoch 1026/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 24572870088.3764 - mean_absolute_error: 145179.5337 - val_loss: 26610139769.4021 - val_mean_absolute_error: 147788.5283\n",
      "Epoch 1027/5000\n",
      "1169/1169 [==============================] - 1s 464us/step - loss: 24708221078.6655 - mean_absolute_error: 145413.1325 - val_loss: 25886518549.9931 - val_mean_absolute_error: 145636.8010\n",
      "Epoch 1028/5000\n",
      "1169/1169 [==============================] - 1s 440us/step - loss: 24518843582.0838 - mean_absolute_error: 145002.0862 - val_loss: 26144739982.5155 - val_mean_absolute_error: 146478.7996\n",
      "Epoch 1029/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 24414286163.8734 - mean_absolute_error: 144848.0793 - val_loss: 26193443224.1924 - val_mean_absolute_error: 146471.8544\n",
      "Epoch 1030/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 24707254797.5774 - mean_absolute_error: 145081.6929 - val_loss: 25014184048.6048 - val_mean_absolute_error: 142935.8818\n",
      "Epoch 1031/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 24574207598.8092 - mean_absolute_error: 144860.6608 - val_loss: 24435714843.2715 - val_mean_absolute_error: 140803.9009\n",
      "Epoch 1032/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 24546389775.9863 - mean_absolute_error: 144947.6255 - val_loss: 24927475360.1100 - val_mean_absolute_error: 142698.5233\n",
      "Epoch 1033/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 24381711312.6980 - mean_absolute_error: 144653.4231 - val_loss: 26134038675.7938 - val_mean_absolute_error: 145996.9438\n",
      "Epoch 1034/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 24403892530.5868 - mean_absolute_error: 144935.1220 - val_loss: 25251215416.3024 - val_mean_absolute_error: 143338.3524\n",
      "Epoch 1035/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 24226688569.3755 - mean_absolute_error: 144139.8908 - val_loss: 25764559263.2302 - val_mean_absolute_error: 145171.5041\n",
      "Epoch 1036/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 24249017381.6664 - mean_absolute_error: 144105.7516 - val_loss: 25658287740.9210 - val_mean_absolute_error: 145286.5562\n",
      "Epoch 1037/5000\n",
      "1169/1169 [==============================] - 0s 411us/step - loss: 24245143233.1497 - mean_absolute_error: 144285.0778 - val_loss: 26089082746.2818 - val_mean_absolute_error: 146117.8019\n",
      "Epoch 1038/5000\n",
      "1169/1169 [==============================] - 1s 458us/step - loss: 24314487831.6510 - mean_absolute_error: 144163.5870 - val_loss: 25516381623.8625 - val_mean_absolute_error: 144436.6566\n",
      "Epoch 1039/5000\n",
      "1169/1169 [==============================] - 0s 396us/step - loss: 24591973926.9803 - mean_absolute_error: 144655.3212 - val_loss: 25408102090.3368 - val_mean_absolute_error: 144033.1393\n",
      "Epoch 1040/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 24278160523.2780 - mean_absolute_error: 144481.6410 - val_loss: 25318818383.1753 - val_mean_absolute_error: 143647.2436\n",
      "Epoch 1041/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 24235786394.1694 - mean_absolute_error: 143755.9289 - val_loss: 25332927660.4261 - val_mean_absolute_error: 144455.6576\n",
      "Epoch 1042/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 24166214133.0505 - mean_absolute_error: 144158.5257 - val_loss: 25260250587.0515 - val_mean_absolute_error: 144146.7591\n",
      "Epoch 1043/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 23970939204.9820 - mean_absolute_error: 143832.4027 - val_loss: 26059737770.6667 - val_mean_absolute_error: 146679.0639\n",
      "Epoch 1044/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 24163164664.5543 - mean_absolute_error: 144004.1468 - val_loss: 25090521320.2474 - val_mean_absolute_error: 142971.6602\n",
      "Epoch 1045/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 24133275378.2036 - mean_absolute_error: 144217.3969 - val_loss: 24478139191.4227 - val_mean_absolute_error: 141853.2719\n",
      "Epoch 1046/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 24213373875.7913 - mean_absolute_error: 143876.7896 - val_loss: 25252313791.7801 - val_mean_absolute_error: 143879.5240\n",
      "Epoch 1047/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 24418148260.8999 - mean_absolute_error: 144038.6192 - val_loss: 25350857541.4983 - val_mean_absolute_error: 144114.3173\n",
      "Epoch 1048/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 24152935598.3165 - mean_absolute_error: 144087.7028 - val_loss: 25857916892.8110 - val_mean_absolute_error: 145390.3748\n",
      "Epoch 1049/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 23925822506.9222 - mean_absolute_error: 143529.0482 - val_loss: 25584725136.2749 - val_mean_absolute_error: 144378.8373\n",
      "Epoch 1050/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 24215120059.4559 - mean_absolute_error: 144005.7466 - val_loss: 26659327908.5086 - val_mean_absolute_error: 147818.2189\n",
      "Epoch 1051/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 24144001584.6159 - mean_absolute_error: 143482.4527 - val_loss: 24714816698.5017 - val_mean_absolute_error: 143382.3591\n",
      "Epoch 1052/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 24201279226.9632 - mean_absolute_error: 144175.2050 - val_loss: 26931986854.2680 - val_mean_absolute_error: 149329.2944\n",
      "Epoch 1053/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 341us/step - loss: 23980477198.2344 - mean_absolute_error: 143459.8452 - val_loss: 24969116365.8557 - val_mean_absolute_error: 143091.3497\n",
      "Epoch 1054/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 23898464602.8811 - mean_absolute_error: 143210.4745 - val_loss: 26173241146.9416 - val_mean_absolute_error: 146238.8454\n",
      "Epoch 1055/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 23776590962.7511 - mean_absolute_error: 142685.4669 - val_loss: 24600659046.0481 - val_mean_absolute_error: 141660.9952\n",
      "Epoch 1056/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 23831730740.1198 - mean_absolute_error: 143308.4836 - val_loss: 24836190503.5876 - val_mean_absolute_error: 142232.9432\n",
      "Epoch 1057/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 23868724739.9418 - mean_absolute_error: 143415.1955 - val_loss: 24483560113.7045 - val_mean_absolute_error: 141312.3440\n",
      "Epoch 1058/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 23770465482.3473 - mean_absolute_error: 142985.0144 - val_loss: 24867622862.7354 - val_mean_absolute_error: 142265.6572\n",
      "Epoch 1059/5000\n",
      "1169/1169 [==============================] - 0s 378us/step - loss: 23596891436.4551 - mean_absolute_error: 142051.9545 - val_loss: 23903795129.6220 - val_mean_absolute_error: 139231.2441\n",
      "Epoch 1060/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 23869854547.4354 - mean_absolute_error: 142836.2992 - val_loss: 24932315431.5876 - val_mean_absolute_error: 142499.4318\n",
      "Epoch 1061/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 23835440046.5355 - mean_absolute_error: 142595.5000 - val_loss: 24861711968.7698 - val_mean_absolute_error: 142393.5339\n",
      "Epoch 1062/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 23742250453.5158 - mean_absolute_error: 143035.2301 - val_loss: 26224718239.2302 - val_mean_absolute_error: 146663.8775\n",
      "Epoch 1063/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 23845509483.5244 - mean_absolute_error: 142823.3240 - val_loss: 25408180336.6048 - val_mean_absolute_error: 143864.8541\n",
      "Epoch 1064/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 23708485504.1095 - mean_absolute_error: 142636.4061 - val_loss: 24367110531.0790 - val_mean_absolute_error: 139722.6471\n",
      "Epoch 1065/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 23679842362.6895 - mean_absolute_error: 142733.8734 - val_loss: 24160881371.9313 - val_mean_absolute_error: 140092.2296\n",
      "Epoch 1066/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 23835387583.3978 - mean_absolute_error: 142572.8448 - val_loss: 25245469242.0619 - val_mean_absolute_error: 143253.5456\n",
      "Epoch 1067/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 23783382785.9709 - mean_absolute_error: 142878.0369 - val_loss: 25084336529.1546 - val_mean_absolute_error: 142871.7360\n",
      "Epoch 1068/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 23501025760.0274 - mean_absolute_error: 141911.0609 - val_loss: 24533150582.7629 - val_mean_absolute_error: 141118.9471\n",
      "Epoch 1069/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 23550812992.1642 - mean_absolute_error: 142006.3375 - val_loss: 24099984000.4399 - val_mean_absolute_error: 140410.9154\n",
      "Epoch 1070/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 23654110165.0778 - mean_absolute_error: 142387.3873 - val_loss: 24460139066.0619 - val_mean_absolute_error: 141061.1306\n",
      "Epoch 1071/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 23827163346.2310 - mean_absolute_error: 142595.4094 - val_loss: 24338056786.6942 - val_mean_absolute_error: 140365.7942\n",
      "Epoch 1072/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 23428100151.1856 - mean_absolute_error: 142021.1934 - val_loss: 23701799608.7423 - val_mean_absolute_error: 139165.5758\n",
      "Epoch 1073/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 23172677306.1420 - mean_absolute_error: 141581.3234 - val_loss: 23927619070.2406 - val_mean_absolute_error: 139674.5662\n",
      "Epoch 1074/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 23628082127.8221 - mean_absolute_error: 142282.4359 - val_loss: 24627476951.5326 - val_mean_absolute_error: 141747.0711\n",
      "Epoch 1075/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 23581206883.6407 - mean_absolute_error: 142297.0093 - val_loss: 24788381562.2818 - val_mean_absolute_error: 142199.4465\n",
      "Epoch 1076/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 23655946548.3387 - mean_absolute_error: 142493.2014 - val_loss: 25882898312.3574 - val_mean_absolute_error: 145629.9264\n",
      "Epoch 1077/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 23325964040.9786 - mean_absolute_error: 141608.2697 - val_loss: 24232206793.4570 - val_mean_absolute_error: 140247.9034\n",
      "Epoch 1078/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 23284561189.4474 - mean_absolute_error: 141620.8179 - val_loss: 26317044753.5945 - val_mean_absolute_error: 147478.1581\n",
      "Epoch 1079/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 23378504294.9256 - mean_absolute_error: 141246.3188 - val_loss: 25732448136.3574 - val_mean_absolute_error: 145438.1702\n",
      "Epoch 1080/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 23312243124.2293 - mean_absolute_error: 141157.2210 - val_loss: 24651233589.6632 - val_mean_absolute_error: 141516.1940\n",
      "Epoch 1081/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 23514094401.9162 - mean_absolute_error: 141714.4773 - val_loss: 24591755883.3265 - val_mean_absolute_error: 141306.6905\n",
      "Epoch 1082/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 23283621278.3302 - mean_absolute_error: 141296.0689 - val_loss: 24220171837.5808 - val_mean_absolute_error: 140144.7911\n",
      "Epoch 1083/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 23343526710.5287 - mean_absolute_error: 141610.8145 - val_loss: 24867649930.1168 - val_mean_absolute_error: 142291.0843\n",
      "Epoch 1084/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 23185095249.9025 - mean_absolute_error: 140937.7575 - val_loss: 24976886280.7973 - val_mean_absolute_error: 142193.0628\n",
      "Epoch 1085/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 23224862314.4294 - mean_absolute_error: 141031.7831 - val_loss: 23910364825.0722 - val_mean_absolute_error: 139320.6968\n",
      "Epoch 1086/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 23231978763.1685 - mean_absolute_error: 141415.6774 - val_loss: 23925710292.0137 - val_mean_absolute_error: 139327.7600\n",
      "Epoch 1087/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 23329727848.0205 - mean_absolute_error: 141287.2229 - val_loss: 22905605813.2234 - val_mean_absolute_error: 136567.6115\n",
      "Epoch 1088/5000\n",
      "1169/1169 [==============================] - 0s 303us/step - loss: 23366495441.3550 - mean_absolute_error: 141601.1638 - val_loss: 24260663373.4158 - val_mean_absolute_error: 140766.9882\n",
      "Epoch 1089/5000\n",
      "1169/1169 [==============================] - 0s 384us/step - loss: 23183557352.5680 - mean_absolute_error: 140832.2904 - val_loss: 25064890881.7594 - val_mean_absolute_error: 142703.6337\n",
      "Epoch 1090/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 23108360766.6313 - mean_absolute_error: 140882.3934 - val_loss: 24076605517.4158 - val_mean_absolute_error: 140210.0795\n",
      "Epoch 1091/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 23046160643.2849 - mean_absolute_error: 140395.7465 - val_loss: 24725572520.0275 - val_mean_absolute_error: 141748.4003\n",
      "Epoch 1092/5000\n",
      "1169/1169 [==============================] - 0s 395us/step - loss: 23167229305.5398 - mean_absolute_error: 141040.7279 - val_loss: 24551379239.5876 - val_mean_absolute_error: 141302.1791\n",
      "Epoch 1093/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 22891000559.5757 - mean_absolute_error: 140396.7362 - val_loss: 23860345979.1615 - val_mean_absolute_error: 139065.5332\n",
      "Epoch 1094/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 23083040666.3884 - mean_absolute_error: 140618.6947 - val_loss: 24370206016.2199 - val_mean_absolute_error: 140896.6886\n",
      "Epoch 1095/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 22730444129.0128 - mean_absolute_error: 140027.0789 - val_loss: 23926937501.4708 - val_mean_absolute_error: 139673.3876\n",
      "Epoch 1096/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 22845625439.4799 - mean_absolute_error: 140128.2111 - val_loss: 23405274432.2199 - val_mean_absolute_error: 138286.9616\n",
      "Epoch 1097/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 22963643240.4585 - mean_absolute_error: 140357.4543 - val_loss: 24067617471.7801 - val_mean_absolute_error: 140413.6611\n",
      "Epoch 1098/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 22961262768.9444 - mean_absolute_error: 140198.5503 - val_loss: 24926966125.9656 - val_mean_absolute_error: 142238.1113\n",
      "Epoch 1099/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 22732571188.1198 - mean_absolute_error: 139703.7186 - val_loss: 23990765575.0378 - val_mean_absolute_error: 139526.5386\n",
      "Epoch 1100/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 22743077440.3832 - mean_absolute_error: 139988.9409 - val_loss: 24563700598.7629 - val_mean_absolute_error: 141199.3643\n",
      "Epoch 1101/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 23009389546.1009 - mean_absolute_error: 140530.5793 - val_loss: 24537558716.2612 - val_mean_absolute_error: 141121.9570\n",
      "Epoch 1102/5000\n",
      "1169/1169 [==============================] - 0s 400us/step - loss: 22855795390.5218 - mean_absolute_error: 139868.3180 - val_loss: 24762595525.0584 - val_mean_absolute_error: 141856.3624\n",
      "Epoch 1103/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 22973845162.3747 - mean_absolute_error: 140085.3313 - val_loss: 24456031629.6357 - val_mean_absolute_error: 140587.1097\n",
      "Epoch 1104/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 22873324068.3524 - mean_absolute_error: 139930.8274 - val_loss: 24369579856.0550 - val_mean_absolute_error: 140499.5535\n",
      "Epoch 1105/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 22978901998.4808 - mean_absolute_error: 139973.4398 - val_loss: 24632596261.8282 - val_mean_absolute_error: 141058.1114\n",
      "Epoch 1106/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 22553033798.9530 - mean_absolute_error: 139450.2882 - val_loss: 23493782088.1375 - val_mean_absolute_error: 138339.7522\n",
      "Epoch 1107/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 22685640355.3670 - mean_absolute_error: 139253.9511 - val_loss: 24227475399.6976 - val_mean_absolute_error: 139872.5452\n",
      "Epoch 1108/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 22533403499.0864 - mean_absolute_error: 139564.2889 - val_loss: 23588392425.1271 - val_mean_absolute_error: 138414.5347\n",
      "Epoch 1109/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 22685235128.1711 - mean_absolute_error: 139613.2979 - val_loss: 24051036342.9828 - val_mean_absolute_error: 140251.5530\n",
      "Epoch 1110/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 22659245446.6792 - mean_absolute_error: 139788.5208 - val_loss: 23680038250.4467 - val_mean_absolute_error: 138998.8204\n",
      "Epoch 1111/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 22458374180.7904 - mean_absolute_error: 138860.1004 - val_loss: 24269516349.5808 - val_mean_absolute_error: 140519.9994\n",
      "Epoch 1112/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 22534471890.2310 - mean_absolute_error: 139129.3730 - val_loss: 24935994434.8591 - val_mean_absolute_error: 142409.0843\n",
      "Epoch 1113/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 22545875878.6518 - mean_absolute_error: 139267.8841 - val_loss: 24615004976.3849 - val_mean_absolute_error: 141426.7812\n",
      "Epoch 1114/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 22865754789.9949 - mean_absolute_error: 139909.1378 - val_loss: 24232892141.5258 - val_mean_absolute_error: 140240.6184\n",
      "Epoch 1115/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 22490093881.5945 - mean_absolute_error: 139285.0397 - val_loss: 23579404548.3986 - val_mean_absolute_error: 137748.0882\n",
      "Epoch 1116/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 22370478288.4790 - mean_absolute_error: 138300.8227 - val_loss: 23234265700.2887 - val_mean_absolute_error: 137028.1718\n",
      "Epoch 1117/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 22758641418.7305 - mean_absolute_error: 139445.7235 - val_loss: 23349093576.5773 - val_mean_absolute_error: 136945.5550\n",
      "Epoch 1118/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 22563943944.3216 - mean_absolute_error: 139070.8322 - val_loss: 24250983462.7079 - val_mean_absolute_error: 139866.7215\n",
      "Epoch 1119/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 22347420972.4551 - mean_absolute_error: 138519.8639 - val_loss: 22070411721.4570 - val_mean_absolute_error: 133482.5973\n",
      "Epoch 1120/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 22423045740.1814 - mean_absolute_error: 138883.9670 - val_loss: 22962171383.2027 - val_mean_absolute_error: 136735.2516\n",
      "Epoch 1121/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 22301753238.8845 - mean_absolute_error: 138199.8032 - val_loss: 24123089860.1787 - val_mean_absolute_error: 139795.7796\n",
      "Epoch 1122/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 22497426718.4397 - mean_absolute_error: 138651.9185 - val_loss: 22636309416.0275 - val_mean_absolute_error: 135665.2859\n",
      "Epoch 1123/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 22151746529.3413 - mean_absolute_error: 138182.1544 - val_loss: 23903845829.9381 - val_mean_absolute_error: 138878.3484\n",
      "Epoch 1124/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 22471806457.4303 - mean_absolute_error: 138752.1851 - val_loss: 23963188544.2199 - val_mean_absolute_error: 139321.1694\n",
      "Epoch 1125/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 22215146971.6476 - mean_absolute_error: 137951.7991 - val_loss: 23420048837.9381 - val_mean_absolute_error: 137894.3750\n",
      "Epoch 1126/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 22471218022.7066 - mean_absolute_error: 138274.3931 - val_loss: 23830619498.4467 - val_mean_absolute_error: 139143.2196\n",
      "Epoch 1127/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 22199708170.0736 - mean_absolute_error: 138118.6539 - val_loss: 22093797017.0722 - val_mean_absolute_error: 134271.7761\n",
      "Epoch 1128/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 22570113884.1950 - mean_absolute_error: 138638.9348 - val_loss: 23361585848.7423 - val_mean_absolute_error: 137580.3594\n",
      "Epoch 1129/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 22254964410.1420 - mean_absolute_error: 138126.0327 - val_loss: 23758249836.2062 - val_mean_absolute_error: 139064.6486\n",
      "Epoch 1130/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 22076737654.2549 - mean_absolute_error: 137249.7687 - val_loss: 23012550670.0756 - val_mean_absolute_error: 136826.9765\n",
      "Epoch 1131/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 22059847361.1497 - mean_absolute_error: 137974.4006 - val_loss: 23282152233.3471 - val_mean_absolute_error: 137243.9154\n",
      "Epoch 1132/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 22356487407.1377 - mean_absolute_error: 138269.8132 - val_loss: 23590291646.0206 - val_mean_absolute_error: 137781.6329\n",
      "Epoch 1133/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 320us/step - loss: 22118195623.9658 - mean_absolute_error: 137810.5449 - val_loss: 22287467769.8419 - val_mean_absolute_error: 134505.8908\n",
      "Epoch 1134/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 22109099332.9820 - mean_absolute_error: 137905.7249 - val_loss: 23503500833.4296 - val_mean_absolute_error: 138177.3151\n",
      "Epoch 1135/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 21809773118.6313 - mean_absolute_error: 136939.8695 - val_loss: 23297087199.4502 - val_mean_absolute_error: 137616.0769\n",
      "Epoch 1136/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 22146625530.7442 - mean_absolute_error: 137305.2504 - val_loss: 24313418516.2337 - val_mean_absolute_error: 140157.7196\n",
      "Epoch 1137/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 21922893235.3533 - mean_absolute_error: 137539.5789 - val_loss: 24252961338.0619 - val_mean_absolute_error: 139758.4296\n",
      "Epoch 1138/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 21988851803.1001 - mean_absolute_error: 137350.7727 - val_loss: 23936803583.1203 - val_mean_absolute_error: 139229.4639\n",
      "Epoch 1139/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 21935627133.4816 - mean_absolute_error: 137763.1157 - val_loss: 23643032621.7457 - val_mean_absolute_error: 138618.3863\n",
      "Epoch 1140/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 22079365736.6775 - mean_absolute_error: 137716.1362 - val_loss: 22991231032.3024 - val_mean_absolute_error: 136537.6718\n",
      "Epoch 1141/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 21938677524.3661 - mean_absolute_error: 137231.3248 - val_loss: 23022511023.0653 - val_mean_absolute_error: 136427.6432\n",
      "Epoch 1142/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 21760011440.0684 - mean_absolute_error: 136938.6153 - val_loss: 23125918420.8935 - val_mean_absolute_error: 136960.2838\n",
      "Epoch 1143/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 21747258039.5141 - mean_absolute_error: 136964.2066 - val_loss: 22837663490.6392 - val_mean_absolute_error: 135918.6623\n",
      "Epoch 1144/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 21927296906.6210 - mean_absolute_error: 136833.8203 - val_loss: 23729711491.0790 - val_mean_absolute_error: 138494.2149\n",
      "Epoch 1145/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 21908019257.8135 - mean_absolute_error: 136923.6797 - val_loss: 22496373411.6289 - val_mean_absolute_error: 135261.1565\n",
      "Epoch 1146/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 21899022886.1044 - mean_absolute_error: 136888.9028 - val_loss: 22249841744.9347 - val_mean_absolute_error: 133886.0398\n",
      "Epoch 1147/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 21597429435.8939 - mean_absolute_error: 136284.6139 - val_loss: 22970331494.9278 - val_mean_absolute_error: 136010.4301\n",
      "Epoch 1148/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 21689371365.0642 - mean_absolute_error: 136237.3304 - val_loss: 23331441927.9175 - val_mean_absolute_error: 136953.0832\n",
      "Epoch 1149/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 21688679029.8169 - mean_absolute_error: 136256.7520 - val_loss: 22792282639.8351 - val_mean_absolute_error: 135823.9674\n",
      "Epoch 1150/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 21792588247.2677 - mean_absolute_error: 136712.7433 - val_loss: 22561377234.2543 - val_mean_absolute_error: 134695.3143\n",
      "Epoch 1151/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 21502726697.6082 - mean_absolute_error: 136079.1584 - val_loss: 23612314071.5326 - val_mean_absolute_error: 138419.6546\n",
      "Epoch 1152/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 21676636294.8982 - mean_absolute_error: 136338.9216 - val_loss: 23053236878.5155 - val_mean_absolute_error: 137143.2566\n",
      "Epoch 1153/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 21510339993.0744 - mean_absolute_error: 135883.3765 - val_loss: 23616269195.8763 - val_mean_absolute_error: 138199.9716\n",
      "Epoch 1154/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 21747991396.9547 - mean_absolute_error: 136313.4851 - val_loss: 22890182402.6392 - val_mean_absolute_error: 135836.4405\n",
      "Epoch 1155/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 21902046738.8332 - mean_absolute_error: 137092.4014 - val_loss: 22831007272.4674 - val_mean_absolute_error: 135302.8600\n",
      "Epoch 1156/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 21627829847.1583 - mean_absolute_error: 136289.1451 - val_loss: 23550227234.3093 - val_mean_absolute_error: 138289.5318\n",
      "Epoch 1157/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 21857398114.7648 - mean_absolute_error: 136545.6524 - val_loss: 24594772861.8007 - val_mean_absolute_error: 141510.4190\n",
      "Epoch 1158/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 21612397331.4902 - mean_absolute_error: 135865.1829 - val_loss: 22483316524.8660 - val_mean_absolute_error: 134716.1628\n",
      "Epoch 1159/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 21549485177.7588 - mean_absolute_error: 135961.0416 - val_loss: 22024616393.4570 - val_mean_absolute_error: 133061.5629\n",
      "Epoch 1160/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 21512863922.6963 - mean_absolute_error: 135694.2303 - val_loss: 21524921305.2921 - val_mean_absolute_error: 132021.5707\n",
      "Epoch 1161/5000\n",
      "1169/1169 [==============================] - 1s 473us/step - loss: 21493295720.6775 - mean_absolute_error: 136146.3164 - val_loss: 23813947617.2096 - val_mean_absolute_error: 139047.2901\n",
      "Epoch 1162/5000\n",
      "1169/1169 [==============================] - 0s 396us/step - loss: 21421904966.9530 - mean_absolute_error: 135738.5096 - val_loss: 22445686185.7869 - val_mean_absolute_error: 135208.3133\n",
      "Epoch 1163/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 21481669371.8392 - mean_absolute_error: 135246.6929 - val_loss: 22797125575.6976 - val_mean_absolute_error: 136207.8454\n",
      "Epoch 1164/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 21472195173.1737 - mean_absolute_error: 135688.7842 - val_loss: 23430053852.8110 - val_mean_absolute_error: 137930.9806\n",
      "Epoch 1165/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 21264179748.3524 - mean_absolute_error: 135317.6094 - val_loss: 23057838741.5533 - val_mean_absolute_error: 136659.9450\n",
      "Epoch 1166/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 21374028736.0547 - mean_absolute_error: 135191.4434 - val_loss: 23590621078.4330 - val_mean_absolute_error: 138673.8966\n",
      "Epoch 1167/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 21641600838.2960 - mean_absolute_error: 135994.3697 - val_loss: 23253087165.1409 - val_mean_absolute_error: 137134.4887\n",
      "Epoch 1168/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 21113239457.3961 - mean_absolute_error: 134522.3011 - val_loss: 23611926640.6048 - val_mean_absolute_error: 138411.4230\n",
      "Epoch 1169/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 21093944376.9376 - mean_absolute_error: 134711.5050 - val_loss: 23328834296.0825 - val_mean_absolute_error: 138169.1393\n",
      "Epoch 1170/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 21067146335.4799 - mean_absolute_error: 134756.7980 - val_loss: 21957237432.7423 - val_mean_absolute_error: 134000.1322\n",
      "Epoch 1171/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 21465725881.0470 - mean_absolute_error: 135831.5916 - val_loss: 23883398323.4639 - val_mean_absolute_error: 138776.4722\n",
      "Epoch 1172/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 21112790015.1240 - mean_absolute_error: 134303.5184 - val_loss: 23122144336.9347 - val_mean_absolute_error: 137325.4910\n",
      "Epoch 1173/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 21305108856.6638 - mean_absolute_error: 135201.4577 - val_loss: 23076541858.7491 - val_mean_absolute_error: 136870.4574\n",
      "Epoch 1174/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 21292545821.5637 - mean_absolute_error: 135301.7426 - val_loss: 22298898945.7594 - val_mean_absolute_error: 134854.7085\n",
      "Epoch 1175/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 21465589062.7340 - mean_absolute_error: 134942.4390 - val_loss: 23303286059.1065 - val_mean_absolute_error: 137155.1543\n",
      "Epoch 1176/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 21171900731.3465 - mean_absolute_error: 134453.0088 - val_loss: 22793160844.7560 - val_mean_absolute_error: 136197.0481\n",
      "Epoch 1177/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 20858862576.2327 - mean_absolute_error: 133987.3522 - val_loss: 22887040489.1271 - val_mean_absolute_error: 136388.3603\n",
      "Epoch 1178/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 21087646800.5885 - mean_absolute_error: 134454.7262 - val_loss: 22120140391.8076 - val_mean_absolute_error: 133961.9739\n",
      "Epoch 1179/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 21177025470.3028 - mean_absolute_error: 134632.4176 - val_loss: 21931023469.0859 - val_mean_absolute_error: 133320.5438\n",
      "Epoch 1180/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 21411185125.2831 - mean_absolute_error: 135240.5671 - val_loss: 23378511090.8041 - val_mean_absolute_error: 137831.6458\n",
      "Epoch 1181/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 21127536718.8366 - mean_absolute_error: 134720.7343 - val_loss: 22283326157.8557 - val_mean_absolute_error: 134714.2079\n",
      "Epoch 1182/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 20995926806.1180 - mean_absolute_error: 134376.5283 - val_loss: 22633779678.5704 - val_mean_absolute_error: 135995.0939\n",
      "Epoch 1183/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 20896214496.9033 - mean_absolute_error: 134300.0449 - val_loss: 22422621574.5979 - val_mean_absolute_error: 135056.9864\n",
      "Epoch 1184/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 20883668889.0744 - mean_absolute_error: 134159.6267 - val_loss: 22074474608.6048 - val_mean_absolute_error: 133761.6192\n",
      "Epoch 1185/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 20780993565.7827 - mean_absolute_error: 133452.5128 - val_loss: 22068876967.1478 - val_mean_absolute_error: 133406.6510\n",
      "Epoch 1186/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 20770882529.3413 - mean_absolute_error: 133271.9625 - val_loss: 21226673500.3711 - val_mean_absolute_error: 130844.0101\n",
      "Epoch 1187/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 21066527180.7562 - mean_absolute_error: 134358.5524 - val_loss: 20996362338.5292 - val_mean_absolute_error: 129837.6159\n",
      "Epoch 1188/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 20952654346.0736 - mean_absolute_error: 133770.7300 - val_loss: 21388277978.1718 - val_mean_absolute_error: 131216.6910\n",
      "Epoch 1189/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 20791038919.0624 - mean_absolute_error: 133495.8101 - val_loss: 21551996238.2955 - val_mean_absolute_error: 132201.3790\n",
      "Epoch 1190/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 20838836862.5766 - mean_absolute_error: 133870.0037 - val_loss: 21960326640.1649 - val_mean_absolute_error: 133856.9669\n",
      "Epoch 1191/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 20726942759.4183 - mean_absolute_error: 133398.2029 - val_loss: 21451369496.6323 - val_mean_absolute_error: 131689.0091\n",
      "Epoch 1192/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 20785016843.3875 - mean_absolute_error: 133435.6876 - val_loss: 22595776195.2990 - val_mean_absolute_error: 134764.7134\n",
      "Epoch 1193/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 20927307646.3576 - mean_absolute_error: 133455.7167 - val_loss: 22264830296.8522 - val_mean_absolute_error: 133453.4216\n",
      "Epoch 1194/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 20612167772.8520 - mean_absolute_error: 132791.6702 - val_loss: 21144386739.4639 - val_mean_absolute_error: 130086.7744\n",
      "Epoch 1195/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 20881701267.8186 - mean_absolute_error: 133346.9686 - val_loss: 21964494073.8419 - val_mean_absolute_error: 132990.2970\n",
      "Epoch 1196/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 20735490548.1745 - mean_absolute_error: 133046.2609 - val_loss: 22305457746.6942 - val_mean_absolute_error: 134307.2134\n",
      "Epoch 1197/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 20509929853.9196 - mean_absolute_error: 132866.0613 - val_loss: 22330874735.7251 - val_mean_absolute_error: 134075.2590\n",
      "Epoch 1198/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 20839399087.6305 - mean_absolute_error: 133454.4625 - val_loss: 22057642434.4192 - val_mean_absolute_error: 133512.2939\n",
      "Epoch 1199/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 20647514774.2275 - mean_absolute_error: 132999.3708 - val_loss: 20769365635.9588 - val_mean_absolute_error: 129594.3680\n",
      "Epoch 1200/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 20500732837.7759 - mean_absolute_error: 133019.2177 - val_loss: 21789951605.8832 - val_mean_absolute_error: 133058.2787\n",
      "Epoch 1201/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 20410194981.6664 - mean_absolute_error: 132612.4610 - val_loss: 23164581240.5223 - val_mean_absolute_error: 136358.0325\n",
      "Epoch 1202/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 20715257135.9589 - mean_absolute_error: 133106.5471 - val_loss: 22770350396.7010 - val_mean_absolute_error: 135507.9614\n",
      "Epoch 1203/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 20611254351.7126 - mean_absolute_error: 132664.1192 - val_loss: 23415016697.8419 - val_mean_absolute_error: 137775.3430\n",
      "Epoch 1204/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 20187915980.0992 - mean_absolute_error: 131998.7112 - val_loss: 21055974164.2337 - val_mean_absolute_error: 130976.2619\n",
      "Epoch 1205/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 20540609911.7879 - mean_absolute_error: 133057.2272 - val_loss: 21511966762.2268 - val_mean_absolute_error: 132112.9110\n",
      "Epoch 1206/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 20505266592.9581 - mean_absolute_error: 132131.8114 - val_loss: 20237368429.0859 - val_mean_absolute_error: 127680.7378\n",
      "Epoch 1207/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 20457345454.9735 - mean_absolute_error: 132104.2225 - val_loss: 20487437269.7732 - val_mean_absolute_error: 128592.3470\n",
      "Epoch 1208/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 20225206043.3738 - mean_absolute_error: 132046.5541 - val_loss: 21491182989.6357 - val_mean_absolute_error: 131782.1034\n",
      "Epoch 1209/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 20599637001.6356 - mean_absolute_error: 132583.5419 - val_loss: 21156310371.4089 - val_mean_absolute_error: 131120.5278\n",
      "Epoch 1210/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 20553074627.5586 - mean_absolute_error: 132297.9409 - val_loss: 21906562635.6564 - val_mean_absolute_error: 133576.6038\n",
      "Epoch 1211/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 20231461121.5329 - mean_absolute_error: 131843.1115 - val_loss: 21074259165.6907 - val_mean_absolute_error: 131075.7429\n",
      "Epoch 1212/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 20164362024.5133 - mean_absolute_error: 132068.7851 - val_loss: 22802542711.6426 - val_mean_absolute_error: 137279.8648\n",
      "Epoch 1213/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 362us/step - loss: 20585008438.0907 - mean_absolute_error: 132074.0799 - val_loss: 22300553701.6082 - val_mean_absolute_error: 135669.8781\n",
      "Epoch 1214/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 20344773458.5595 - mean_absolute_error: 132256.0039 - val_loss: 23200976171.1065 - val_mean_absolute_error: 137214.9486\n",
      "Epoch 1215/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 20443121826.9290 - mean_absolute_error: 131625.1995 - val_loss: 20634676125.4708 - val_mean_absolute_error: 129222.9204\n",
      "Epoch 1216/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 20160911188.3114 - mean_absolute_error: 131890.5613 - val_loss: 21315392353.6495 - val_mean_absolute_error: 131490.8495\n",
      "Epoch 1217/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 20207674342.5971 - mean_absolute_error: 131742.3936 - val_loss: 21334319533.3058 - val_mean_absolute_error: 131116.7902\n",
      "Epoch 1218/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 20117633321.8272 - mean_absolute_error: 131014.5157 - val_loss: 22205823546.0619 - val_mean_absolute_error: 133745.2810\n",
      "Epoch 1219/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 20471121566.9872 - mean_absolute_error: 132326.6905 - val_loss: 21274042375.0378 - val_mean_absolute_error: 130806.0191\n",
      "Epoch 1220/5000\n",
      "1169/1169 [==============================] - 0s 413us/step - loss: 20223227077.0915 - mean_absolute_error: 131815.0052 - val_loss: 20966136919.9725 - val_mean_absolute_error: 130940.2977\n",
      "Epoch 1221/5000\n",
      "1169/1169 [==============================] - 0s 404us/step - loss: 20101368829.3721 - mean_absolute_error: 131388.6631 - val_loss: 21469172655.0653 - val_mean_absolute_error: 131909.7458\n",
      "Epoch 1222/5000\n",
      "1169/1169 [==============================] - 0s 383us/step - loss: 19744704918.4465 - mean_absolute_error: 130568.0036 - val_loss: 22892060995.7388 - val_mean_absolute_error: 135748.3762\n",
      "Epoch 1223/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 20258963434.9769 - mean_absolute_error: 131604.8643 - val_loss: 21639993414.3780 - val_mean_absolute_error: 132016.1611\n",
      "Epoch 1224/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 19956621086.0017 - mean_absolute_error: 130941.7985 - val_loss: 21458852304.4948 - val_mean_absolute_error: 132605.6094\n",
      "Epoch 1225/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 20183336201.4166 - mean_absolute_error: 131473.8878 - val_loss: 22438426462.1306 - val_mean_absolute_error: 135214.0105\n",
      "Epoch 1226/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 19787501536.4654 - mean_absolute_error: 130550.0826 - val_loss: 21413285437.5808 - val_mean_absolute_error: 131494.1477\n",
      "Epoch 1227/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 19879414868.9683 - mean_absolute_error: 130416.9544 - val_loss: 20634860441.9519 - val_mean_absolute_error: 129143.0528\n",
      "Epoch 1228/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 20000502104.2532 - mean_absolute_error: 131093.0922 - val_loss: 21285344238.4055 - val_mean_absolute_error: 130953.6717\n",
      "Epoch 1229/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 20083870752.4106 - mean_absolute_error: 131096.1641 - val_loss: 20429989930.2268 - val_mean_absolute_error: 128349.8968\n",
      "Epoch 1230/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 19923873978.5800 - mean_absolute_error: 130671.4974 - val_loss: 21312991823.1753 - val_mean_absolute_error: 130799.7491\n",
      "Epoch 1231/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 19800265113.9504 - mean_absolute_error: 130497.2283 - val_loss: 19883696064.6598 - val_mean_absolute_error: 127122.9669\n",
      "Epoch 1232/5000\n",
      "1169/1169 [==============================] - 0s 395us/step - loss: 19706902568.2943 - mean_absolute_error: 130231.3471 - val_loss: 20399988422.8179 - val_mean_absolute_error: 128145.8111\n",
      "Epoch 1233/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 19810165471.8084 - mean_absolute_error: 130640.2298 - val_loss: 21094242296.9622 - val_mean_absolute_error: 130791.9780\n",
      "Epoch 1234/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 19668938717.8375 - mean_absolute_error: 130173.8558 - val_loss: 20905914966.2131 - val_mean_absolute_error: 130289.3820\n",
      "Epoch 1235/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 19659281505.2318 - mean_absolute_error: 130368.3892 - val_loss: 20864128559.5052 - val_mean_absolute_error: 128949.9737\n",
      "Epoch 1236/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 19650023238.2960 - mean_absolute_error: 130011.0391 - val_loss: 20905978369.7594 - val_mean_absolute_error: 129420.2087\n",
      "Epoch 1237/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 19657021278.8229 - mean_absolute_error: 129794.0085 - val_loss: 22491525190.3780 - val_mean_absolute_error: 134656.6549\n",
      "Epoch 1238/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 19584213437.8648 - mean_absolute_error: 129707.0435 - val_loss: 20686021311.7801 - val_mean_absolute_error: 129204.3039\n",
      "Epoch 1239/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 19661012243.0522 - mean_absolute_error: 129917.2336 - val_loss: 21590836030.4605 - val_mean_absolute_error: 131354.7919\n",
      "Epoch 1240/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 19591356251.3191 - mean_absolute_error: 129688.6399 - val_loss: 20009859701.8832 - val_mean_absolute_error: 126353.1971\n",
      "Epoch 1241/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 19836163200.7665 - mean_absolute_error: 130098.2546 - val_loss: 21050232670.1306 - val_mean_absolute_error: 129243.7302\n",
      "Epoch 1242/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 20005627975.8289 - mean_absolute_error: 130555.2797 - val_loss: 19330840998.2680 - val_mean_absolute_error: 124075.7997\n",
      "Epoch 1243/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 19573621163.4696 - mean_absolute_error: 129237.6020 - val_loss: 20559001951.8900 - val_mean_absolute_error: 127879.0544\n",
      "Epoch 1244/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 19230765464.1985 - mean_absolute_error: 128439.4396 - val_loss: 21071142658.6392 - val_mean_absolute_error: 130128.6003\n",
      "Epoch 1245/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 19473175358.4123 - mean_absolute_error: 129314.4834 - val_loss: 21222064620.6460 - val_mean_absolute_error: 130819.2942\n",
      "Epoch 1246/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 19279926017.0950 - mean_absolute_error: 128770.4847 - val_loss: 21409592928.7698 - val_mean_absolute_error: 131604.6863\n",
      "Epoch 1247/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 19271548255.2609 - mean_absolute_error: 128556.4619 - val_loss: 19415709703.0378 - val_mean_absolute_error: 125378.2694\n",
      "Epoch 1248/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 19677111438.7819 - mean_absolute_error: 129467.5172 - val_loss: 20398184595.7938 - val_mean_absolute_error: 127929.1134\n",
      "Epoch 1249/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 19348893329.8477 - mean_absolute_error: 129009.9367 - val_loss: 20719603676.8110 - val_mean_absolute_error: 128865.2483\n",
      "Epoch 1250/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 19362080356.2977 - mean_absolute_error: 129085.0522 - val_loss: 22679074407.8076 - val_mean_absolute_error: 134333.9360\n",
      "Epoch 1251/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 19855116799.5620 - mean_absolute_error: 129671.8021 - val_loss: 20791179334.3780 - val_mean_absolute_error: 129157.0691\n",
      "Epoch 1252/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 19392538709.8443 - mean_absolute_error: 128640.6901 - val_loss: 20424314053.0584 - val_mean_absolute_error: 127681.1887\n",
      "Epoch 1253/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 19588752924.4688 - mean_absolute_error: 129338.0739 - val_loss: 21276323861.1134 - val_mean_absolute_error: 129727.2844\n",
      "Epoch 1254/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 19315152556.1266 - mean_absolute_error: 128815.7362 - val_loss: 20812797871.0653 - val_mean_absolute_error: 128242.5772\n",
      "Epoch 1255/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 19113035500.9478 - mean_absolute_error: 127772.2640 - val_loss: 20709930276.0687 - val_mean_absolute_error: 128854.6685\n",
      "Epoch 1256/5000\n",
      "1169/1169 [==============================] - 0s 319us/step - loss: 19421095519.9179 - mean_absolute_error: 128819.7104 - val_loss: 20563178854.9278 - val_mean_absolute_error: 128939.0909\n",
      "Epoch 1257/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 19416217983.6715 - mean_absolute_error: 129058.8772 - val_loss: 19564370113.5395 - val_mean_absolute_error: 126254.5180\n",
      "Epoch 1258/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 19235363693.7143 - mean_absolute_error: 128585.0631 - val_loss: 18882124036.3986 - val_mean_absolute_error: 123677.4106\n",
      "Epoch 1259/5000\n",
      "1169/1169 [==============================] - 0s 307us/step - loss: 19541555995.3738 - mean_absolute_error: 129537.8593 - val_loss: 21879712504.0825 - val_mean_absolute_error: 132086.5023\n",
      "Epoch 1260/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 19172153348.3798 - mean_absolute_error: 127965.9173 - val_loss: 19153785183.8900 - val_mean_absolute_error: 123573.4363\n",
      "Epoch 1261/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 19095746871.8426 - mean_absolute_error: 127703.1579 - val_loss: 19827945201.0447 - val_mean_absolute_error: 125520.4345\n",
      "Epoch 1262/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 19136678366.2755 - mean_absolute_error: 128362.1387 - val_loss: 21557301029.8282 - val_mean_absolute_error: 131335.4088\n",
      "Epoch 1263/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 19395212085.6527 - mean_absolute_error: 128650.0124 - val_loss: 20765963168.9897 - val_mean_absolute_error: 128228.7762\n",
      "Epoch 1264/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 18986770590.5492 - mean_absolute_error: 127355.4858 - val_loss: 19661708235.2165 - val_mean_absolute_error: 125521.2855\n",
      "Epoch 1265/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 19053639030.9119 - mean_absolute_error: 127759.3554 - val_loss: 19700331076.6186 - val_mean_absolute_error: 125119.4319\n",
      "Epoch 1266/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 19218674713.4029 - mean_absolute_error: 127894.3604 - val_loss: 20354957150.1306 - val_mean_absolute_error: 127111.9436\n",
      "Epoch 1267/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 18983953925.6938 - mean_absolute_error: 127021.9492 - val_loss: 19932880195.7388 - val_mean_absolute_error: 126202.0333\n",
      "Epoch 1268/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 19159155596.3730 - mean_absolute_error: 127740.2756 - val_loss: 20999459906.8591 - val_mean_absolute_error: 129825.7944\n",
      "Epoch 1269/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 19041462222.9461 - mean_absolute_error: 127759.7719 - val_loss: 21316230534.5979 - val_mean_absolute_error: 131660.5356\n",
      "Epoch 1270/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 18826403538.6689 - mean_absolute_error: 126943.9113 - val_loss: 20764863484.4811 - val_mean_absolute_error: 129877.1525\n",
      "Epoch 1271/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 19085628696.3080 - mean_absolute_error: 128181.9159 - val_loss: 20434136507.3814 - val_mean_absolute_error: 129067.2900\n",
      "Epoch 1272/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 19152688705.2592 - mean_absolute_error: 127679.7656 - val_loss: 20945337136.3849 - val_mean_absolute_error: 130152.7716\n",
      "Epoch 1273/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 18737984935.9658 - mean_absolute_error: 126282.4885 - val_loss: 21667517387.2165 - val_mean_absolute_error: 132950.0465\n",
      "Epoch 1274/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 18794367830.9393 - mean_absolute_error: 126718.1227 - val_loss: 20418352902.1581 - val_mean_absolute_error: 128549.6352\n",
      "Epoch 1275/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 18959271775.6989 - mean_absolute_error: 127744.3738 - val_loss: 21204040510.4605 - val_mean_absolute_error: 130616.8316\n",
      "Epoch 1276/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 18922970316.0992 - mean_absolute_error: 127054.8015 - val_loss: 21515130338.0893 - val_mean_absolute_error: 132648.7629\n",
      "Epoch 1277/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 18864294001.8751 - mean_absolute_error: 126692.1967 - val_loss: 20913699794.2543 - val_mean_absolute_error: 129481.0275\n",
      "Epoch 1278/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 18832194155.3054 - mean_absolute_error: 126974.5184 - val_loss: 19925714176.8797 - val_mean_absolute_error: 126627.5668\n",
      "Epoch 1279/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 18881309211.5928 - mean_absolute_error: 126761.9116 - val_loss: 18639237436.7010 - val_mean_absolute_error: 121917.0465\n",
      "Epoch 1280/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 18422682847.3704 - mean_absolute_error: 125899.0441 - val_loss: 18907496099.6289 - val_mean_absolute_error: 123019.3378\n",
      "Epoch 1281/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 19041334717.8648 - mean_absolute_error: 128062.0191 - val_loss: 19593963720.5773 - val_mean_absolute_error: 125110.0535\n",
      "Epoch 1282/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 18683547094.3918 - mean_absolute_error: 125976.3436 - val_loss: 21690182912.8797 - val_mean_absolute_error: 132762.6182\n",
      "Epoch 1283/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 18698080983.0488 - mean_absolute_error: 126319.6173 - val_loss: 21361302165.5533 - val_mean_absolute_error: 132153.0981\n",
      "Epoch 1284/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 18711460269.2216 - mean_absolute_error: 126790.0229 - val_loss: 20238867776.2199 - val_mean_absolute_error: 127550.1537\n",
      "Epoch 1285/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 18605194897.8477 - mean_absolute_error: 126167.3791 - val_loss: 20169747684.7285 - val_mean_absolute_error: 127310.8858\n",
      "Epoch 1286/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 18481733423.5210 - mean_absolute_error: 125770.5554 - val_loss: 19219511366.3780 - val_mean_absolute_error: 123984.8399\n",
      "Epoch 1287/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 18496844869.2010 - mean_absolute_error: 125731.7340 - val_loss: 19769810440.7973 - val_mean_absolute_error: 125594.6300\n",
      "Epoch 1288/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 18365072214.9393 - mean_absolute_error: 125840.1873 - val_loss: 19300070667.4364 - val_mean_absolute_error: 125093.7217\n",
      "Epoch 1289/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 18618841126.5423 - mean_absolute_error: 125757.2142 - val_loss: 20182106284.4261 - val_mean_absolute_error: 128140.5992\n",
      "Epoch 1290/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 18545940867.1754 - mean_absolute_error: 126128.2402 - val_loss: 20213857628.3711 - val_mean_absolute_error: 127510.4066\n",
      "Epoch 1291/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 18321978812.9889 - mean_absolute_error: 125580.0815 - val_loss: 21188435320.5223 - val_mean_absolute_error: 131459.4205\n",
      "Epoch 1292/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 18448137022.4123 - mean_absolute_error: 125846.2295 - val_loss: 20441354986.0069 - val_mean_absolute_error: 128795.5417\n",
      "Epoch 1293/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 352us/step - loss: 18129604568.5817 - mean_absolute_error: 124851.6866 - val_loss: 19247950724.8385 - val_mean_absolute_error: 124526.6556\n",
      "Epoch 1294/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 18241172118.2275 - mean_absolute_error: 124976.7155 - val_loss: 20568783491.9588 - val_mean_absolute_error: 128416.8524\n",
      "Epoch 1295/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 18653102255.1925 - mean_absolute_error: 126324.2655 - val_loss: 19787776000.0000 - val_mean_absolute_error: 125784.5119\n",
      "Epoch 1296/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 18318088170.1009 - mean_absolute_error: 125230.4385 - val_loss: 19288111994.2818 - val_mean_absolute_error: 123535.7867\n",
      "Epoch 1297/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 18599254562.6005 - mean_absolute_error: 125577.4350 - val_loss: 19612106752.0000 - val_mean_absolute_error: 125107.9582\n",
      "Epoch 1298/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 18501685023.7536 - mean_absolute_error: 125338.6734 - val_loss: 20372754776.8522 - val_mean_absolute_error: 127314.0605\n",
      "Epoch 1299/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 18526119212.4551 - mean_absolute_error: 125996.8872 - val_loss: 19291883020.3162 - val_mean_absolute_error: 124208.3538\n",
      "Epoch 1300/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 18082181212.8520 - mean_absolute_error: 124883.6053 - val_loss: 19545194661.3883 - val_mean_absolute_error: 125135.2809\n",
      "Epoch 1301/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 18187619549.6185 - mean_absolute_error: 124571.6921 - val_loss: 19481140322.5292 - val_mean_absolute_error: 125289.8182\n",
      "Epoch 1302/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 18356886740.8589 - mean_absolute_error: 125393.5706 - val_loss: 20425909406.3505 - val_mean_absolute_error: 127839.0725\n",
      "Epoch 1303/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 18088324345.6493 - mean_absolute_error: 124308.4097 - val_loss: 18812403824.6048 - val_mean_absolute_error: 123339.2713\n",
      "Epoch 1304/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 18158949977.7861 - mean_absolute_error: 124889.5208 - val_loss: 19498306190.5155 - val_mean_absolute_error: 124920.4622\n",
      "Epoch 1305/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 18177250865.4919 - mean_absolute_error: 124573.9445 - val_loss: 19514717148.8110 - val_mean_absolute_error: 124843.6803\n",
      "Epoch 1306/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 18225060816.6980 - mean_absolute_error: 124869.6128 - val_loss: 19443102403.2990 - val_mean_absolute_error: 124985.4136\n",
      "Epoch 1307/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 18236596177.5740 - mean_absolute_error: 124608.0569 - val_loss: 19374299452.7010 - val_mean_absolute_error: 124407.1357\n",
      "Epoch 1308/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 17958465652.5030 - mean_absolute_error: 124304.2682 - val_loss: 19335973659.2715 - val_mean_absolute_error: 124550.2167\n",
      "Epoch 1309/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 17977601993.6903 - mean_absolute_error: 123960.2774 - val_loss: 18658857058.5292 - val_mean_absolute_error: 121644.1590\n",
      "Epoch 1310/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 18085057272.3353 - mean_absolute_error: 124296.9731 - val_loss: 20456001071.5052 - val_mean_absolute_error: 127567.9180\n",
      "Epoch 1311/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 17951921918.4671 - mean_absolute_error: 123853.8149 - val_loss: 19181323619.4089 - val_mean_absolute_error: 123628.9785\n",
      "Epoch 1312/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 17979215199.2609 - mean_absolute_error: 123794.4860 - val_loss: 19586017417.2371 - val_mean_absolute_error: 124783.4444\n",
      "Epoch 1313/5000\n",
      "1169/1169 [==============================] - 0s 313us/step - loss: 18199022048.0274 - mean_absolute_error: 124357.0423 - val_loss: 19219451003.1615 - val_mean_absolute_error: 123475.7214\n",
      "Epoch 1314/5000\n",
      "1169/1169 [==============================] - 0s 300us/step - loss: 17856812812.9204 - mean_absolute_error: 123608.6920 - val_loss: 20840607022.6254 - val_mean_absolute_error: 129183.7247\n",
      "Epoch 1315/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 17962456664.0342 - mean_absolute_error: 123861.5406 - val_loss: 19102425028.1787 - val_mean_absolute_error: 123095.1927\n",
      "Epoch 1316/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 17732803753.0607 - mean_absolute_error: 123223.9427 - val_loss: 18795274968.4124 - val_mean_absolute_error: 121587.0748\n",
      "Epoch 1317/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 18212318156.3182 - mean_absolute_error: 124284.7847 - val_loss: 18322100948.8935 - val_mean_absolute_error: 121155.8722\n",
      "Epoch 1318/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 17596646621.6185 - mean_absolute_error: 122972.3397 - val_loss: 18507559763.5739 - val_mean_absolute_error: 122359.8027\n",
      "Epoch 1319/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 18015428511.6441 - mean_absolute_error: 124019.5320 - val_loss: 18959529818.6117 - val_mean_absolute_error: 123448.5077\n",
      "Epoch 1320/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 17746376586.6210 - mean_absolute_error: 123367.2790 - val_loss: 19371540919.8625 - val_mean_absolute_error: 125291.6718\n",
      "Epoch 1321/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 17764107911.3362 - mean_absolute_error: 123093.5290 - val_loss: 18310254254.1856 - val_mean_absolute_error: 121159.4403\n",
      "Epoch 1322/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 17942172264.6775 - mean_absolute_error: 123549.8516 - val_loss: 19440741903.8351 - val_mean_absolute_error: 125361.5579\n",
      "Epoch 1323/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 17440692898.4910 - mean_absolute_error: 122664.3744 - val_loss: 18085745885.6907 - val_mean_absolute_error: 120262.1354\n",
      "Epoch 1324/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 17797248840.0479 - mean_absolute_error: 123146.5872 - val_loss: 19855890379.2165 - val_mean_absolute_error: 126743.7458\n",
      "Epoch 1325/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 17437951181.4132 - mean_absolute_error: 122529.7541 - val_loss: 17008032078.2955 - val_mean_absolute_error: 116864.6370\n",
      "Epoch 1326/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 17632503685.3653 - mean_absolute_error: 122835.8104 - val_loss: 19132971208.5773 - val_mean_absolute_error: 124206.8462\n",
      "Epoch 1327/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 17548484647.4183 - mean_absolute_error: 122270.4214 - val_loss: 18297687131.4914 - val_mean_absolute_error: 120885.5616\n",
      "Epoch 1328/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 17756356564.2019 - mean_absolute_error: 122576.4352 - val_loss: 18835275944.9072 - val_mean_absolute_error: 123185.1127\n",
      "Epoch 1329/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 17522710787.2849 - mean_absolute_error: 122118.7593 - val_loss: 18076648370.5842 - val_mean_absolute_error: 120414.4679\n",
      "Epoch 1330/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 17496555456.4927 - mean_absolute_error: 122485.6146 - val_loss: 17534052513.8694 - val_mean_absolute_error: 118281.1212\n",
      "Epoch 1331/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 17523855179.5518 - mean_absolute_error: 122240.9428 - val_loss: 18767149956.8385 - val_mean_absolute_error: 123183.8151\n",
      "Epoch 1332/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 17599545645.3311 - mean_absolute_error: 121773.0816 - val_loss: 17832948088.5223 - val_mean_absolute_error: 119414.0411\n",
      "Epoch 1333/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 17336302687.4799 - mean_absolute_error: 122273.9387 - val_loss: 18390112175.0653 - val_mean_absolute_error: 121308.3312\n",
      "Epoch 1334/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 17353960537.3482 - mean_absolute_error: 121586.9981 - val_loss: 18121410591.6701 - val_mean_absolute_error: 121021.9853\n",
      "Epoch 1335/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 17398892016.6707 - mean_absolute_error: 121657.8571 - val_loss: 18160540172.3162 - val_mean_absolute_error: 121136.9601\n",
      "Epoch 1336/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 17199240024.6912 - mean_absolute_error: 121055.7487 - val_loss: 18089521243.4914 - val_mean_absolute_error: 120378.4543\n",
      "Epoch 1337/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 17557016338.6142 - mean_absolute_error: 122227.6181 - val_loss: 19385196536.9622 - val_mean_absolute_error: 123997.2060\n",
      "Epoch 1338/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 17336561514.2104 - mean_absolute_error: 121558.1925 - val_loss: 18608005454.2955 - val_mean_absolute_error: 122703.9234\n",
      "Epoch 1339/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 17427574060.4551 - mean_absolute_error: 121665.5496 - val_loss: 17736076770.0893 - val_mean_absolute_error: 119280.4583\n",
      "Epoch 1340/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 17684984710.2412 - mean_absolute_error: 122521.7511 - val_loss: 18269831136.3299 - val_mean_absolute_error: 119939.4934\n",
      "Epoch 1341/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 17393773544.3490 - mean_absolute_error: 121359.0142 - val_loss: 18113786155.1065 - val_mean_absolute_error: 119622.1098\n",
      "Epoch 1342/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 17455918311.2541 - mean_absolute_error: 122103.4900 - val_loss: 17618504633.6220 - val_mean_absolute_error: 118615.9521\n",
      "Epoch 1343/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 16932940986.5800 - mean_absolute_error: 120776.3113 - val_loss: 18657258203.9313 - val_mean_absolute_error: 122934.3917\n",
      "Epoch 1344/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 17088408469.1326 - mean_absolute_error: 120633.7376 - val_loss: 18883720068.8385 - val_mean_absolute_error: 123014.4893\n",
      "Epoch 1345/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 17408318536.7049 - mean_absolute_error: 121563.9119 - val_loss: 20742492825.0722 - val_mean_absolute_error: 128380.7669\n",
      "Epoch 1346/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 17501702793.0881 - mean_absolute_error: 121481.2496 - val_loss: 17658808017.3746 - val_mean_absolute_error: 118080.0880\n",
      "Epoch 1347/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 17229451295.5346 - mean_absolute_error: 121476.4523 - val_loss: 18638373018.8316 - val_mean_absolute_error: 121718.5160\n",
      "Epoch 1348/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 17040844331.3601 - mean_absolute_error: 120465.5938 - val_loss: 18402755812.7285 - val_mean_absolute_error: 121279.1111\n",
      "Epoch 1349/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 17045024874.8674 - mean_absolute_error: 120976.7552 - val_loss: 18939404541.3608 - val_mean_absolute_error: 121988.0696\n",
      "Epoch 1350/5000\n",
      "1169/1169 [==============================] - 0s 378us/step - loss: 17006581225.6630 - mean_absolute_error: 120363.0826 - val_loss: 17699822507.5464 - val_mean_absolute_error: 119041.6162\n",
      "Epoch 1351/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 16852255969.1223 - mean_absolute_error: 119737.8782 - val_loss: 17374467958.7629 - val_mean_absolute_error: 117715.9351\n",
      "Epoch 1352/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 16563821349.8854 - mean_absolute_error: 119386.2054 - val_loss: 19094470261.8832 - val_mean_absolute_error: 123727.8066\n",
      "Epoch 1353/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 17117026354.8058 - mean_absolute_error: 119918.0757 - val_loss: 19899306226.8041 - val_mean_absolute_error: 126468.5145\n",
      "Epoch 1354/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 16959615251.0522 - mean_absolute_error: 120215.9744 - val_loss: 19770847397.3883 - val_mean_absolute_error: 126921.9793\n",
      "Epoch 1355/5000\n",
      "1169/1169 [==============================] - 0s 389us/step - loss: 16991187774.4123 - mean_absolute_error: 120775.2369 - val_loss: 19109801632.1100 - val_mean_absolute_error: 123533.8028\n",
      "Epoch 1356/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 17090770662.8161 - mean_absolute_error: 120477.7874 - val_loss: 18232921503.2302 - val_mean_absolute_error: 121626.5891\n",
      "Epoch 1357/5000\n",
      "1169/1169 [==============================] - 0s 310us/step - loss: 16820178351.8494 - mean_absolute_error: 119863.7916 - val_loss: 18805830965.6632 - val_mean_absolute_error: 123980.9748\n",
      "Epoch 1358/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 17359761856.4927 - mean_absolute_error: 120976.6022 - val_loss: 17981659962.9416 - val_mean_absolute_error: 120405.0376\n",
      "Epoch 1359/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 16870881600.6022 - mean_absolute_error: 120122.5627 - val_loss: 17288070217.8969 - val_mean_absolute_error: 116864.4969\n",
      "Epoch 1360/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 16735865740.3730 - mean_absolute_error: 119334.7559 - val_loss: 17968295372.9759 - val_mean_absolute_error: 119419.4553\n",
      "Epoch 1361/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 16778269474.3815 - mean_absolute_error: 119682.2578 - val_loss: 18224466433.7594 - val_mean_absolute_error: 120768.1243\n",
      "Epoch 1362/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 16878408969.4166 - mean_absolute_error: 119352.3219 - val_loss: 18564251296.1100 - val_mean_absolute_error: 122083.1991\n",
      "Epoch 1363/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 16810629356.5098 - mean_absolute_error: 119439.7728 - val_loss: 18483530787.1890 - val_mean_absolute_error: 121407.4461\n",
      "Epoch 1364/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 17061713674.7305 - mean_absolute_error: 120314.0710 - val_loss: 17434626695.4777 - val_mean_absolute_error: 118188.4778\n",
      "Epoch 1365/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 16799145496.9649 - mean_absolute_error: 119771.5777 - val_loss: 17998523606.6529 - val_mean_absolute_error: 120039.0501\n",
      "Epoch 1366/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 17168534870.5013 - mean_absolute_error: 120015.4064 - val_loss: 17888009990.1581 - val_mean_absolute_error: 118530.9789\n",
      "Epoch 1367/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 16790293676.5646 - mean_absolute_error: 119865.9907 - val_loss: 18103969612.5361 - val_mean_absolute_error: 119820.6490\n",
      "Epoch 1368/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 16573390161.2455 - mean_absolute_error: 119268.5601 - val_loss: 17791060538.0619 - val_mean_absolute_error: 118820.1127\n",
      "Epoch 1369/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 16598688373.8169 - mean_absolute_error: 118843.9614 - val_loss: 16925960051.2440 - val_mean_absolute_error: 116303.3178\n",
      "Epoch 1370/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 16723091053.9333 - mean_absolute_error: 119381.7195 - val_loss: 18178138460.3711 - val_mean_absolute_error: 120077.7492\n",
      "Epoch 1371/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 16542882697.7451 - mean_absolute_error: 119170.4159 - val_loss: 17812174379.9863 - val_mean_absolute_error: 119397.9936\n",
      "Epoch 1372/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 16519472666.7169 - mean_absolute_error: 118431.8188 - val_loss: 16391740349.1409 - val_mean_absolute_error: 115053.9527\n",
      "Epoch 1373/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 351us/step - loss: 16854330302.3028 - mean_absolute_error: 119087.5487 - val_loss: 17673405911.5326 - val_mean_absolute_error: 118582.2212\n",
      "Epoch 1374/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 16516989343.2062 - mean_absolute_error: 118334.3615 - val_loss: 16282214533.7182 - val_mean_absolute_error: 114049.5244\n",
      "Epoch 1375/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 16492211101.0163 - mean_absolute_error: 118126.5501 - val_loss: 17993795151.1753 - val_mean_absolute_error: 119246.8268\n",
      "Epoch 1376/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 16383297407.2335 - mean_absolute_error: 118740.1635 - val_loss: 17528450501.9381 - val_mean_absolute_error: 117854.3108\n",
      "Epoch 1377/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 16395056102.1591 - mean_absolute_error: 118509.6257 - val_loss: 16210446248.0275 - val_mean_absolute_error: 113841.8035\n",
      "Epoch 1378/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 16422311261.5090 - mean_absolute_error: 118266.4243 - val_loss: 18165595533.6357 - val_mean_absolute_error: 119010.6546\n",
      "Epoch 1379/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 16328840191.1240 - mean_absolute_error: 118309.3493 - val_loss: 18113098998.3230 - val_mean_absolute_error: 119469.5124\n",
      "Epoch 1380/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 16548852462.6997 - mean_absolute_error: 118368.7625 - val_loss: 18285155947.3265 - val_mean_absolute_error: 120867.9714\n",
      "Epoch 1381/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 16176176319.8358 - mean_absolute_error: 117891.5866 - val_loss: 18323345059.6289 - val_mean_absolute_error: 121496.9223\n",
      "Epoch 1382/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 16337826025.0060 - mean_absolute_error: 117516.1971 - val_loss: 17590549834.7766 - val_mean_absolute_error: 118919.4795\n",
      "Epoch 1383/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 16887095718.2139 - mean_absolute_error: 119519.4220 - val_loss: 17957204326.9278 - val_mean_absolute_error: 119541.4080\n",
      "Epoch 1384/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 16243942786.2994 - mean_absolute_error: 117802.7619 - val_loss: 18165062670.0756 - val_mean_absolute_error: 120270.9805\n",
      "Epoch 1385/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 16155738851.3122 - mean_absolute_error: 117674.0056 - val_loss: 18601941291.1065 - val_mean_absolute_error: 122100.1755\n",
      "Epoch 1386/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 16495031285.4885 - mean_absolute_error: 118119.7049 - val_loss: 16962003654.8179 - val_mean_absolute_error: 117042.1523\n",
      "Epoch 1387/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 16300952848.4243 - mean_absolute_error: 117430.2372 - val_loss: 16440864648.3574 - val_mean_absolute_error: 114782.7422\n",
      "Epoch 1388/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 16496897972.6672 - mean_absolute_error: 117536.1290 - val_loss: 16519831625.8969 - val_mean_absolute_error: 113836.4951\n",
      "Epoch 1389/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 16246675706.9632 - mean_absolute_error: 116744.1353 - val_loss: 16888733752.3024 - val_mean_absolute_error: 115929.1271\n",
      "Epoch 1390/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 15861496704.1095 - mean_absolute_error: 116759.7545 - val_loss: 17767526604.0962 - val_mean_absolute_error: 119078.4780\n",
      "Epoch 1391/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 16572700479.2883 - mean_absolute_error: 118293.8460 - val_loss: 17095299870.7904 - val_mean_absolute_error: 115790.9845\n",
      "Epoch 1392/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 16366638300.7425 - mean_absolute_error: 116971.9278 - val_loss: 17125309059.9588 - val_mean_absolute_error: 115850.7080\n",
      "Epoch 1393/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 15894524343.7331 - mean_absolute_error: 116276.7426 - val_loss: 14942261181.1409 - val_mean_absolute_error: 107483.3544\n",
      "Epoch 1394/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 16013395664.9170 - mean_absolute_error: 116874.9226 - val_loss: 16499606042.3918 - val_mean_absolute_error: 114195.0648\n",
      "Epoch 1395/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 16023929284.8725 - mean_absolute_error: 116863.7034 - val_loss: 17300433617.3746 - val_mean_absolute_error: 117851.9924\n",
      "Epoch 1396/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 16088435277.5227 - mean_absolute_error: 117020.6293 - val_loss: 17393168830.9003 - val_mean_absolute_error: 118319.4652\n",
      "Epoch 1397/5000\n",
      "1169/1169 [==============================] - 0s 319us/step - loss: 16115578525.2352 - mean_absolute_error: 117071.8928 - val_loss: 16848255246.9553 - val_mean_absolute_error: 116349.6132\n",
      "Epoch 1398/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 16062675865.5124 - mean_absolute_error: 116081.0436 - val_loss: 16191231173.0584 - val_mean_absolute_error: 114209.1825\n",
      "Epoch 1399/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 15915851010.4089 - mean_absolute_error: 116032.5637 - val_loss: 17949305074.8041 - val_mean_absolute_error: 119495.8675\n",
      "Epoch 1400/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 16023043002.7990 - mean_absolute_error: 116330.7820 - val_loss: 17922730518.8729 - val_mean_absolute_error: 119412.7912\n",
      "Epoch 1401/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 16013375503.7673 - mean_absolute_error: 116512.7394 - val_loss: 17909684649.7869 - val_mean_absolute_error: 119567.0140\n",
      "Epoch 1402/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 16052559135.3157 - mean_absolute_error: 116398.0959 - val_loss: 16999141126.1581 - val_mean_absolute_error: 116835.2686\n",
      "Epoch 1403/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 15648551491.8871 - mean_absolute_error: 116339.0000 - val_loss: 16541847868.7010 - val_mean_absolute_error: 114971.6429\n",
      "Epoch 1404/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 15641571347.2712 - mean_absolute_error: 115202.6831 - val_loss: 18398328891.8213 - val_mean_absolute_error: 120954.5703\n",
      "Epoch 1405/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 15667194695.1719 - mean_absolute_error: 115728.2317 - val_loss: 18221665779.6838 - val_mean_absolute_error: 120664.0295\n",
      "Epoch 1406/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 15991365926.3234 - mean_absolute_error: 115620.5767 - val_loss: 18031978805.6632 - val_mean_absolute_error: 119010.8486\n",
      "Epoch 1407/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 15664097280.0000 - mean_absolute_error: 115665.7517 - val_loss: 17200998174.7904 - val_mean_absolute_error: 116995.5605\n",
      "Epoch 1408/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 15913723816.4038 - mean_absolute_error: 116341.3387 - val_loss: 17123782268.9210 - val_mean_absolute_error: 115938.0253\n",
      "Epoch 1409/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 15584801759.5894 - mean_absolute_error: 115653.7677 - val_loss: 16601029709.4158 - val_mean_absolute_error: 114877.9945\n",
      "Epoch 1410/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 15349499418.7169 - mean_absolute_error: 114865.2982 - val_loss: 17110097673.6770 - val_mean_absolute_error: 115843.6604\n",
      "Epoch 1411/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 15695198216.7596 - mean_absolute_error: 115532.9952 - val_loss: 17652840638.0206 - val_mean_absolute_error: 118374.5297\n",
      "Epoch 1412/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 15646789128.3216 - mean_absolute_error: 114671.6469 - val_loss: 16872094818.5292 - val_mean_absolute_error: 115736.7105\n",
      "Epoch 1413/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 15959575354.9085 - mean_absolute_error: 115743.0272 - val_loss: 16260675770.5017 - val_mean_absolute_error: 114086.9225\n",
      "Epoch 1414/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 15958736665.6219 - mean_absolute_error: 115771.6295 - val_loss: 16363205072.4948 - val_mean_absolute_error: 113527.6408\n",
      "Epoch 1415/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 15594810705.2455 - mean_absolute_error: 114593.7853 - val_loss: 17337803540.2337 - val_mean_absolute_error: 116486.9602\n",
      "Epoch 1416/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 15868089438.6039 - mean_absolute_error: 115022.6975 - val_loss: 17401712478.1306 - val_mean_absolute_error: 118126.6048\n",
      "Epoch 1417/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 15813147375.5757 - mean_absolute_error: 115764.9778 - val_loss: 16034791241.0172 - val_mean_absolute_error: 112529.0765\n",
      "Epoch 1418/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 15663047950.6724 - mean_absolute_error: 114966.4799 - val_loss: 17108579152.0550 - val_mean_absolute_error: 115882.2890\n",
      "Epoch 1419/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 15823776683.0317 - mean_absolute_error: 114841.0389 - val_loss: 16872083132.2612 - val_mean_absolute_error: 116355.0504\n",
      "Epoch 1420/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 15838698709.7348 - mean_absolute_error: 114921.6991 - val_loss: 17206290815.5601 - val_mean_absolute_error: 117113.7508\n",
      "Epoch 1421/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 15899566055.9110 - mean_absolute_error: 115243.8467 - val_loss: 16056322924.2062 - val_mean_absolute_error: 113438.8237\n",
      "Epoch 1422/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 15705140121.5124 - mean_absolute_error: 115153.7478 - val_loss: 17794598788.8385 - val_mean_absolute_error: 118662.5553\n",
      "Epoch 1423/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 15401350001.2181 - mean_absolute_error: 113920.1433 - val_loss: 16112647403.7663 - val_mean_absolute_error: 112909.8497\n",
      "Epoch 1424/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 15439213516.3182 - mean_absolute_error: 114547.8850 - val_loss: 16235202971.7113 - val_mean_absolute_error: 113447.3142\n",
      "Epoch 1425/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 15168329552.8075 - mean_absolute_error: 113625.0085 - val_loss: 15788793475.9588 - val_mean_absolute_error: 112403.3858\n",
      "Epoch 1426/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 15499811578.0873 - mean_absolute_error: 114946.8607 - val_loss: 15279924723.6838 - val_mean_absolute_error: 110286.1174\n",
      "Epoch 1427/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 15314981163.5791 - mean_absolute_error: 114110.8718 - val_loss: 16327283317.8832 - val_mean_absolute_error: 113927.5113\n",
      "Epoch 1428/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 15685506672.9991 - mean_absolute_error: 114715.8603 - val_loss: 17039705422.2955 - val_mean_absolute_error: 116364.3341\n",
      "Epoch 1429/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 15305687464.8417 - mean_absolute_error: 113484.2525 - val_loss: 17478791168.0000 - val_mean_absolute_error: 118117.1239\n",
      "Epoch 1430/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 15452456406.3918 - mean_absolute_error: 113957.9847 - val_loss: 18129173043.0241 - val_mean_absolute_error: 119684.6872\n",
      "Epoch 1431/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 15476652950.0086 - mean_absolute_error: 114217.1927 - val_loss: 17003536208.0550 - val_mean_absolute_error: 115917.6430\n",
      "Epoch 1432/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 15348286150.4055 - mean_absolute_error: 113591.2525 - val_loss: 16838607956.4536 - val_mean_absolute_error: 114743.6324\n",
      "Epoch 1433/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 15424986866.2036 - mean_absolute_error: 113541.2678 - val_loss: 15850082230.1031 - val_mean_absolute_error: 110846.8312\n",
      "Epoch 1434/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 15225846732.3182 - mean_absolute_error: 113345.4576 - val_loss: 15857490335.2302 - val_mean_absolute_error: 111510.0656\n",
      "Epoch 1435/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 15493340371.9829 - mean_absolute_error: 114561.9388 - val_loss: 16118430825.5670 - val_mean_absolute_error: 112366.1931\n",
      "Epoch 1436/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 15338033586.4773 - mean_absolute_error: 113274.4448 - val_loss: 16392179792.9347 - val_mean_absolute_error: 113804.2602\n",
      "Epoch 1437/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 15129311567.4936 - mean_absolute_error: 113474.9112 - val_loss: 17444003062.3230 - val_mean_absolute_error: 116267.2667\n",
      "Epoch 1438/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 15209564322.9290 - mean_absolute_error: 112655.4790 - val_loss: 16227467591.2577 - val_mean_absolute_error: 113064.5026\n",
      "Epoch 1439/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 15323181653.4063 - mean_absolute_error: 113710.4498 - val_loss: 16349210113.7595 - val_mean_absolute_error: 113624.4335\n",
      "Epoch 1440/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 15200644913.2729 - mean_absolute_error: 113207.6083 - val_loss: 14128214860.5361 - val_mean_absolute_error: 104980.7620\n",
      "Epoch 1441/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 15362601093.1463 - mean_absolute_error: 113766.1229 - val_loss: 16073446910.2405 - val_mean_absolute_error: 112928.9021\n",
      "Epoch 1442/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 15093541427.2438 - mean_absolute_error: 113144.5132 - val_loss: 16228529387.7663 - val_mean_absolute_error: 112929.7462\n",
      "Epoch 1443/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 15260693345.0128 - mean_absolute_error: 113074.0633 - val_loss: 14618475280.7148 - val_mean_absolute_error: 105460.7319\n",
      "Epoch 1444/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 15391162730.6484 - mean_absolute_error: 112903.5110 - val_loss: 15362770616.7423 - val_mean_absolute_error: 108697.1570\n",
      "Epoch 1445/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 15051770233.5398 - mean_absolute_error: 112609.0037 - val_loss: 14091740740.6186 - val_mean_absolute_error: 105071.6383\n",
      "Epoch 1446/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 14962453935.8494 - mean_absolute_error: 112831.9111 - val_loss: 15521814028.3162 - val_mean_absolute_error: 110055.3392\n",
      "Epoch 1447/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 14767660643.4217 - mean_absolute_error: 111229.4335 - val_loss: 16340707349.1134 - val_mean_absolute_error: 113447.9905\n",
      "Epoch 1448/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 14878138669.3311 - mean_absolute_error: 111713.5494 - val_loss: 16784035164.3711 - val_mean_absolute_error: 114020.0493\n",
      "Epoch 1449/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 15056156235.7707 - mean_absolute_error: 112847.5380 - val_loss: 15632215500.9759 - val_mean_absolute_error: 109987.5075\n",
      "Epoch 1450/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 15214614298.4979 - mean_absolute_error: 112651.0875 - val_loss: 16420603523.9588 - val_mean_absolute_error: 113173.3653\n",
      "Epoch 1451/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 15005932231.2814 - mean_absolute_error: 112212.3632 - val_loss: 16631008801.4296 - val_mean_absolute_error: 114512.2619\n",
      "Epoch 1452/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 14739244893.0710 - mean_absolute_error: 111849.4399 - val_loss: 15758729036.5361 - val_mean_absolute_error: 110966.5288\n",
      "Epoch 1453/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 348us/step - loss: 14589361152.8760 - mean_absolute_error: 111052.6261 - val_loss: 15298169792.6598 - val_mean_absolute_error: 110197.7920\n",
      "Epoch 1454/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 14380314361.6493 - mean_absolute_error: 110020.5289 - val_loss: 16138596218.2818 - val_mean_absolute_error: 112215.9587\n",
      "Epoch 1455/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 14704567053.7964 - mean_absolute_error: 111227.1860 - val_loss: 16044697814.6529 - val_mean_absolute_error: 110575.2753\n",
      "Epoch 1456/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 14475321321.0060 - mean_absolute_error: 110107.0999 - val_loss: 15072597372.0412 - val_mean_absolute_error: 108362.3121\n",
      "Epoch 1457/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 14672391422.9050 - mean_absolute_error: 111185.4544 - val_loss: 14897172399.0653 - val_mean_absolute_error: 108201.8503\n",
      "Epoch 1458/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 14441820969.3892 - mean_absolute_error: 110896.0462 - val_loss: 15810317878.5430 - val_mean_absolute_error: 111044.4408\n",
      "Epoch 1459/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 14444260935.3909 - mean_absolute_error: 110870.6983 - val_loss: 15964905387.5464 - val_mean_absolute_error: 111304.6869\n",
      "Epoch 1460/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 14711792567.2951 - mean_absolute_error: 110977.7259 - val_loss: 15711230873.9519 - val_mean_absolute_error: 111841.4313\n",
      "Epoch 1461/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 14736866477.4405 - mean_absolute_error: 111615.5353 - val_loss: 14862902873.7320 - val_mean_absolute_error: 107651.9901\n",
      "Epoch 1462/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 14533307438.4260 - mean_absolute_error: 111123.4147 - val_loss: 16373771123.2440 - val_mean_absolute_error: 112444.5127\n",
      "Epoch 1463/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 14430370229.9812 - mean_absolute_error: 110046.4689 - val_loss: 16627529537.9794 - val_mean_absolute_error: 113539.8901\n",
      "Epoch 1464/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 14457592226.7100 - mean_absolute_error: 110174.8620 - val_loss: 15911795648.6598 - val_mean_absolute_error: 112244.3948\n",
      "Epoch 1465/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 14533502893.6595 - mean_absolute_error: 110573.2140 - val_loss: 15575758443.3265 - val_mean_absolute_error: 110579.2086\n",
      "Epoch 1466/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 14703579693.1121 - mean_absolute_error: 111103.9780 - val_loss: 14886132602.2818 - val_mean_absolute_error: 108161.8745\n",
      "Epoch 1467/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 14888778264.9649 - mean_absolute_error: 111745.5601 - val_loss: 15460285746.1443 - val_mean_absolute_error: 109180.0309\n",
      "Epoch 1468/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 14755229272.9102 - mean_absolute_error: 110571.1488 - val_loss: 14872721066.6667 - val_mean_absolute_error: 108138.5237\n",
      "Epoch 1469/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 14295081653.7622 - mean_absolute_error: 110392.9282 - val_loss: 15579746912.7698 - val_mean_absolute_error: 111653.8232\n",
      "Epoch 1470/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 14916546533.7211 - mean_absolute_error: 110301.2936 - val_loss: 15509622488.4124 - val_mean_absolute_error: 110761.9965\n",
      "Epoch 1471/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 14279430748.4140 - mean_absolute_error: 109764.4048 - val_loss: 15441977034.3368 - val_mean_absolute_error: 110172.8897\n",
      "Epoch 1472/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 14566247037.7006 - mean_absolute_error: 110920.5267 - val_loss: 14958336907.8763 - val_mean_absolute_error: 108611.5077\n",
      "Epoch 1473/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 14058766580.3935 - mean_absolute_error: 109171.9923 - val_loss: 16507425570.3093 - val_mean_absolute_error: 114603.3896\n",
      "Epoch 1474/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 14482565785.7314 - mean_absolute_error: 110509.6767 - val_loss: 15123910659.5189 - val_mean_absolute_error: 110686.5848\n",
      "Epoch 1475/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 14392056191.6715 - mean_absolute_error: 109743.7749 - val_loss: 15539223150.8454 - val_mean_absolute_error: 111032.5333\n",
      "Epoch 1476/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 14466189103.5210 - mean_absolute_error: 110044.6607 - val_loss: 15474428368.4948 - val_mean_absolute_error: 110669.5109\n",
      "Epoch 1477/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 14470667122.9701 - mean_absolute_error: 109672.3350 - val_loss: 14861613956.8385 - val_mean_absolute_error: 106993.0089\n",
      "Epoch 1478/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 14239689707.8529 - mean_absolute_error: 109021.5212 - val_loss: 16374817777.9244 - val_mean_absolute_error: 111776.5674\n",
      "Epoch 1479/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 14398075861.9538 - mean_absolute_error: 109883.6514 - val_loss: 16419308181.5533 - val_mean_absolute_error: 112045.9463\n",
      "Epoch 1480/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 14099563951.8494 - mean_absolute_error: 109063.8819 - val_loss: 15436114261.3333 - val_mean_absolute_error: 109449.7841\n",
      "Epoch 1481/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 14021396354.7374 - mean_absolute_error: 109736.1067 - val_loss: 16014719204.7285 - val_mean_absolute_error: 111620.6594\n",
      "Epoch 1482/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 14191394991.1925 - mean_absolute_error: 108415.4975 - val_loss: 15099637031.5876 - val_mean_absolute_error: 108799.4247\n",
      "Epoch 1483/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 14427927953.1908 - mean_absolute_error: 110314.8785 - val_loss: 15350484224.8797 - val_mean_absolute_error: 109700.9214\n",
      "Epoch 1484/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 14559610313.2524 - mean_absolute_error: 109914.3841 - val_loss: 16348717003.2165 - val_mean_absolute_error: 114714.8213\n",
      "Epoch 1485/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 14161993665.8067 - mean_absolute_error: 109366.8545 - val_loss: 16447133178.7216 - val_mean_absolute_error: 113037.4674\n",
      "Epoch 1486/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 14094760954.7442 - mean_absolute_error: 109141.8842 - val_loss: 14752871740.7010 - val_mean_absolute_error: 107252.0973\n",
      "Epoch 1487/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 14204222217.8546 - mean_absolute_error: 108480.0675 - val_loss: 15507656718.0756 - val_mean_absolute_error: 110336.3569\n",
      "Epoch 1488/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 14131117205.7896 - mean_absolute_error: 108729.7800 - val_loss: 14353045458.2543 - val_mean_absolute_error: 105817.9532\n",
      "Epoch 1489/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 13772807508.7494 - mean_absolute_error: 107355.9509 - val_loss: 14427601078.9828 - val_mean_absolute_error: 104971.9945\n",
      "Epoch 1490/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 13959657472.0000 - mean_absolute_error: 108330.0558 - val_loss: 14605150186.8866 - val_mean_absolute_error: 105622.9115\n",
      "Epoch 1491/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 14451667131.4559 - mean_absolute_error: 108911.0257 - val_loss: 15028660319.0103 - val_mean_absolute_error: 107766.2116\n",
      "Epoch 1492/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 14116916184.5817 - mean_absolute_error: 108125.3404 - val_loss: 15527192459.8763 - val_mean_absolute_error: 109751.4182\n",
      "Epoch 1493/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 13869639017.7725 - mean_absolute_error: 107184.0035 - val_loss: 13831475277.4158 - val_mean_absolute_error: 103563.3511\n",
      "Epoch 1494/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 13624276587.3054 - mean_absolute_error: 106951.9178 - val_loss: 13666334501.8282 - val_mean_absolute_error: 103468.3555\n",
      "Epoch 1495/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 13955100986.9085 - mean_absolute_error: 108372.3757 - val_loss: 14419399595.5464 - val_mean_absolute_error: 105724.9235\n",
      "Epoch 1496/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 13910854327.5141 - mean_absolute_error: 108149.1210 - val_loss: 14362666244.3986 - val_mean_absolute_error: 105589.1877\n",
      "Epoch 1497/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 13988326709.2147 - mean_absolute_error: 108025.9796 - val_loss: 13541399661.0859 - val_mean_absolute_error: 102443.0561\n",
      "Epoch 1498/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 13429706209.7793 - mean_absolute_error: 106965.9297 - val_loss: 14033544670.5704 - val_mean_absolute_error: 104276.6594\n",
      "Epoch 1499/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 13586422900.0650 - mean_absolute_error: 106477.8467 - val_loss: 14483847889.3746 - val_mean_absolute_error: 106375.1881\n",
      "Epoch 1500/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 14052971072.3832 - mean_absolute_error: 108668.0807 - val_loss: 15396640482.9691 - val_mean_absolute_error: 109266.4476\n",
      "Epoch 1501/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 14276886599.8289 - mean_absolute_error: 107920.9919 - val_loss: 16047834615.2027 - val_mean_absolute_error: 112255.1647\n",
      "Epoch 1502/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 13769625648.1779 - mean_absolute_error: 106642.9488 - val_loss: 14854621081.9519 - val_mean_absolute_error: 107878.1129\n",
      "Epoch 1503/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 13291518371.5860 - mean_absolute_error: 106338.3018 - val_loss: 14717681041.1546 - val_mean_absolute_error: 107768.5298\n",
      "Epoch 1504/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 13807309912.4722 - mean_absolute_error: 107507.5554 - val_loss: 15398394609.0447 - val_mean_absolute_error: 109805.7665\n",
      "Epoch 1505/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 13544237525.5158 - mean_absolute_error: 106610.5271 - val_loss: 15938575722.4467 - val_mean_absolute_error: 112349.2811\n",
      "Epoch 1506/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 13739229707.8255 - mean_absolute_error: 106636.2530 - val_loss: 15392775087.0653 - val_mean_absolute_error: 110904.5943\n",
      "Epoch 1507/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 13348872598.4465 - mean_absolute_error: 106898.8021 - val_loss: 15435812329.1271 - val_mean_absolute_error: 110723.9160\n",
      "Epoch 1508/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 13148668036.2703 - mean_absolute_error: 105401.5930 - val_loss: 14760297489.5945 - val_mean_absolute_error: 107826.5688\n",
      "Epoch 1509/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 13829317507.1754 - mean_absolute_error: 106716.2756 - val_loss: 14260696824.0825 - val_mean_absolute_error: 106147.0942\n",
      "Epoch 1510/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 13829750735.8221 - mean_absolute_error: 107351.4505 - val_loss: 13266652191.6701 - val_mean_absolute_error: 101110.5606\n",
      "Epoch 1511/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 13720445688.3353 - mean_absolute_error: 107417.8020 - val_loss: 13894425902.6254 - val_mean_absolute_error: 102737.1707\n",
      "Epoch 1512/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 13529355598.6176 - mean_absolute_error: 106429.0673 - val_loss: 14115152076.0962 - val_mean_absolute_error: 104444.9017\n",
      "Epoch 1513/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 13662545974.3097 - mean_absolute_error: 106391.8799 - val_loss: 14668039421.3608 - val_mean_absolute_error: 106643.0608\n",
      "Epoch 1514/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 13527693853.3447 - mean_absolute_error: 105704.8287 - val_loss: 14372590419.5739 - val_mean_absolute_error: 106325.2417\n",
      "Epoch 1515/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 13503095933.2626 - mean_absolute_error: 105722.8735 - val_loss: 14408302996.6735 - val_mean_absolute_error: 105119.4469\n",
      "Epoch 1516/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 13395892924.3319 - mean_absolute_error: 105438.2523 - val_loss: 14130858145.8694 - val_mean_absolute_error: 104089.9742\n",
      "Epoch 1517/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 13613578835.6544 - mean_absolute_error: 106760.9237 - val_loss: 15241965515.2165 - val_mean_absolute_error: 108590.5025\n",
      "Epoch 1518/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 13431254784.2190 - mean_absolute_error: 105408.9631 - val_loss: 15192694245.6082 - val_mean_absolute_error: 107803.7792\n",
      "Epoch 1519/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 13463490789.5021 - mean_absolute_error: 105245.9688 - val_loss: 13471799359.3402 - val_mean_absolute_error: 101794.2579\n",
      "Epoch 1520/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 13280523567.9589 - mean_absolute_error: 105480.9772 - val_loss: 14710350531.2990 - val_mean_absolute_error: 106270.0650\n",
      "Epoch 1521/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 13206364405.2695 - mean_absolute_error: 104933.1676 - val_loss: 15306270206.2405 - val_mean_absolute_error: 109602.7212\n",
      "Epoch 1522/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 13596202082.9837 - mean_absolute_error: 105976.5631 - val_loss: 14992354891.6564 - val_mean_absolute_error: 107898.1038\n",
      "Epoch 1523/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 13185033224.7596 - mean_absolute_error: 105642.4345 - val_loss: 14377916894.5704 - val_mean_absolute_error: 105389.2156\n",
      "Epoch 1524/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 12902014275.2301 - mean_absolute_error: 104169.1865 - val_loss: 14916342083.7388 - val_mean_absolute_error: 107623.7940\n",
      "Epoch 1525/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 13177762387.6544 - mean_absolute_error: 104521.4901 - val_loss: 13531022779.3814 - val_mean_absolute_error: 102119.9586\n",
      "Epoch 1526/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 13646289277.0436 - mean_absolute_error: 106743.1071 - val_loss: 14449161740.3162 - val_mean_absolute_error: 106228.0508\n",
      "Epoch 1527/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 13446444516.4072 - mean_absolute_error: 105870.9914 - val_loss: 14085715383.8625 - val_mean_absolute_error: 105398.1001\n",
      "Epoch 1528/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 12971179854.1796 - mean_absolute_error: 103821.1347 - val_loss: 12969426398.5704 - val_mean_absolute_error: 100704.9875\n",
      "Epoch 1529/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 13237814399.0145 - mean_absolute_error: 104229.0989 - val_loss: 14809550890.2268 - val_mean_absolute_error: 106010.0714\n",
      "Epoch 1530/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 13171879621.5295 - mean_absolute_error: 103857.4868 - val_loss: 15087824248.5223 - val_mean_absolute_error: 109600.8492\n",
      "Epoch 1531/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 13473860495.8768 - mean_absolute_error: 105050.7879 - val_loss: 12966598071.8625 - val_mean_absolute_error: 101363.8012\n",
      "Epoch 1532/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 13177824444.3319 - mean_absolute_error: 104790.5641 - val_loss: 14464597083.4914 - val_mean_absolute_error: 106454.3215\n",
      "Epoch 1533/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 353us/step - loss: 13417653719.2677 - mean_absolute_error: 105277.6412 - val_loss: 14713781420.4261 - val_mean_absolute_error: 106746.5859\n",
      "Epoch 1534/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 13000468155.0180 - mean_absolute_error: 103879.6292 - val_loss: 15567183470.8454 - val_mean_absolute_error: 108509.4435\n",
      "Epoch 1535/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 12762679418.6347 - mean_absolute_error: 103756.5384 - val_loss: 14063611900.4811 - val_mean_absolute_error: 104595.2299\n",
      "Epoch 1536/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 13193151012.3524 - mean_absolute_error: 104316.8456 - val_loss: 13885767384.4124 - val_mean_absolute_error: 104370.4296\n",
      "Epoch 1537/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 12760152441.1018 - mean_absolute_error: 103758.1967 - val_loss: 13544826904.6323 - val_mean_absolute_error: 102471.2890\n",
      "Epoch 1538/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 12750128358.3781 - mean_absolute_error: 103570.2492 - val_loss: 13652344124.7010 - val_mean_absolute_error: 103000.9156\n",
      "Epoch 1539/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 12593883697.4919 - mean_absolute_error: 103126.3120 - val_loss: 14580525443.0790 - val_mean_absolute_error: 106143.5644\n",
      "Epoch 1540/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 13070940929.0950 - mean_absolute_error: 103316.1192 - val_loss: 15600270575.2852 - val_mean_absolute_error: 110376.3251\n",
      "Epoch 1541/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 12936429546.9769 - mean_absolute_error: 104163.2906 - val_loss: 14640652699.7113 - val_mean_absolute_error: 106153.1915\n",
      "Epoch 1542/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 12812419077.2558 - mean_absolute_error: 102891.5690 - val_loss: 15204647907.8488 - val_mean_absolute_error: 107290.9880\n",
      "Epoch 1543/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 12751244032.2190 - mean_absolute_error: 102267.1724 - val_loss: 14052023859.0241 - val_mean_absolute_error: 104339.9290\n",
      "Epoch 1544/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 12758077668.6262 - mean_absolute_error: 102595.9187 - val_loss: 12988284083.4639 - val_mean_absolute_error: 100549.5200\n",
      "Epoch 1545/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 12589648625.3276 - mean_absolute_error: 102212.6260 - val_loss: 14139050459.0515 - val_mean_absolute_error: 104891.1600\n",
      "Epoch 1546/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 12987406432.3559 - mean_absolute_error: 103426.9743 - val_loss: 12205913626.3918 - val_mean_absolute_error: 97026.5367\n",
      "Epoch 1547/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 13220457989.6938 - mean_absolute_error: 104431.4804 - val_loss: 14460861717.9931 - val_mean_absolute_error: 104514.7751\n",
      "Epoch 1548/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 12886934913.4234 - mean_absolute_error: 103780.6642 - val_loss: 13130105335.2027 - val_mean_absolute_error: 100757.4899\n",
      "Epoch 1549/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 13026466049.0950 - mean_absolute_error: 103949.8458 - val_loss: 14193399895.9725 - val_mean_absolute_error: 104403.8278\n",
      "Epoch 1550/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 12740755524.3251 - mean_absolute_error: 102596.7383 - val_loss: 14416608013.1959 - val_mean_absolute_error: 105780.5679\n",
      "Epoch 1551/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 13261052683.6065 - mean_absolute_error: 104152.1573 - val_loss: 14288981255.9175 - val_mean_absolute_error: 105741.2421\n",
      "Epoch 1552/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 11914730905.9504 - mean_absolute_error: 100562.0509 - val_loss: 14168221713.5945 - val_mean_absolute_error: 104623.2316\n",
      "Epoch 1553/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 12381657625.8409 - mean_absolute_error: 101548.8683 - val_loss: 13409333592.8522 - val_mean_absolute_error: 101253.7159\n",
      "Epoch 1554/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 12906085406.2207 - mean_absolute_error: 102971.4381 - val_loss: 13977178428.7010 - val_mean_absolute_error: 103280.9148\n",
      "Epoch 1555/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 12349065492.8041 - mean_absolute_error: 101316.0098 - val_loss: 12560090062.7354 - val_mean_absolute_error: 98836.4595\n",
      "Epoch 1556/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 12563138716.7973 - mean_absolute_error: 101618.9416 - val_loss: 13616222482.4742 - val_mean_absolute_error: 102927.5947\n",
      "Epoch 1557/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 12618058735.3567 - mean_absolute_error: 101749.7572 - val_loss: 14096256587.6564 - val_mean_absolute_error: 103694.4819\n",
      "Epoch 1558/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 12398377701.0642 - mean_absolute_error: 101471.4242 - val_loss: 14340550272.4399 - val_mean_absolute_error: 104850.0073\n",
      "Epoch 1559/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 12507265248.2464 - mean_absolute_error: 101920.6188 - val_loss: 13739884575.6701 - val_mean_absolute_error: 103313.5907\n",
      "Epoch 1560/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 12539555493.9949 - mean_absolute_error: 101365.3520 - val_loss: 14344635300.5086 - val_mean_absolute_error: 105376.1733\n",
      "Epoch 1561/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 12707972049.5740 - mean_absolute_error: 102388.6336 - val_loss: 14572206354.4742 - val_mean_absolute_error: 105706.4281\n",
      "Epoch 1562/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 12652021032.5133 - mean_absolute_error: 102162.2493 - val_loss: 13982793545.0172 - val_mean_absolute_error: 104341.5784\n",
      "Epoch 1563/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 12755985929.6356 - mean_absolute_error: 101484.0250 - val_loss: 14281523492.0687 - val_mean_absolute_error: 104795.1917\n",
      "Epoch 1564/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 12596937424.9170 - mean_absolute_error: 101289.9044 - val_loss: 14796680304.6048 - val_mean_absolute_error: 106174.3980\n",
      "Epoch 1565/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 12483458567.0077 - mean_absolute_error: 101451.2124 - val_loss: 13067899949.7457 - val_mean_absolute_error: 100344.7723\n",
      "Epoch 1566/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 12736620640.3559 - mean_absolute_error: 101376.0265 - val_loss: 14388504706.1993 - val_mean_absolute_error: 105852.5949\n",
      "Epoch 1567/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 12042044220.6604 - mean_absolute_error: 100502.8536 - val_loss: 13382694479.1753 - val_mean_absolute_error: 101140.4118\n",
      "Epoch 1568/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 12505027946.6484 - mean_absolute_error: 101326.6249 - val_loss: 12738559229.3608 - val_mean_absolute_error: 99519.9784\n",
      "Epoch 1569/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 12199477544.0753 - mean_absolute_error: 99553.4446 - val_loss: 12983009082.9416 - val_mean_absolute_error: 100200.0748\n",
      "Epoch 1570/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 12107416939.0864 - mean_absolute_error: 99852.9627 - val_loss: 10966335153.7045 - val_mean_absolute_error: 92027.4949\n",
      "Epoch 1571/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 12291293441.7519 - mean_absolute_error: 101359.9870 - val_loss: 12135982231.3127 - val_mean_absolute_error: 97652.4143\n",
      "Epoch 1572/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 12370094629.4474 - mean_absolute_error: 101157.5135 - val_loss: 13051666769.8144 - val_mean_absolute_error: 99329.1941\n",
      "Epoch 1573/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 12129427309.2763 - mean_absolute_error: 99475.6939 - val_loss: 13197593216.4399 - val_mean_absolute_error: 100032.1231\n",
      "Epoch 1574/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 12623805657.0197 - mean_absolute_error: 102047.8738 - val_loss: 13368688537.9519 - val_mean_absolute_error: 100564.8982\n",
      "Epoch 1575/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 12356656628.1745 - mean_absolute_error: 100521.7161 - val_loss: 12509680735.0103 - val_mean_absolute_error: 98109.5800\n",
      "Epoch 1576/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 12091162715.1001 - mean_absolute_error: 99966.0732 - val_loss: 12613715260.7010 - val_mean_absolute_error: 98083.4673\n",
      "Epoch 1577/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 12238829904.3695 - mean_absolute_error: 99824.4744 - val_loss: 12665505383.8076 - val_mean_absolute_error: 97826.5117\n",
      "Epoch 1578/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 12432437630.3576 - mean_absolute_error: 100183.5627 - val_loss: 13071985259.3265 - val_mean_absolute_error: 99803.1354\n",
      "Epoch 1579/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 11949061395.0522 - mean_absolute_error: 98901.0799 - val_loss: 12350738952.7973 - val_mean_absolute_error: 96062.9877\n",
      "Epoch 1580/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 11940492792.5543 - mean_absolute_error: 99553.6585 - val_loss: 13198633927.6976 - val_mean_absolute_error: 99815.5023\n",
      "Epoch 1581/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 12163560624.0684 - mean_absolute_error: 99730.8721 - val_loss: 12931038436.7285 - val_mean_absolute_error: 99395.3854\n",
      "Epoch 1582/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 12243917583.1103 - mean_absolute_error: 100349.5502 - val_loss: 12605629330.9141 - val_mean_absolute_error: 97285.5963\n",
      "Epoch 1583/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 12215079579.0453 - mean_absolute_error: 99841.6915 - val_loss: 12323563361.6495 - val_mean_absolute_error: 96691.1789\n",
      "Epoch 1584/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 12075343048.5954 - mean_absolute_error: 100248.7638 - val_loss: 12583946278.7079 - val_mean_absolute_error: 97914.1382\n",
      "Epoch 1585/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 11993649555.3807 - mean_absolute_error: 99456.5701 - val_loss: 13150564798.9003 - val_mean_absolute_error: 99314.8420\n",
      "Epoch 1586/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 12026984805.3926 - mean_absolute_error: 98704.0597 - val_loss: 13293371142.1581 - val_mean_absolute_error: 99834.8507\n",
      "Epoch 1587/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 11971843911.1719 - mean_absolute_error: 98398.9998 - val_loss: 12946146902.2131 - val_mean_absolute_error: 99786.7466\n",
      "Epoch 1588/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 12252985489.4098 - mean_absolute_error: 99628.4579 - val_loss: 11441851413.1134 - val_mean_absolute_error: 92447.6200\n",
      "Epoch 1589/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 12071496463.1103 - mean_absolute_error: 99439.3116 - val_loss: 12406561510.4880 - val_mean_absolute_error: 95724.9430\n",
      "Epoch 1590/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 11974452774.9803 - mean_absolute_error: 99312.0568 - val_loss: 11825300325.1684 - val_mean_absolute_error: 93995.0809\n",
      "Epoch 1591/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 11889801937.7930 - mean_absolute_error: 98701.4692 - val_loss: 11932798479.8351 - val_mean_absolute_error: 94503.6373\n",
      "Epoch 1592/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 11968820267.7981 - mean_absolute_error: 99674.6212 - val_loss: 12618759277.0859 - val_mean_absolute_error: 97728.0211\n",
      "Epoch 1593/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 11740052852.2840 - mean_absolute_error: 97724.2419 - val_loss: 13286286248.0275 - val_mean_absolute_error: 99744.0477\n",
      "Epoch 1594/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 12055276264.5680 - mean_absolute_error: 98169.4734 - val_loss: 12553026369.9794 - val_mean_absolute_error: 97603.5351\n",
      "Epoch 1595/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 11856673181.4542 - mean_absolute_error: 98368.1890 - val_loss: 12368407256.4124 - val_mean_absolute_error: 96638.0195\n",
      "Epoch 1596/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 11897610485.2695 - mean_absolute_error: 99109.9843 - val_loss: 13429363986.4742 - val_mean_absolute_error: 101577.1034\n",
      "Epoch 1597/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 11993407544.4996 - mean_absolute_error: 99245.3212 - val_loss: 12535100405.4433 - val_mean_absolute_error: 98289.1335\n",
      "Epoch 1598/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 11856491050.4842 - mean_absolute_error: 97765.5053 - val_loss: 12767100547.9588 - val_mean_absolute_error: 98777.2103\n",
      "Epoch 1599/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 11891520260.1608 - mean_absolute_error: 98506.1513 - val_loss: 12211986090.6667 - val_mean_absolute_error: 96665.1768\n",
      "Epoch 1600/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 11707436511.1514 - mean_absolute_error: 98330.3775 - val_loss: 13009130640.2749 - val_mean_absolute_error: 98760.5743\n",
      "Epoch 1601/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 11684524293.0368 - mean_absolute_error: 98595.2765 - val_loss: 12724349761.9794 - val_mean_absolute_error: 98866.8632\n",
      "Epoch 1602/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 11505278874.3884 - mean_absolute_error: 97346.9008 - val_loss: 12642335631.3952 - val_mean_absolute_error: 97895.5020\n",
      "Epoch 1603/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 11693994205.1805 - mean_absolute_error: 97797.7512 - val_loss: 12754710390.7629 - val_mean_absolute_error: 99289.6443\n",
      "Epoch 1604/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 11728123831.2951 - mean_absolute_error: 97995.6639 - val_loss: 13098509892.6186 - val_mean_absolute_error: 100332.3653\n",
      "Epoch 1605/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 11719393610.2378 - mean_absolute_error: 97217.8115 - val_loss: 12822852453.1684 - val_mean_absolute_error: 97514.9567\n",
      "Epoch 1606/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 11684549480.0205 - mean_absolute_error: 96783.8093 - val_loss: 12153923288.4124 - val_mean_absolute_error: 94368.3658\n",
      "Epoch 1607/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 11638479299.9966 - mean_absolute_error: 96988.9538 - val_loss: 12211253462.6529 - val_mean_absolute_error: 95721.9961\n",
      "Epoch 1608/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 11682951281.8751 - mean_absolute_error: 96987.7831 - val_loss: 12600441507.6289 - val_mean_absolute_error: 96752.2241\n",
      "Epoch 1609/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 11385475714.9564 - mean_absolute_error: 96922.9477 - val_loss: 12592800732.8110 - val_mean_absolute_error: 96960.4127\n",
      "Epoch 1610/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 11555344362.9769 - mean_absolute_error: 96184.8975 - val_loss: 11212050139.9313 - val_mean_absolute_error: 90763.5590\n",
      "Epoch 1611/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 11642839222.2002 - mean_absolute_error: 96905.7383 - val_loss: 11869257872.2749 - val_mean_absolute_error: 94438.0235\n",
      "Epoch 1612/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 11302073494.2275 - mean_absolute_error: 96459.9830 - val_loss: 12098469145.5120 - val_mean_absolute_error: 96226.8321\n",
      "Epoch 1613/5000\n",
      "1169/1169 [==============================] - 0s 319us/step - loss: 11857012376.4175 - mean_absolute_error: 97456.6917 - val_loss: 12026261204.8935 - val_mean_absolute_error: 95001.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1614/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 11306458134.3370 - mean_absolute_error: 96355.7838 - val_loss: 11950730961.3746 - val_mean_absolute_error: 93446.7410\n",
      "Epoch 1615/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 11917556507.3738 - mean_absolute_error: 97779.7472 - val_loss: 11694818722.7491 - val_mean_absolute_error: 91736.5658\n",
      "Epoch 1616/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 11339316281.5945 - mean_absolute_error: 94979.4493 - val_loss: 11726519679.5601 - val_mean_absolute_error: 93841.6302\n",
      "Epoch 1617/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 11282190181.8306 - mean_absolute_error: 95785.8073 - val_loss: 13497853793.6495 - val_mean_absolute_error: 101533.7078\n",
      "Epoch 1618/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 11447296676.2429 - mean_absolute_error: 96031.0580 - val_loss: 12534181972.4536 - val_mean_absolute_error: 98498.3058\n",
      "Epoch 1619/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 11238122344.4585 - mean_absolute_error: 95189.6430 - val_loss: 12771897970.3643 - val_mean_absolute_error: 98090.9400\n",
      "Epoch 1620/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 11293021436.7151 - mean_absolute_error: 96408.2037 - val_loss: 12116115677.6907 - val_mean_absolute_error: 95099.2250\n",
      "Epoch 1621/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 11429650240.6022 - mean_absolute_error: 96264.7494 - val_loss: 11388537000.9072 - val_mean_absolute_error: 92677.5107\n",
      "Epoch 1622/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 11176520188.0582 - mean_absolute_error: 95222.8302 - val_loss: 12386749253.4983 - val_mean_absolute_error: 95840.7147\n",
      "Epoch 1623/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 11140485820.7699 - mean_absolute_error: 94674.0915 - val_loss: 12541314906.6117 - val_mean_absolute_error: 96529.6941\n",
      "Epoch 1624/5000\n",
      "1169/1169 [==============================] - 0s 416us/step - loss: 11512043963.2370 - mean_absolute_error: 95904.9143 - val_loss: 11555444524.8660 - val_mean_absolute_error: 94143.7648\n",
      "Epoch 1625/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 11520517651.7092 - mean_absolute_error: 96442.7425 - val_loss: 12716890660.9485 - val_mean_absolute_error: 96801.1503\n",
      "Epoch 1626/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 10943164671.7810 - mean_absolute_error: 94416.7239 - val_loss: 11619748814.7354 - val_mean_absolute_error: 92024.8940\n",
      "Epoch 1627/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 11556708561.3550 - mean_absolute_error: 96181.3180 - val_loss: 12393835463.6976 - val_mean_absolute_error: 95905.2116\n",
      "Epoch 1628/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 11278905124.5714 - mean_absolute_error: 94471.9942 - val_loss: 11537406149.0584 - val_mean_absolute_error: 93003.9623\n",
      "Epoch 1629/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 11729752388.9820 - mean_absolute_error: 96534.4503 - val_loss: 12082036640.9897 - val_mean_absolute_error: 95612.9815\n",
      "Epoch 1630/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 10999086256.5064 - mean_absolute_error: 94994.4315 - val_loss: 12205795458.1993 - val_mean_absolute_error: 97072.3203\n",
      "Epoch 1631/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 11319826028.1814 - mean_absolute_error: 95657.6482 - val_loss: 11687172405.6632 - val_mean_absolute_error: 94536.4656\n",
      "Epoch 1632/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 10988391824.3148 - mean_absolute_error: 94692.5433 - val_loss: 12185969818.8316 - val_mean_absolute_error: 96402.3032\n",
      "Epoch 1633/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 10895933687.0214 - mean_absolute_error: 93364.4913 - val_loss: 13109151297.0997 - val_mean_absolute_error: 100580.6574\n",
      "Epoch 1634/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 10925943145.9914 - mean_absolute_error: 94248.3915 - val_loss: 12989209962.4467 - val_mean_absolute_error: 99316.8859\n",
      "Epoch 1635/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 10985668579.0932 - mean_absolute_error: 94257.5665 - val_loss: 13010063074.9691 - val_mean_absolute_error: 98309.3495\n",
      "Epoch 1636/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 11259159227.0180 - mean_absolute_error: 94901.3168 - val_loss: 11728122352.1649 - val_mean_absolute_error: 93350.4935\n",
      "Epoch 1637/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 10991124434.4500 - mean_absolute_error: 94455.2138 - val_loss: 12640615645.6907 - val_mean_absolute_error: 98297.9690\n",
      "Epoch 1638/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 11032774875.8666 - mean_absolute_error: 94734.4880 - val_loss: 11649963486.5704 - val_mean_absolute_error: 93515.1496\n",
      "Epoch 1639/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 11100833925.1463 - mean_absolute_error: 94425.3440 - val_loss: 13749819015.4777 - val_mean_absolute_error: 100336.2255\n",
      "Epoch 1640/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 10948589450.6210 - mean_absolute_error: 94423.7832 - val_loss: 12942781017.7320 - val_mean_absolute_error: 98590.0331\n",
      "Epoch 1641/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 10745872421.6664 - mean_absolute_error: 93283.2933 - val_loss: 10936462877.9107 - val_mean_absolute_error: 91324.7188\n",
      "Epoch 1642/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 10872515205.5843 - mean_absolute_error: 93706.3929 - val_loss: 12458254300.8110 - val_mean_absolute_error: 96657.0565\n",
      "Epoch 1643/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 10655124672.7117 - mean_absolute_error: 93286.0512 - val_loss: 9874143541.6632 - val_mean_absolute_error: 85491.8791\n",
      "Epoch 1644/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 10906819009.3687 - mean_absolute_error: 93318.6076 - val_loss: 10300692502.8729 - val_mean_absolute_error: 85396.2739\n",
      "Epoch 1645/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 10853703011.6407 - mean_absolute_error: 93504.2580 - val_loss: 11049625506.7491 - val_mean_absolute_error: 89080.3652\n",
      "Epoch 1646/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 11088295875.5586 - mean_absolute_error: 94327.6634 - val_loss: 9708569920.2199 - val_mean_absolute_error: 82894.4435\n",
      "Epoch 1647/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 10755433260.4551 - mean_absolute_error: 93346.2968 - val_loss: 9854379280.7148 - val_mean_absolute_error: 84552.5982\n",
      "Epoch 1648/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 10570093645.0847 - mean_absolute_error: 92708.2654 - val_loss: 13782992716.5361 - val_mean_absolute_error: 99495.1939\n",
      "Epoch 1649/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 10630834894.2891 - mean_absolute_error: 91772.1310 - val_loss: 11020586617.4021 - val_mean_absolute_error: 89971.1518\n",
      "Epoch 1650/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 10664339275.5518 - mean_absolute_error: 92691.3563 - val_loss: 11818920038.0481 - val_mean_absolute_error: 93468.6760\n",
      "Epoch 1651/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 10800979720.1027 - mean_absolute_error: 92329.1462 - val_loss: 10535214347.4364 - val_mean_absolute_error: 88557.0852\n",
      "Epoch 1652/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 10694764884.7494 - mean_absolute_error: 93841.1252 - val_loss: 12201312438.9828 - val_mean_absolute_error: 94322.3973\n",
      "Epoch 1653/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 10306561814.1180 - mean_absolute_error: 91776.8510 - val_loss: 11467604348.0412 - val_mean_absolute_error: 92326.5139\n",
      "Epoch 1654/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 10658428278.4739 - mean_absolute_error: 93794.2089 - val_loss: 10377945376.5498 - val_mean_absolute_error: 88332.4316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1655/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 10818744891.1275 - mean_absolute_error: 92909.0502 - val_loss: 12781890933.0034 - val_mean_absolute_error: 98303.8467\n",
      "Epoch 1656/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 10787527518.3849 - mean_absolute_error: 93221.6056 - val_loss: 10770419930.1718 - val_mean_absolute_error: 89671.8370\n",
      "Epoch 1657/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 10376735160.6091 - mean_absolute_error: 91681.2213 - val_loss: 11339025619.1340 - val_mean_absolute_error: 92645.5264\n",
      "Epoch 1658/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 10562309873.7656 - mean_absolute_error: 92615.2634 - val_loss: 11523946510.0756 - val_mean_absolute_error: 92820.9276\n",
      "Epoch 1659/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 10395169442.4910 - mean_absolute_error: 90923.3863 - val_loss: 11359341979.7113 - val_mean_absolute_error: 92191.3244\n",
      "Epoch 1660/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 10261838404.7630 - mean_absolute_error: 91114.0629 - val_loss: 11555472514.1993 - val_mean_absolute_error: 91955.3938\n",
      "Epoch 1661/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 10633094774.6929 - mean_absolute_error: 92115.3559 - val_loss: 11555009497.2921 - val_mean_absolute_error: 92268.2396\n",
      "Epoch 1662/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 10521488143.1103 - mean_absolute_error: 92157.3393 - val_loss: 10084210190.0756 - val_mean_absolute_error: 86753.9787\n",
      "Epoch 1663/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 10422615727.6305 - mean_absolute_error: 91376.5397 - val_loss: 11287913018.0619 - val_mean_absolute_error: 92370.0082\n",
      "Epoch 1664/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 10307742280.2669 - mean_absolute_error: 91158.8037 - val_loss: 12014744269.8557 - val_mean_absolute_error: 94391.7599\n",
      "Epoch 1665/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 10607863884.8657 - mean_absolute_error: 91150.2638 - val_loss: 11689128358.2680 - val_mean_absolute_error: 92008.2483\n",
      "Epoch 1666/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 10758916831.3704 - mean_absolute_error: 90775.9616 - val_loss: 10960413739.9863 - val_mean_absolute_error: 88806.9333\n",
      "Epoch 1667/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 10563221478.5971 - mean_absolute_error: 91269.1491 - val_loss: 10649480878.1856 - val_mean_absolute_error: 88270.4581\n",
      "Epoch 1668/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 10680091468.8657 - mean_absolute_error: 91299.5093 - val_loss: 9738068509.9107 - val_mean_absolute_error: 83094.7344\n",
      "Epoch 1669/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 10033390079.5620 - mean_absolute_error: 90688.6112 - val_loss: 9890619045.3883 - val_mean_absolute_error: 84242.4607\n",
      "Epoch 1670/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 10088559111.4457 - mean_absolute_error: 90228.5514 - val_loss: 9897972014.6254 - val_mean_absolute_error: 84374.8207\n",
      "Epoch 1671/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 10886432603.3191 - mean_absolute_error: 91639.6653 - val_loss: 10854385127.3677 - val_mean_absolute_error: 89131.4215\n",
      "Epoch 1672/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 10114543708.8520 - mean_absolute_error: 90329.3755 - val_loss: 12265064912.4948 - val_mean_absolute_error: 94185.7677\n",
      "Epoch 1673/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 10208459555.9145 - mean_absolute_error: 89927.4896 - val_loss: 10667918513.7045 - val_mean_absolute_error: 88944.9903\n",
      "Epoch 1674/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 10572291437.2763 - mean_absolute_error: 91873.1150 - val_loss: 11752848056.7423 - val_mean_absolute_error: 93004.8568\n",
      "Epoch 1675/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 10016301700.7083 - mean_absolute_error: 89229.6159 - val_loss: 10924421582.7354 - val_mean_absolute_error: 90021.0453\n",
      "Epoch 1676/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 10202804709.7211 - mean_absolute_error: 89974.8133 - val_loss: 10756407966.3505 - val_mean_absolute_error: 88556.7575\n",
      "Epoch 1677/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 9992622147.4491 - mean_absolute_error: 89518.4879 - val_loss: 10892114773.3333 - val_mean_absolute_error: 88941.7879\n",
      "Epoch 1678/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 10081516339.9008 - mean_absolute_error: 89516.8736 - val_loss: 11388367594.0069 - val_mean_absolute_error: 91774.7440\n",
      "Epoch 1679/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 9911571322.4157 - mean_absolute_error: 88391.8240 - val_loss: 11459756123.4914 - val_mean_absolute_error: 92336.9464\n",
      "Epoch 1680/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 10137078587.7844 - mean_absolute_error: 90204.8098 - val_loss: 11585074239.3402 - val_mean_absolute_error: 93015.0301\n",
      "Epoch 1681/5000\n",
      "1169/1169 [==============================] - 0s 316us/step - loss: 10437535894.8845 - mean_absolute_error: 90972.3410 - val_loss: 11210181153.4296 - val_mean_absolute_error: 91376.6106\n",
      "Epoch 1682/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 9925228922.8537 - mean_absolute_error: 89217.9911 - val_loss: 11885668651.1065 - val_mean_absolute_error: 94839.6761\n",
      "Epoch 1683/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 10004360550.2686 - mean_absolute_error: 88850.9927 - val_loss: 10248830395.3814 - val_mean_absolute_error: 87143.7937\n",
      "Epoch 1684/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 10295005682.4226 - mean_absolute_error: 90017.1195 - val_loss: 11133781125.7182 - val_mean_absolute_error: 90009.1382\n",
      "Epoch 1685/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 10017607519.6989 - mean_absolute_error: 89892.6430 - val_loss: 11692488112.8247 - val_mean_absolute_error: 91949.8396\n",
      "Epoch 1686/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 9993998131.9008 - mean_absolute_error: 89417.5487 - val_loss: 11187866729.5670 - val_mean_absolute_error: 89501.3375\n",
      "Epoch 1687/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 10338325766.7887 - mean_absolute_error: 90362.9462 - val_loss: 10889929129.7869 - val_mean_absolute_error: 89390.9937\n",
      "Epoch 1688/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 9803368799.2609 - mean_absolute_error: 88328.3382 - val_loss: 10820626882.4192 - val_mean_absolute_error: 88733.8625\n",
      "Epoch 1689/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 9946018524.3045 - mean_absolute_error: 88535.6834 - val_loss: 10883569558.4330 - val_mean_absolute_error: 89642.7105\n",
      "Epoch 1690/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 10047960055.2404 - mean_absolute_error: 89349.4345 - val_loss: 10687275078.3780 - val_mean_absolute_error: 89277.1196\n",
      "Epoch 1691/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 10303415797.9264 - mean_absolute_error: 90468.9346 - val_loss: 10733171859.7938 - val_mean_absolute_error: 88415.7417\n",
      "Epoch 1692/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 10235855924.1198 - mean_absolute_error: 88877.9992 - val_loss: 10258303706.1718 - val_mean_absolute_error: 85368.9177\n",
      "Epoch 1693/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 10102787901.0984 - mean_absolute_error: 88494.4441 - val_loss: 11682315601.8144 - val_mean_absolute_error: 91637.1232\n",
      "Epoch 1694/5000\n",
      "1169/1169 [==============================] - 0s 311us/step - loss: 9647076745.7451 - mean_absolute_error: 87649.2898 - val_loss: 10809238605.4158 - val_mean_absolute_error: 87885.5483\n",
      "Epoch 1695/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 9785097067.0864 - mean_absolute_error: 87435.3275 - val_loss: 11353700095.1203 - val_mean_absolute_error: 90897.7087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1696/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 9575372391.8015 - mean_absolute_error: 87781.0993 - val_loss: 11249047147.3265 - val_mean_absolute_error: 90480.2815\n",
      "Epoch 1697/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 10002302883.1480 - mean_absolute_error: 88058.5241 - val_loss: 9947617623.0928 - val_mean_absolute_error: 84362.6049\n",
      "Epoch 1698/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 9941036361.3618 - mean_absolute_error: 88434.2237 - val_loss: 8907563995.0515 - val_mean_absolute_error: 79894.4577\n",
      "Epoch 1699/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 9873222098.8879 - mean_absolute_error: 89054.9964 - val_loss: 10207300395.1065 - val_mean_absolute_error: 85011.1009\n",
      "Epoch 1700/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 9890561306.9358 - mean_absolute_error: 88623.6327 - val_loss: 9696590744.1924 - val_mean_absolute_error: 83475.1831\n",
      "Epoch 1701/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 9794430126.3165 - mean_absolute_error: 88264.2517 - val_loss: 10566322126.7354 - val_mean_absolute_error: 86929.4834\n",
      "Epoch 1702/5000\n",
      "1169/1169 [==============================] - 0s 315us/step - loss: 10270891206.8435 - mean_absolute_error: 89167.9860 - val_loss: 10152624224.7698 - val_mean_absolute_error: 84157.7840\n",
      "Epoch 1703/5000\n",
      "1169/1169 [==============================] - 0s 319us/step - loss: 10074161363.9829 - mean_absolute_error: 88636.5604 - val_loss: 10186831161.1821 - val_mean_absolute_error: 85430.9475\n",
      "Epoch 1704/5000\n",
      "1169/1169 [==============================] - 0s 317us/step - loss: 9965418731.6339 - mean_absolute_error: 88462.1285 - val_loss: 10946826243.5189 - val_mean_absolute_error: 89086.3268\n",
      "Epoch 1705/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 9793103886.0154 - mean_absolute_error: 88082.3743 - val_loss: 11337750242.9691 - val_mean_absolute_error: 91024.2824\n",
      "Epoch 1706/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 9640115455.1240 - mean_absolute_error: 86412.3034 - val_loss: 9300688901.2784 - val_mean_absolute_error: 82058.7100\n",
      "Epoch 1707/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 9344436151.2951 - mean_absolute_error: 86333.2709 - val_loss: 10024428772.7285 - val_mean_absolute_error: 85520.2169\n",
      "Epoch 1708/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 9872360613.1189 - mean_absolute_error: 87111.5186 - val_loss: 10282031772.5911 - val_mean_absolute_error: 86265.7090\n",
      "Epoch 1709/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 9286068793.3755 - mean_absolute_error: 86155.0157 - val_loss: 9205168342.6529 - val_mean_absolute_error: 82175.7736\n",
      "Epoch 1710/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 9789575830.2275 - mean_absolute_error: 86841.2565 - val_loss: 9232202141.4708 - val_mean_absolute_error: 81431.8868\n",
      "Epoch 1711/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 9751471002.3884 - mean_absolute_error: 87332.3449 - val_loss: 11755310368.5498 - val_mean_absolute_error: 90889.0912\n",
      "Epoch 1712/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 9518756195.6407 - mean_absolute_error: 87429.8972 - val_loss: 10773502082.1993 - val_mean_absolute_error: 88927.1273\n",
      "Epoch 1713/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 9204143453.5090 - mean_absolute_error: 85113.8624 - val_loss: 10285648772.8385 - val_mean_absolute_error: 86632.9999\n",
      "Epoch 1714/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 9524704761.4303 - mean_absolute_error: 86673.6418 - val_loss: 9034999271.3677 - val_mean_absolute_error: 80238.3994\n",
      "Epoch 1715/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 9743643107.5312 - mean_absolute_error: 87277.1834 - val_loss: 9993259841.9794 - val_mean_absolute_error: 83850.9029\n",
      "Epoch 1716/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 9584951745.3687 - mean_absolute_error: 86055.1165 - val_loss: 9959279892.2337 - val_mean_absolute_error: 84940.2874\n",
      "Epoch 1717/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 9687422834.0941 - mean_absolute_error: 86903.7010 - val_loss: 10552943598.4055 - val_mean_absolute_error: 86723.3246\n",
      "Epoch 1718/5000\n",
      "1169/1169 [==============================] - 0s 315us/step - loss: 9736632002.6826 - mean_absolute_error: 87520.6246 - val_loss: 10906487989.2234 - val_mean_absolute_error: 88313.4802\n",
      "Epoch 1719/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 9307731048.2395 - mean_absolute_error: 85461.2134 - val_loss: 9890147778.4192 - val_mean_absolute_error: 85050.1258\n",
      "Epoch 1720/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 9802614148.7083 - mean_absolute_error: 85868.8370 - val_loss: 10225879859.9038 - val_mean_absolute_error: 86108.0870\n",
      "Epoch 1721/5000\n",
      "1169/1169 [==============================] - 0s 312us/step - loss: 9605781278.8777 - mean_absolute_error: 86029.2883 - val_loss: 9414174577.4845 - val_mean_absolute_error: 83166.9126\n",
      "Epoch 1722/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 9372328622.7545 - mean_absolute_error: 86052.6829 - val_loss: 9742900077.9656 - val_mean_absolute_error: 82492.8715\n",
      "Epoch 1723/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 9297510261.5979 - mean_absolute_error: 85159.5892 - val_loss: 8517445297.7045 - val_mean_absolute_error: 77171.9294\n",
      "Epoch 1724/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 9754306906.0051 - mean_absolute_error: 86277.5512 - val_loss: 9615060464.1649 - val_mean_absolute_error: 82835.1715\n",
      "Epoch 1725/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 9450614532.1608 - mean_absolute_error: 85075.4358 - val_loss: 10807385645.7457 - val_mean_absolute_error: 88268.1747\n",
      "Epoch 1726/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 9397021675.4149 - mean_absolute_error: 85567.3668 - val_loss: 9581149372.2612 - val_mean_absolute_error: 83454.1657\n",
      "Epoch 1727/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 9199841145.1018 - mean_absolute_error: 85329.0406 - val_loss: 9636070118.4880 - val_mean_absolute_error: 82734.1403\n",
      "Epoch 1728/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 9304425670.8435 - mean_absolute_error: 85083.5726 - val_loss: 9607350069.6632 - val_mean_absolute_error: 82684.7055\n",
      "Epoch 1729/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 9369505296.6433 - mean_absolute_error: 85721.2816 - val_loss: 8944447811.7388 - val_mean_absolute_error: 79738.3918\n",
      "Epoch 1730/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 9515845949.9743 - mean_absolute_error: 85214.0975 - val_loss: 9755163582.9003 - val_mean_absolute_error: 84081.9270\n",
      "Epoch 1731/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 9100677298.2583 - mean_absolute_error: 85025.9151 - val_loss: 9154229800.4674 - val_mean_absolute_error: 82314.3507\n",
      "Epoch 1732/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 9465024965.7485 - mean_absolute_error: 85757.6463 - val_loss: 11062040678.0481 - val_mean_absolute_error: 90016.2717\n",
      "Epoch 1733/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 9547044329.6630 - mean_absolute_error: 86329.0739 - val_loss: 9228434954.5567 - val_mean_absolute_error: 82241.2452\n",
      "Epoch 1734/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 9215928390.2960 - mean_absolute_error: 84201.2433 - val_loss: 9045542531.9588 - val_mean_absolute_error: 79836.9458\n",
      "Epoch 1735/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 9395340112.1506 - mean_absolute_error: 86019.0858 - val_loss: 9603317490.8041 - val_mean_absolute_error: 81811.5852\n",
      "Epoch 1736/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 9156155921.0813 - mean_absolute_error: 84096.9280 - val_loss: 9311018397.4708 - val_mean_absolute_error: 81594.5239\n",
      "Epoch 1737/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 364us/step - loss: 9214354701.7964 - mean_absolute_error: 84186.3514 - val_loss: 10272446863.3952 - val_mean_absolute_error: 85866.1989\n",
      "Epoch 1738/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 9094359719.7468 - mean_absolute_error: 83993.6470 - val_loss: 11644025141.6632 - val_mean_absolute_error: 90797.0266\n",
      "Epoch 1739/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 8902151149.6048 - mean_absolute_error: 83714.6168 - val_loss: 9744566988.0962 - val_mean_absolute_error: 83695.4859\n",
      "Epoch 1740/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 9032440857.4029 - mean_absolute_error: 83751.2699 - val_loss: 10698118960.3849 - val_mean_absolute_error: 88263.0121\n",
      "Epoch 1741/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 9730245476.9547 - mean_absolute_error: 85785.2050 - val_loss: 10728334881.4296 - val_mean_absolute_error: 88131.4779\n",
      "Epoch 1742/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 9487863076.1334 - mean_absolute_error: 85296.7298 - val_loss: 10156834835.3540 - val_mean_absolute_error: 86048.2742\n",
      "Epoch 1743/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 9154580719.5757 - mean_absolute_error: 84075.4812 - val_loss: 10188765736.4674 - val_mean_absolute_error: 85262.7814\n",
      "Epoch 1744/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 8928661284.7904 - mean_absolute_error: 82991.1772 - val_loss: 9150847957.7732 - val_mean_absolute_error: 81143.1316\n",
      "Epoch 1745/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 8776361281.0402 - mean_absolute_error: 82901.9381 - val_loss: 9307420237.4158 - val_mean_absolute_error: 81472.3608\n",
      "Epoch 1746/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 9495571852.8109 - mean_absolute_error: 84825.4355 - val_loss: 8198664447.1203 - val_mean_absolute_error: 76461.3996\n",
      "Epoch 1747/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 8856736875.7434 - mean_absolute_error: 83481.4290 - val_loss: 8955646240.5498 - val_mean_absolute_error: 78240.7162\n",
      "Epoch 1748/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 9501654203.4559 - mean_absolute_error: 84129.1170 - val_loss: 11136059877.6082 - val_mean_absolute_error: 88680.0321\n",
      "Epoch 1749/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 9276017160.3216 - mean_absolute_error: 84139.1942 - val_loss: 9420675914.7766 - val_mean_absolute_error: 81653.9861\n",
      "Epoch 1750/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 8982967347.2438 - mean_absolute_error: 83123.4946 - val_loss: 9691702866.6942 - val_mean_absolute_error: 83349.2193\n",
      "Epoch 1751/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 9513927156.1745 - mean_absolute_error: 83899.4127 - val_loss: 9893149483.1065 - val_mean_absolute_error: 84822.4003\n",
      "Epoch 1752/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 9116581211.3191 - mean_absolute_error: 83345.4133 - val_loss: 9259525818.5017 - val_mean_absolute_error: 80999.0099\n",
      "Epoch 1753/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 8892359988.7767 - mean_absolute_error: 82734.7973 - val_loss: 9913007394.3093 - val_mean_absolute_error: 84206.3482\n",
      "Epoch 1754/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 9031194508.3730 - mean_absolute_error: 82261.6618 - val_loss: 9113840807.1478 - val_mean_absolute_error: 81296.4857\n",
      "Epoch 1755/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 9015597577.1976 - mean_absolute_error: 82846.9487 - val_loss: 10726417886.5704 - val_mean_absolute_error: 87899.2192\n",
      "Epoch 1756/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 9102375720.0753 - mean_absolute_error: 84206.4810 - val_loss: 10226555754.4467 - val_mean_absolute_error: 85399.6834\n",
      "Epoch 1757/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 8932414570.4294 - mean_absolute_error: 82659.0337 - val_loss: 10333882874.7216 - val_mean_absolute_error: 86883.7788\n",
      "Epoch 1758/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 8871335401.2250 - mean_absolute_error: 83031.3070 - val_loss: 9122861590.8729 - val_mean_absolute_error: 80837.0624\n",
      "Epoch 1759/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 9007377018.1968 - mean_absolute_error: 81991.1642 - val_loss: 9382084674.8591 - val_mean_absolute_error: 81011.8644\n",
      "Epoch 1760/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 8896825379.9145 - mean_absolute_error: 81768.8418 - val_loss: 9722132311.0928 - val_mean_absolute_error: 82627.7692\n",
      "Epoch 1761/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 8780525813.2695 - mean_absolute_error: 81553.1323 - val_loss: 9841020449.4296 - val_mean_absolute_error: 83834.6079\n",
      "Epoch 1762/5000\n",
      "1169/1169 [==============================] - 0s 385us/step - loss: 9209292752.9170 - mean_absolute_error: 83028.3663 - val_loss: 8857153696.1100 - val_mean_absolute_error: 78098.9064\n",
      "Epoch 1763/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 8947558420.1471 - mean_absolute_error: 81696.0463 - val_loss: 9008880059.3814 - val_mean_absolute_error: 79920.0957\n",
      "Epoch 1764/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 8853450240.0000 - mean_absolute_error: 81968.0682 - val_loss: 9450992886.3230 - val_mean_absolute_error: 82459.3250\n",
      "Epoch 1765/5000\n",
      "1169/1169 [==============================] - 0s 411us/step - loss: 8971759749.1463 - mean_absolute_error: 81572.2447 - val_loss: 8712724539.8213 - val_mean_absolute_error: 78807.1281\n",
      "Epoch 1766/5000\n",
      "1169/1169 [==============================] - 1s 462us/step - loss: 8857960427.8529 - mean_absolute_error: 81822.6202 - val_loss: 8258046638.1856 - val_mean_absolute_error: 76223.1131\n",
      "Epoch 1767/5000\n",
      "1169/1169 [==============================] - 1s 446us/step - loss: 8584353138.0941 - mean_absolute_error: 81601.3858 - val_loss: 8351526920.7973 - val_mean_absolute_error: 76167.7208\n",
      "Epoch 1768/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 8672680939.6339 - mean_absolute_error: 81036.9107 - val_loss: 7438074799.0653 - val_mean_absolute_error: 71630.5465\n",
      "Epoch 1769/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 8608185891.4765 - mean_absolute_error: 80843.2209 - val_loss: 7681865080.5223 - val_mean_absolute_error: 73581.4185\n",
      "Epoch 1770/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 8913230998.6655 - mean_absolute_error: 82145.2008 - val_loss: 8209227543.7526 - val_mean_absolute_error: 76020.3104\n",
      "Epoch 1771/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 8457085230.2070 - mean_absolute_error: 80592.6101 - val_loss: 8077695970.0893 - val_mean_absolute_error: 74754.4808\n",
      "Epoch 1772/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 8587360925.6732 - mean_absolute_error: 81323.5163 - val_loss: 9057316213.0034 - val_mean_absolute_error: 79748.2075\n",
      "Epoch 1773/5000\n",
      "1169/1169 [==============================] - 0s 376us/step - loss: 8493293863.1993 - mean_absolute_error: 80413.4339 - val_loss: 9376186383.8351 - val_mean_absolute_error: 81101.5698\n",
      "Epoch 1774/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 8636504274.2310 - mean_absolute_error: 79850.9977 - val_loss: 8971625616.2749 - val_mean_absolute_error: 80900.7702\n",
      "Epoch 1775/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 9015392142.5629 - mean_absolute_error: 82287.6965 - val_loss: 11950375130.1718 - val_mean_absolute_error: 94124.7115\n",
      "Epoch 1776/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 8951299989.1326 - mean_absolute_error: 81140.6798 - val_loss: 10876006776.5223 - val_mean_absolute_error: 88278.9126\n",
      "Epoch 1777/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 8725287338.5937 - mean_absolute_error: 80305.7416 - val_loss: 8045782279.9175 - val_mean_absolute_error: 75437.8665\n",
      "Epoch 1778/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 8724895111.5552 - mean_absolute_error: 81879.3488 - val_loss: 8164857521.7045 - val_mean_absolute_error: 74594.2634\n",
      "Epoch 1779/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 8765099687.7468 - mean_absolute_error: 80647.4116 - val_loss: 8971642529.8694 - val_mean_absolute_error: 79053.0154\n",
      "Epoch 1780/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 8454501230.5902 - mean_absolute_error: 79309.2295 - val_loss: 8534418154.0069 - val_mean_absolute_error: 76894.5402\n",
      "Epoch 1781/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 8339558627.7502 - mean_absolute_error: 79642.1735 - val_loss: 9027915849.8969 - val_mean_absolute_error: 80250.1930\n",
      "Epoch 1782/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 8779188448.2464 - mean_absolute_error: 81356.8892 - val_loss: 8243519116.7560 - val_mean_absolute_error: 75612.0386\n",
      "Epoch 1783/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 8268480975.3841 - mean_absolute_error: 78926.1766 - val_loss: 8733489403.6014 - val_mean_absolute_error: 77905.5304\n",
      "Epoch 1784/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 8556909142.7203 - mean_absolute_error: 79840.3867 - val_loss: 8725711817.4570 - val_mean_absolute_error: 78071.8264\n",
      "Epoch 1785/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 8237342364.3593 - mean_absolute_error: 79867.4584 - val_loss: 8152096748.6460 - val_mean_absolute_error: 76040.0742\n",
      "Epoch 1786/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 8392474092.9478 - mean_absolute_error: 79564.8188 - val_loss: 9179044501.5533 - val_mean_absolute_error: 80289.7147\n",
      "Epoch 1787/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 8340698103.6784 - mean_absolute_error: 79747.4969 - val_loss: 7315475695.2852 - val_mean_absolute_error: 70673.8243\n",
      "Epoch 1788/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 8287558288.0958 - mean_absolute_error: 79433.7862 - val_loss: 8045822073.4021 - val_mean_absolute_error: 73496.3744\n",
      "Epoch 1789/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 8329015026.6416 - mean_absolute_error: 78593.7789 - val_loss: 8241042298.2818 - val_mean_absolute_error: 75996.9557\n",
      "Epoch 1790/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 8137662003.1343 - mean_absolute_error: 78887.6432 - val_loss: 8374193938.4742 - val_mean_absolute_error: 76320.7964\n",
      "Epoch 1791/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 8530974149.5295 - mean_absolute_error: 80289.5054 - val_loss: 8512192424.0275 - val_mean_absolute_error: 75467.3227\n",
      "Epoch 1792/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 8399291948.2361 - mean_absolute_error: 78769.3933 - val_loss: 8582820543.7801 - val_mean_absolute_error: 77950.2423\n",
      "Epoch 1793/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 7959833538.6826 - mean_absolute_error: 77813.8692 - val_loss: 8396000681.7869 - val_mean_absolute_error: 76438.6230\n",
      "Epoch 1794/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 7960689233.0265 - mean_absolute_error: 77761.8759 - val_loss: 8452010230.3230 - val_mean_absolute_error: 76738.3779\n",
      "Epoch 1795/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 8481220134.9803 - mean_absolute_error: 80179.8932 - val_loss: 9203599423.3402 - val_mean_absolute_error: 80737.1727\n",
      "Epoch 1796/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 7966263081.3892 - mean_absolute_error: 77859.3560 - val_loss: 8956077648.9347 - val_mean_absolute_error: 79520.4852\n",
      "Epoch 1797/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 8171795316.0650 - mean_absolute_error: 78587.1113 - val_loss: 8821915892.5636 - val_mean_absolute_error: 79442.8030\n",
      "Epoch 1798/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 8245015330.3815 - mean_absolute_error: 78683.0730 - val_loss: 8775543910.0481 - val_mean_absolute_error: 79944.3423\n",
      "Epoch 1799/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 8128826450.3405 - mean_absolute_error: 78065.5291 - val_loss: 9401608816.6048 - val_mean_absolute_error: 81918.5777\n",
      "Epoch 1800/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 8060605641.6903 - mean_absolute_error: 77679.8323 - val_loss: 7805239558.1581 - val_mean_absolute_error: 73544.1728\n",
      "Epoch 1801/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 8129464082.6142 - mean_absolute_error: 78064.9957 - val_loss: 8199248797.4708 - val_mean_absolute_error: 74754.4085\n",
      "Epoch 1802/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 8117423520.0821 - mean_absolute_error: 77775.2927 - val_loss: 7651395610.3918 - val_mean_absolute_error: 72371.2640\n",
      "Epoch 1803/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 8378640511.0145 - mean_absolute_error: 79210.1396 - val_loss: 9371625866.1168 - val_mean_absolute_error: 81293.1687\n",
      "Epoch 1804/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 8144131333.0368 - mean_absolute_error: 78867.4919 - val_loss: 7978740438.6529 - val_mean_absolute_error: 74748.1648\n",
      "Epoch 1805/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 8296720524.1540 - mean_absolute_error: 78700.8384 - val_loss: 7822113223.6976 - val_mean_absolute_error: 73526.8046\n",
      "Epoch 1806/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 8158337804.4825 - mean_absolute_error: 78618.3625 - val_loss: 8696372533.6632 - val_mean_absolute_error: 77544.2704\n",
      "Epoch 1807/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 8190112499.0796 - mean_absolute_error: 78203.9196 - val_loss: 8568899318.3230 - val_mean_absolute_error: 76804.0999\n",
      "Epoch 1808/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 8062476902.0496 - mean_absolute_error: 76945.9090 - val_loss: 8863465702.4880 - val_mean_absolute_error: 78304.4053\n",
      "Epoch 1809/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 8028041509.4474 - mean_absolute_error: 77199.6332 - val_loss: 8520226323.3540 - val_mean_absolute_error: 77192.5046\n",
      "Epoch 1810/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 8039658780.2498 - mean_absolute_error: 77830.2988 - val_loss: 8965180898.0893 - val_mean_absolute_error: 78052.5934\n",
      "Epoch 1811/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 7736709095.6920 - mean_absolute_error: 75927.8254 - val_loss: 8620965198.2955 - val_mean_absolute_error: 76717.8975\n",
      "Epoch 1812/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 8100601133.1121 - mean_absolute_error: 76962.7162 - val_loss: 8181892514.7491 - val_mean_absolute_error: 74506.9920\n",
      "Epoch 1813/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 8002575011.8050 - mean_absolute_error: 76491.7490 - val_loss: 8121117776.9347 - val_mean_absolute_error: 74251.7989\n",
      "Epoch 1814/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 7969321197.3858 - mean_absolute_error: 77366.0575 - val_loss: 8898415674.0619 - val_mean_absolute_error: 78653.7493\n",
      "Epoch 1815/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 7841767204.1334 - mean_absolute_error: 77520.8144 - val_loss: 9410068752.7148 - val_mean_absolute_error: 80920.8741\n",
      "Epoch 1816/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 8064027820.5646 - mean_absolute_error: 77589.0909 - val_loss: 9008004798.0206 - val_mean_absolute_error: 78706.3294\n",
      "Epoch 1817/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 8058821376.2190 - mean_absolute_error: 76016.3524 - val_loss: 6949464876.8660 - val_mean_absolute_error: 68207.6596\n",
      "Epoch 1818/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 8054017738.7853 - mean_absolute_error: 77596.3312 - val_loss: 7270642102.1031 - val_mean_absolute_error: 70043.8330\n",
      "Epoch 1819/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 344us/step - loss: 8105683660.5372 - mean_absolute_error: 77479.3888 - val_loss: 8235439418.9416 - val_mean_absolute_error: 74517.8138\n",
      "Epoch 1820/5000\n",
      "1169/1169 [==============================] - 0s 318us/step - loss: 7970726631.0351 - mean_absolute_error: 76732.3117 - val_loss: 7722567229.5808 - val_mean_absolute_error: 73088.6336\n",
      "Epoch 1821/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 7819392287.7536 - mean_absolute_error: 76001.8792 - val_loss: 7682508214.1031 - val_mean_absolute_error: 72924.5860\n",
      "Epoch 1822/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 7971692875.1138 - mean_absolute_error: 76868.1948 - val_loss: 7116016469.3333 - val_mean_absolute_error: 69152.5841\n",
      "Epoch 1823/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 7623205903.3293 - mean_absolute_error: 76134.4024 - val_loss: 7980691897.6220 - val_mean_absolute_error: 73999.6646\n",
      "Epoch 1824/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 7653749703.5004 - mean_absolute_error: 74599.9251 - val_loss: 9291647120.2749 - val_mean_absolute_error: 78274.3377\n",
      "Epoch 1825/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 7645713865.2524 - mean_absolute_error: 75747.6572 - val_loss: 7741289060.2887 - val_mean_absolute_error: 71203.4399\n",
      "Epoch 1826/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 7811035229.9470 - mean_absolute_error: 74726.8094 - val_loss: 8292367898.3918 - val_mean_absolute_error: 74595.3303\n",
      "Epoch 1827/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 7908140762.9906 - mean_absolute_error: 76479.3632 - val_loss: 7408695287.2027 - val_mean_absolute_error: 70719.4595\n",
      "Epoch 1828/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 7884592660.5851 - mean_absolute_error: 76606.6511 - val_loss: 7272389225.5670 - val_mean_absolute_error: 70586.2627\n",
      "Epoch 1829/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 7700563282.9974 - mean_absolute_error: 75979.8752 - val_loss: 7008116220.4811 - val_mean_absolute_error: 69542.7640\n",
      "Epoch 1830/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 7760305746.7784 - mean_absolute_error: 76233.2574 - val_loss: 7975875744.1100 - val_mean_absolute_error: 74014.5323\n",
      "Epoch 1831/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 7898988526.0428 - mean_absolute_error: 76226.2518 - val_loss: 7638171413.9931 - val_mean_absolute_error: 71903.6468\n",
      "Epoch 1832/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 7616769458.0393 - mean_absolute_error: 75082.9332 - val_loss: 7192064888.5223 - val_mean_absolute_error: 69746.9130\n",
      "Epoch 1833/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 7704585122.2720 - mean_absolute_error: 75643.9826 - val_loss: 7115462374.4880 - val_mean_absolute_error: 68766.0062\n",
      "Epoch 1834/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 7957033669.0915 - mean_absolute_error: 76169.7678 - val_loss: 7639497798.3780 - val_mean_absolute_error: 70460.3253\n",
      "Epoch 1835/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 7936879606.8024 - mean_absolute_error: 75873.5107 - val_loss: 7560184970.9966 - val_mean_absolute_error: 69872.2754\n",
      "Epoch 1836/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 7466970674.3678 - mean_absolute_error: 74250.9895 - val_loss: 8064345385.3471 - val_mean_absolute_error: 73747.5464\n",
      "Epoch 1837/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 7599757292.7288 - mean_absolute_error: 74157.6404 - val_loss: 7841864529.8144 - val_mean_absolute_error: 72811.8215\n",
      "Epoch 1838/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 7830670981.5843 - mean_absolute_error: 75355.4270 - val_loss: 8463984483.4089 - val_mean_absolute_error: 74958.5991\n",
      "Epoch 1839/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 7831283661.1942 - mean_absolute_error: 74334.3035 - val_loss: 8499675322.5017 - val_mean_absolute_error: 74817.4780\n",
      "Epoch 1840/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 7767495449.6219 - mean_absolute_error: 74887.6617 - val_loss: 6581790790.3780 - val_mean_absolute_error: 67147.0426\n",
      "Epoch 1841/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 7507733482.9769 - mean_absolute_error: 74007.8482 - val_loss: 8611060662.1031 - val_mean_absolute_error: 75880.1511\n",
      "Epoch 1842/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 7354101086.3849 - mean_absolute_error: 72564.2284 - val_loss: 6051625408.6598 - val_mean_absolute_error: 61338.4939\n",
      "Epoch 1843/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 7382722610.3678 - mean_absolute_error: 73720.4823 - val_loss: 6777142836.7835 - val_mean_absolute_error: 67341.2532\n",
      "Epoch 1844/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 7591549398.3918 - mean_absolute_error: 73162.3264 - val_loss: 7714165870.8454 - val_mean_absolute_error: 72411.6311\n",
      "Epoch 1845/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 7332189470.4397 - mean_absolute_error: 72872.0219 - val_loss: 7551869431.2027 - val_mean_absolute_error: 72528.8253\n",
      "Epoch 1846/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 7191712453.0915 - mean_absolute_error: 72514.5921 - val_loss: 7594129971.0241 - val_mean_absolute_error: 70721.5751\n",
      "Epoch 1847/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 7677663967.8631 - mean_absolute_error: 74758.5959 - val_loss: 7967561024.2199 - val_mean_absolute_error: 73516.9784\n",
      "Epoch 1848/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 7808304564.6672 - mean_absolute_error: 74960.0919 - val_loss: 7409997767.6976 - val_mean_absolute_error: 70580.7677\n",
      "Epoch 1849/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 7536691041.4508 - mean_absolute_error: 74432.3620 - val_loss: 8254296695.6426 - val_mean_absolute_error: 75191.4884\n",
      "Epoch 1850/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 7578628381.5637 - mean_absolute_error: 73369.9961 - val_loss: 7222254095.8351 - val_mean_absolute_error: 69832.8784\n",
      "Epoch 1851/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 7263907663.9316 - mean_absolute_error: 73289.7166 - val_loss: 7517537644.2062 - val_mean_absolute_error: 72270.9145\n",
      "Epoch 1852/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 7371944815.4662 - mean_absolute_error: 72832.2162 - val_loss: 6807847307.8763 - val_mean_absolute_error: 68442.0184\n",
      "Epoch 1853/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 7487187174.3781 - mean_absolute_error: 73097.3927 - val_loss: 8716073201.0447 - val_mean_absolute_error: 78463.7489\n",
      "Epoch 1854/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 7485000871.3088 - mean_absolute_error: 74146.3820 - val_loss: 7828135881.4570 - val_mean_absolute_error: 72744.7336\n",
      "Epoch 1855/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 7723921674.2926 - mean_absolute_error: 74237.2304 - val_loss: 8022476903.8076 - val_mean_absolute_error: 74289.7372\n",
      "Epoch 1856/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 6781756747.5518 - mean_absolute_error: 70584.6680 - val_loss: 7866561537.7594 - val_mean_absolute_error: 71958.4248\n",
      "Epoch 1857/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 7612895355.0727 - mean_absolute_error: 73164.8619 - val_loss: 7386592516.3986 - val_mean_absolute_error: 71628.7493\n",
      "Epoch 1858/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 7665824682.1557 - mean_absolute_error: 73345.4888 - val_loss: 6506205210.3918 - val_mean_absolute_error: 65917.6782\n",
      "Epoch 1859/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 7395917606.7613 - mean_absolute_error: 73468.1026 - val_loss: 7965782151.4777 - val_mean_absolute_error: 74846.1876\n",
      "Epoch 1860/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 7246322488.7186 - mean_absolute_error: 72187.1153 - val_loss: 8301337334.3230 - val_mean_absolute_error: 74828.9899\n",
      "Epoch 1861/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 7317494839.6236 - mean_absolute_error: 72927.2089 - val_loss: 8075588608.0000 - val_mean_absolute_error: 72157.1714\n",
      "Epoch 1862/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 7699549879.2951 - mean_absolute_error: 73111.4445 - val_loss: 8738774019.5189 - val_mean_absolute_error: 77697.2981\n",
      "Epoch 1863/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 7500197238.4739 - mean_absolute_error: 73477.0399 - val_loss: 7874532948.4536 - val_mean_absolute_error: 73895.8995\n",
      "Epoch 1864/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 7536689096.3764 - mean_absolute_error: 73742.4233 - val_loss: 7185465620.2337 - val_mean_absolute_error: 68644.3734\n",
      "Epoch 1865/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 7142458142.0017 - mean_absolute_error: 71891.6589 - val_loss: 7178714057.4570 - val_mean_absolute_error: 68403.0358\n",
      "Epoch 1866/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 7206486852.5441 - mean_absolute_error: 71980.9760 - val_loss: 6633902146.8591 - val_mean_absolute_error: 64970.4411\n",
      "Epoch 1867/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 7519163770.4157 - mean_absolute_error: 72982.9178 - val_loss: 7635249032.3574 - val_mean_absolute_error: 70847.1607\n",
      "Epoch 1868/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 7258886363.4286 - mean_absolute_error: 71811.2047 - val_loss: 8052160373.0034 - val_mean_absolute_error: 72642.2065\n",
      "Epoch 1869/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6987455674.1420 - mean_absolute_error: 70565.1328 - val_loss: 7593356815.8351 - val_mean_absolute_error: 72785.0478\n",
      "Epoch 1870/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 6846109276.8520 - mean_absolute_error: 71077.4670 - val_loss: 7481023315.5739 - val_mean_absolute_error: 71717.6616\n",
      "Epoch 1871/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 6601657940.5304 - mean_absolute_error: 69299.7993 - val_loss: 7034280553.5670 - val_mean_absolute_error: 68428.1142\n",
      "Epoch 1872/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 7118209043.2712 - mean_absolute_error: 71583.4384 - val_loss: 6553471644.5911 - val_mean_absolute_error: 65283.9455\n",
      "Epoch 1873/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 7147350432.9581 - mean_absolute_error: 71855.6767 - val_loss: 7010643265.9794 - val_mean_absolute_error: 68259.8082\n",
      "Epoch 1874/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6965335866.0325 - mean_absolute_error: 70417.8471 - val_loss: 7178520166.0481 - val_mean_absolute_error: 68547.8007\n",
      "Epoch 1875/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 7606766315.1959 - mean_absolute_error: 73254.1621 - val_loss: 7765673450.8866 - val_mean_absolute_error: 71859.8970\n",
      "Epoch 1876/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 7454771497.3892 - mean_absolute_error: 72156.3493 - val_loss: 6221607058.0344 - val_mean_absolute_error: 64392.0820\n",
      "Epoch 1877/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 7250326602.0188 - mean_absolute_error: 71758.7173 - val_loss: 7462379041.4296 - val_mean_absolute_error: 70048.4097\n",
      "Epoch 1878/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 6959238348.9752 - mean_absolute_error: 70605.8777 - val_loss: 8305923900.7010 - val_mean_absolute_error: 74478.6063\n",
      "Epoch 1879/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 7446587824.2874 - mean_absolute_error: 71646.1080 - val_loss: 7977104149.9931 - val_mean_absolute_error: 72717.9330\n",
      "Epoch 1880/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 6952772045.1942 - mean_absolute_error: 71075.5010 - val_loss: 8132782609.5945 - val_mean_absolute_error: 74423.9562\n",
      "Epoch 1881/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 7037517742.5355 - mean_absolute_error: 71309.5342 - val_loss: 6932455251.5739 - val_mean_absolute_error: 67992.9615\n",
      "Epoch 1882/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 6868192182.2002 - mean_absolute_error: 70309.9484 - val_loss: 5889537046.8729 - val_mean_absolute_error: 63003.9592\n",
      "Epoch 1883/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 6766634252.9204 - mean_absolute_error: 69721.5618 - val_loss: 7771984830.9003 - val_mean_absolute_error: 72773.0153\n",
      "Epoch 1884/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 7337691574.8571 - mean_absolute_error: 71815.5717 - val_loss: 6847338466.0893 - val_mean_absolute_error: 68096.4104\n",
      "Epoch 1885/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 7315393120.7938 - mean_absolute_error: 71168.1363 - val_loss: 7676981599.8900 - val_mean_absolute_error: 72110.6517\n",
      "Epoch 1886/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 7059270091.4423 - mean_absolute_error: 70472.6345 - val_loss: 6913558659.9588 - val_mean_absolute_error: 66297.8985\n",
      "Epoch 1887/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 7055109001.3071 - mean_absolute_error: 69717.4423 - val_loss: 6029355016.7973 - val_mean_absolute_error: 61754.3151\n",
      "Epoch 1888/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 6825365926.2139 - mean_absolute_error: 69370.6964 - val_loss: 6421772886.2131 - val_mean_absolute_error: 63539.0582\n",
      "Epoch 1889/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 6893046720.7117 - mean_absolute_error: 69042.7301 - val_loss: 7814484135.1478 - val_mean_absolute_error: 72075.7100\n",
      "Epoch 1890/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 6848857715.1891 - mean_absolute_error: 69540.6071 - val_loss: 6427575603.9038 - val_mean_absolute_error: 65303.8608\n",
      "Epoch 1891/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 6701430983.7194 - mean_absolute_error: 69757.3636 - val_loss: 6685435177.3471 - val_mean_absolute_error: 66729.1012\n",
      "Epoch 1892/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 6967823462.0496 - mean_absolute_error: 69570.1944 - val_loss: 6836107256.9622 - val_mean_absolute_error: 67657.9503\n",
      "Epoch 1893/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 6905603522.2447 - mean_absolute_error: 70626.1923 - val_loss: 8142466933.0034 - val_mean_absolute_error: 74065.7924\n",
      "Epoch 1894/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 6916103943.6647 - mean_absolute_error: 68133.0606 - val_loss: 7142744090.3918 - val_mean_absolute_error: 70181.7182\n",
      "Epoch 1895/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6749720294.8161 - mean_absolute_error: 70391.1158 - val_loss: 6071509827.7388 - val_mean_absolute_error: 63240.6500\n",
      "Epoch 1896/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 6778491724.4277 - mean_absolute_error: 69132.9725 - val_loss: 7270325196.9759 - val_mean_absolute_error: 68948.9164\n",
      "Epoch 1897/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 7038712885.2147 - mean_absolute_error: 70570.0717 - val_loss: 6769355293.9107 - val_mean_absolute_error: 66528.8494\n",
      "Epoch 1898/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 6863460457.7725 - mean_absolute_error: 69140.4794 - val_loss: 5903509354.4467 - val_mean_absolute_error: 61518.4679\n",
      "Epoch 1899/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 6956936311.1309 - mean_absolute_error: 69268.6828 - val_loss: 7231457514.0069 - val_mean_absolute_error: 68328.7239\n",
      "Epoch 1900/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 6976540626.8879 - mean_absolute_error: 69906.4252 - val_loss: 6982662631.3677 - val_mean_absolute_error: 69945.2705\n",
      "Epoch 1901/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 347us/step - loss: 6754922418.4773 - mean_absolute_error: 69144.9716 - val_loss: 6877257372.5911 - val_mean_absolute_error: 69068.8856\n",
      "Epoch 1902/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 6526123915.4970 - mean_absolute_error: 68761.1803 - val_loss: 7505362424.9622 - val_mean_absolute_error: 71384.0099\n",
      "Epoch 1903/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 6886202922.0462 - mean_absolute_error: 69365.8920 - val_loss: 6829924487.4777 - val_mean_absolute_error: 67712.7318\n",
      "Epoch 1904/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 6471568292.4619 - mean_absolute_error: 67921.6298 - val_loss: 7028387584.8797 - val_mean_absolute_error: 67759.2335\n",
      "Epoch 1905/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 6552480093.0710 - mean_absolute_error: 67557.0634 - val_loss: 7102052783.0653 - val_mean_absolute_error: 68959.7294\n",
      "Epoch 1906/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 6685084697.8409 - mean_absolute_error: 68714.6364 - val_loss: 6179929214.6804 - val_mean_absolute_error: 62847.7785\n",
      "Epoch 1907/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 6637096502.7476 - mean_absolute_error: 68261.3750 - val_loss: 5899597662.1306 - val_mean_absolute_error: 61736.0492\n",
      "Epoch 1908/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 6451791399.8563 - mean_absolute_error: 67511.0423 - val_loss: 7022378867.2440 - val_mean_absolute_error: 67166.0955\n",
      "Epoch 1909/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 6710676975.7947 - mean_absolute_error: 68127.1841 - val_loss: 6970735556.1787 - val_mean_absolute_error: 66705.6722\n",
      "Epoch 1910/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 6411515717.8580 - mean_absolute_error: 66719.2792 - val_loss: 6865621423.0653 - val_mean_absolute_error: 65545.9079\n",
      "Epoch 1911/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 6803049408.9307 - mean_absolute_error: 68150.5543 - val_loss: 7341179691.1065 - val_mean_absolute_error: 67683.9123\n",
      "Epoch 1912/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 6502674029.1121 - mean_absolute_error: 66853.1284 - val_loss: 7281154099.0241 - val_mean_absolute_error: 69181.6864\n",
      "Epoch 1913/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 6594640058.1420 - mean_absolute_error: 67038.7725 - val_loss: 7043336155.0515 - val_mean_absolute_error: 68666.2867\n",
      "Epoch 1914/5000\n",
      "1169/1169 [==============================] - 0s 315us/step - loss: 6962117416.8417 - mean_absolute_error: 69313.5710 - val_loss: 6230220548.3986 - val_mean_absolute_error: 65407.2452\n",
      "Epoch 1915/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6564705575.6373 - mean_absolute_error: 67487.1151 - val_loss: 6308248039.3677 - val_mean_absolute_error: 64669.4923\n",
      "Epoch 1916/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 6964244013.1121 - mean_absolute_error: 67868.4379 - val_loss: 6728310910.6804 - val_mean_absolute_error: 66965.3976\n",
      "Epoch 1917/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 6583034556.3319 - mean_absolute_error: 66290.8501 - val_loss: 6897439777.4296 - val_mean_absolute_error: 67734.1982\n",
      "Epoch 1918/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 6575678822.2686 - mean_absolute_error: 67570.9183 - val_loss: 7653497000.9072 - val_mean_absolute_error: 70492.0217\n",
      "Epoch 1919/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 6577794009.4577 - mean_absolute_error: 66283.3297 - val_loss: 7820140266.0069 - val_mean_absolute_error: 71687.6790\n",
      "Epoch 1920/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 6585497443.8597 - mean_absolute_error: 66309.0233 - val_loss: 7091525463.0928 - val_mean_absolute_error: 68935.2521\n",
      "Epoch 1921/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 6454306645.1873 - mean_absolute_error: 66667.9070 - val_loss: 6289286096.4948 - val_mean_absolute_error: 63887.7201\n",
      "Epoch 1922/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 6715385840.6707 - mean_absolute_error: 66624.7834 - val_loss: 6020273875.1340 - val_mean_absolute_error: 62298.4642\n",
      "Epoch 1923/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 6465979565.4405 - mean_absolute_error: 66462.6013 - val_loss: 6612695369.0172 - val_mean_absolute_error: 65166.5027\n",
      "Epoch 1924/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6448823541.2695 - mean_absolute_error: 67346.0843 - val_loss: 5703239424.8797 - val_mean_absolute_error: 60249.4269\n",
      "Epoch 1925/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 6524328574.5766 - mean_absolute_error: 67591.0120 - val_loss: 7547238083.2990 - val_mean_absolute_error: 69503.6558\n",
      "Epoch 1926/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 6141022780.8794 - mean_absolute_error: 65664.9826 - val_loss: 6701899563.1065 - val_mean_absolute_error: 64489.8282\n",
      "Epoch 1927/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 6700514818.1899 - mean_absolute_error: 66355.5472 - val_loss: 6613064334.5155 - val_mean_absolute_error: 66187.7078\n",
      "Epoch 1928/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 6228351431.5004 - mean_absolute_error: 65874.4298 - val_loss: 5568803116.8660 - val_mean_absolute_error: 59210.6618\n",
      "Epoch 1929/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6259441347.3396 - mean_absolute_error: 66137.3576 - val_loss: 5172725551.5052 - val_mean_absolute_error: 54954.7036\n",
      "Epoch 1930/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 6795785299.6544 - mean_absolute_error: 68214.5421 - val_loss: 5731315750.7079 - val_mean_absolute_error: 60737.4088\n",
      "Epoch 1931/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 6576300982.4192 - mean_absolute_error: 66187.4332 - val_loss: 5793565877.2234 - val_mean_absolute_error: 61420.2369\n",
      "Epoch 1932/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 6372096758.1454 - mean_absolute_error: 66676.3641 - val_loss: 6213187958.7629 - val_mean_absolute_error: 63603.3489\n",
      "Epoch 1933/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6357478392.5543 - mean_absolute_error: 66068.4599 - val_loss: 6465687961.9519 - val_mean_absolute_error: 64432.8639\n",
      "Epoch 1934/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 6759509055.9453 - mean_absolute_error: 67786.7676 - val_loss: 7061584336.4948 - val_mean_absolute_error: 68613.5758\n",
      "Epoch 1935/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 6037514405.9949 - mean_absolute_error: 65673.2943 - val_loss: 5931832883.0241 - val_mean_absolute_error: 61982.9581\n",
      "Epoch 1936/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6396111810.2447 - mean_absolute_error: 65141.1873 - val_loss: 6533618707.3540 - val_mean_absolute_error: 65623.8139\n",
      "Epoch 1937/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 6162391736.8281 - mean_absolute_error: 65763.9343 - val_loss: 6518242812.4811 - val_mean_absolute_error: 64651.2840\n",
      "Epoch 1938/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 6107515055.1925 - mean_absolute_error: 64760.0513 - val_loss: 6624026104.9622 - val_mean_absolute_error: 65179.6516\n",
      "Epoch 1939/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 6373555602.0667 - mean_absolute_error: 65341.5834 - val_loss: 6201055256.6323 - val_mean_absolute_error: 62306.7572\n",
      "Epoch 1940/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 6493170552.8828 - mean_absolute_error: 66151.7261 - val_loss: 6985666083.1890 - val_mean_absolute_error: 64225.7350\n",
      "Epoch 1941/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 6098205353.4987 - mean_absolute_error: 64203.2303 - val_loss: 6316991734.3230 - val_mean_absolute_error: 63002.7837\n",
      "Epoch 1942/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6334834605.6595 - mean_absolute_error: 65719.9554 - val_loss: 6381408678.2680 - val_mean_absolute_error: 63783.1741\n",
      "Epoch 1943/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 6485325358.4260 - mean_absolute_error: 66454.8621 - val_loss: 6867793073.7045 - val_mean_absolute_error: 66567.1594\n",
      "Epoch 1944/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 6166537822.8229 - mean_absolute_error: 63918.4808 - val_loss: 6730736680.4674 - val_mean_absolute_error: 66441.0846\n",
      "Epoch 1945/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6537361399.2404 - mean_absolute_error: 66405.0327 - val_loss: 6495694473.2371 - val_mean_absolute_error: 65476.3195\n",
      "Epoch 1946/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 6436369116.7425 - mean_absolute_error: 65681.3946 - val_loss: 6092443009.3196 - val_mean_absolute_error: 63032.6961\n",
      "Epoch 1947/5000\n",
      "1169/1169 [==============================] - 0s 319us/step - loss: 6196519109.9675 - mean_absolute_error: 66127.4767 - val_loss: 7058578699.4364 - val_mean_absolute_error: 66019.7967\n",
      "Epoch 1948/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 6042287949.9606 - mean_absolute_error: 63529.4108 - val_loss: 5713104683.1065 - val_mean_absolute_error: 57177.5802\n",
      "Epoch 1949/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 5934391949.9059 - mean_absolute_error: 64323.7444 - val_loss: 5182930540.2062 - val_mean_absolute_error: 55488.3101\n",
      "Epoch 1950/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 6169400733.3447 - mean_absolute_error: 64127.9243 - val_loss: 5545272084.2337 - val_mean_absolute_error: 56824.8104\n",
      "Epoch 1951/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 6228279961.7314 - mean_absolute_error: 64108.5112 - val_loss: 5796133189.4983 - val_mean_absolute_error: 60289.8681\n",
      "Epoch 1952/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 6468013299.0796 - mean_absolute_error: 66022.3168 - val_loss: 6227550537.0172 - val_mean_absolute_error: 62316.8980\n",
      "Epoch 1953/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 6437910374.7066 - mean_absolute_error: 64990.7283 - val_loss: 5634682607.2852 - val_mean_absolute_error: 59562.0941\n",
      "Epoch 1954/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 6438868436.6399 - mean_absolute_error: 65887.8239 - val_loss: 5400039531.3265 - val_mean_absolute_error: 57192.0039\n",
      "Epoch 1955/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 6046694495.0419 - mean_absolute_error: 64067.6533 - val_loss: 6320729807.6151 - val_mean_absolute_error: 60199.2477\n",
      "Epoch 1956/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 6084683793.5192 - mean_absolute_error: 64526.4035 - val_loss: 5975035360.3299 - val_mean_absolute_error: 61561.4976\n",
      "Epoch 1957/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 5956178946.1899 - mean_absolute_error: 63384.3943 - val_loss: 5395137479.6976 - val_mean_absolute_error: 58189.9803\n",
      "Epoch 1958/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 6462335384.6364 - mean_absolute_error: 65375.7667 - val_loss: 6612141756.2612 - val_mean_absolute_error: 64236.6914\n",
      "Epoch 1959/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 6285515647.6715 - mean_absolute_error: 63867.8075 - val_loss: 5184141209.9519 - val_mean_absolute_error: 56792.9327\n",
      "Epoch 1960/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 6209690188.6467 - mean_absolute_error: 65116.9528 - val_loss: 5093238375.8076 - val_mean_absolute_error: 57050.9420\n",
      "Epoch 1961/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 5870966105.1292 - mean_absolute_error: 62611.6272 - val_loss: 6282636557.1959 - val_mean_absolute_error: 64807.1749\n",
      "Epoch 1962/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 6014735081.0060 - mean_absolute_error: 63549.4774 - val_loss: 5672022601.8969 - val_mean_absolute_error: 60381.0385\n",
      "Epoch 1963/5000\n",
      "1169/1169 [==============================] - 0s 306us/step - loss: 5772659281.9025 - mean_absolute_error: 62380.1600 - val_loss: 6297995364.2887 - val_mean_absolute_error: 63981.5720\n",
      "Epoch 1964/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 5808596319.6989 - mean_absolute_error: 62455.9906 - val_loss: 5100877085.9107 - val_mean_absolute_error: 56069.8217\n",
      "Epoch 1965/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 6020881043.8186 - mean_absolute_error: 63926.8769 - val_loss: 5845784795.9313 - val_mean_absolute_error: 59177.4072\n",
      "Epoch 1966/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 5829401862.7887 - mean_absolute_error: 62836.7551 - val_loss: 6075180867.7388 - val_mean_absolute_error: 60738.9156\n",
      "Epoch 1967/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 6083048360.4038 - mean_absolute_error: 62691.6720 - val_loss: 6592442419.0241 - val_mean_absolute_error: 64996.8609\n",
      "Epoch 1968/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 5920356213.5979 - mean_absolute_error: 62545.5556 - val_loss: 5915331219.7938 - val_mean_absolute_error: 61750.0955\n",
      "Epoch 1969/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 5992390409.4166 - mean_absolute_error: 63412.0793 - val_loss: 6259230609.1546 - val_mean_absolute_error: 62459.7115\n",
      "Epoch 1970/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 5930373687.8426 - mean_absolute_error: 61748.4097 - val_loss: 6520508713.3471 - val_mean_absolute_error: 63537.5974\n",
      "Epoch 1971/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 5854001181.0163 - mean_absolute_error: 62617.2124 - val_loss: 5945615233.3196 - val_mean_absolute_error: 59994.3744\n",
      "Epoch 1972/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 5872459590.2960 - mean_absolute_error: 63515.9110 - val_loss: 4640966876.8110 - val_mean_absolute_error: 51153.3196\n",
      "Epoch 1973/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 5898674535.2541 - mean_absolute_error: 62327.3153 - val_loss: 5772442219.3265 - val_mean_absolute_error: 58739.1757\n",
      "Epoch 1974/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 6076961301.4611 - mean_absolute_error: 62977.4323 - val_loss: 4368475968.2199 - val_mean_absolute_error: 51657.8767\n",
      "Epoch 1975/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 5583127136.7938 - mean_absolute_error: 61774.8376 - val_loss: 6107636243.3540 - val_mean_absolute_error: 62123.9581\n",
      "Epoch 1976/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 6264519238.8435 - mean_absolute_error: 63771.8440 - val_loss: 5183971841.7594 - val_mean_absolute_error: 54375.9973\n",
      "Epoch 1977/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 5969021103.5210 - mean_absolute_error: 63783.1227 - val_loss: 5519175379.1340 - val_mean_absolute_error: 57172.6255\n",
      "Epoch 1978/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 5844941650.1215 - mean_absolute_error: 61645.9469 - val_loss: 5826165005.1959 - val_mean_absolute_error: 60053.0364\n",
      "Epoch 1979/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 5775408975.9316 - mean_absolute_error: 62462.9373 - val_loss: 4849379613.0309 - val_mean_absolute_error: 52735.5136\n",
      "Epoch 1980/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 6265764384.4106 - mean_absolute_error: 63803.3453 - val_loss: 5445956428.5361 - val_mean_absolute_error: 55168.9052\n",
      "Epoch 1981/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 5612489769.1702 - mean_absolute_error: 62065.9922 - val_loss: 4801852101.9381 - val_mean_absolute_error: 53578.3328\n",
      "Epoch 1982/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 5573876275.6818 - mean_absolute_error: 60728.4747 - val_loss: 5661497852.4811 - val_mean_absolute_error: 59372.0359\n",
      "Epoch 1983/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 347us/step - loss: 5609581678.4808 - mean_absolute_error: 60613.0512 - val_loss: 5375307933.4708 - val_mean_absolute_error: 57687.2735\n",
      "Epoch 1984/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 6185546510.2344 - mean_absolute_error: 64144.1154 - val_loss: 5317857845.6632 - val_mean_absolute_error: 57104.6599\n",
      "Epoch 1985/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 5829765464.0342 - mean_absolute_error: 61825.1790 - val_loss: 5584389229.0859 - val_mean_absolute_error: 58316.4376\n",
      "Epoch 1986/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 5912573795.2027 - mean_absolute_error: 62722.3909 - val_loss: 5104268044.3162 - val_mean_absolute_error: 55112.0266\n",
      "Epoch 1987/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 5905708173.9059 - mean_absolute_error: 62205.3749 - val_loss: 5134835652.1787 - val_mean_absolute_error: 55642.5505\n",
      "Epoch 1988/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 5556549464.9102 - mean_absolute_error: 60576.8645 - val_loss: 5778533418.2268 - val_mean_absolute_error: 58722.7925\n",
      "Epoch 1989/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 5558939397.9127 - mean_absolute_error: 61851.1256 - val_loss: 5020439496.5773 - val_mean_absolute_error: 53352.5128\n",
      "Epoch 1990/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 5984040297.3345 - mean_absolute_error: 62985.7480 - val_loss: 6280848387.5189 - val_mean_absolute_error: 62594.0391\n",
      "Epoch 1991/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 5913938864.1779 - mean_absolute_error: 62313.6348 - val_loss: 5373485750.9828 - val_mean_absolute_error: 57043.6807\n",
      "Epoch 1992/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 5838823428.3798 - mean_absolute_error: 62469.8447 - val_loss: 5620889728.4399 - val_mean_absolute_error: 59633.5630\n",
      "Epoch 1993/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 5625855760.4243 - mean_absolute_error: 61011.8607 - val_loss: 5826913623.0928 - val_mean_absolute_error: 59970.3368\n",
      "Epoch 1994/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 5564965075.9829 - mean_absolute_error: 60868.3555 - val_loss: 5556411986.6942 - val_mean_absolute_error: 58451.1300\n",
      "Epoch 1995/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 5628628515.0385 - mean_absolute_error: 60101.7009 - val_loss: 6307333591.5326 - val_mean_absolute_error: 62568.6325\n",
      "Epoch 1996/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 5904335766.8845 - mean_absolute_error: 61765.6002 - val_loss: 5391256330.5567 - val_mean_absolute_error: 55027.7739\n",
      "Epoch 1997/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 5688971394.9564 - mean_absolute_error: 59777.1415 - val_loss: 6377674864.6048 - val_mean_absolute_error: 61059.0671\n",
      "Epoch 1998/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 5634959455.0419 - mean_absolute_error: 60531.4322 - val_loss: 6012119113.8969 - val_mean_absolute_error: 61011.4120\n",
      "Epoch 1999/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 5775823701.6253 - mean_absolute_error: 61910.8270 - val_loss: 5526067024.0550 - val_mean_absolute_error: 57710.9851\n",
      "Epoch 2000/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 5705412205.0573 - mean_absolute_error: 60873.3338 - val_loss: 4608207466.4467 - val_mean_absolute_error: 51709.1160\n",
      "Epoch 2001/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 5619026809.1018 - mean_absolute_error: 60848.0708 - val_loss: 5397777788.0412 - val_mean_absolute_error: 56379.5571\n",
      "Epoch 2002/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 5435578665.3892 - mean_absolute_error: 59848.5066 - val_loss: 5604699132.4811 - val_mean_absolute_error: 57393.9390\n",
      "Epoch 2003/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 5391685065.6903 - mean_absolute_error: 59524.4947 - val_loss: 6088187926.8729 - val_mean_absolute_error: 60709.4099\n",
      "Epoch 2004/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 5540745572.7357 - mean_absolute_error: 59760.1599 - val_loss: 4844142937.7320 - val_mean_absolute_error: 53190.4546\n",
      "Epoch 2005/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 5710786178.9564 - mean_absolute_error: 61568.8299 - val_loss: 5092395311.5052 - val_mean_absolute_error: 53176.4424\n",
      "Epoch 2006/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 5374010218.6484 - mean_absolute_error: 58922.9396 - val_loss: 5202408829.8007 - val_mean_absolute_error: 55764.3224\n",
      "Epoch 2007/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 5582358625.6698 - mean_absolute_error: 59852.4834 - val_loss: 5903376684.8660 - val_mean_absolute_error: 58831.9989\n",
      "Epoch 2008/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 5641696127.2335 - mean_absolute_error: 60365.6171 - val_loss: 6106096337.3746 - val_mean_absolute_error: 61006.4932\n",
      "Epoch 2009/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 5462379079.8289 - mean_absolute_error: 60145.8998 - val_loss: 6044667979.6564 - val_mean_absolute_error: 59366.9015\n",
      "Epoch 2010/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 5123178490.9632 - mean_absolute_error: 58061.3108 - val_loss: 6407919225.4021 - val_mean_absolute_error: 61232.9777\n",
      "Epoch 2011/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 5613263021.0026 - mean_absolute_error: 60134.9808 - val_loss: 4777126667.4364 - val_mean_absolute_error: 52600.3782\n",
      "Epoch 2012/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 5808823850.4842 - mean_absolute_error: 60839.7907 - val_loss: 5006305567.6701 - val_mean_absolute_error: 54168.1325\n",
      "Epoch 2013/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 5786841836.5098 - mean_absolute_error: 60982.1347 - val_loss: 5019790421.3333 - val_mean_absolute_error: 52823.2730\n",
      "Epoch 2014/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 5540431181.5227 - mean_absolute_error: 60294.3677 - val_loss: 6190166318.6254 - val_mean_absolute_error: 59715.6226\n",
      "Epoch 2015/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 5700733601.3961 - mean_absolute_error: 61263.2392 - val_loss: 5438226460.1512 - val_mean_absolute_error: 56139.8976\n",
      "Epoch 2016/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 5100586847.6989 - mean_absolute_error: 58047.8386 - val_loss: 6012758966.1031 - val_mean_absolute_error: 59226.9238\n",
      "Epoch 2017/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 5662814158.5081 - mean_absolute_error: 59769.1556 - val_loss: 5733908626.0344 - val_mean_absolute_error: 58521.0231\n",
      "Epoch 2018/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 5712050028.4003 - mean_absolute_error: 59752.5631 - val_loss: 4452592096.3299 - val_mean_absolute_error: 49551.4651\n",
      "Epoch 2019/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 5478126935.5962 - mean_absolute_error: 60013.8661 - val_loss: 4467126725.9381 - val_mean_absolute_error: 48663.2977\n",
      "Epoch 2020/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 5528365152.7938 - mean_absolute_error: 58964.5809 - val_loss: 5109506245.0584 - val_mean_absolute_error: 52704.8415\n",
      "Epoch 2021/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 5432814521.4850 - mean_absolute_error: 58884.6844 - val_loss: 5689708911.7251 - val_mean_absolute_error: 57095.2911\n",
      "Epoch 2022/5000\n",
      "1169/1169 [==============================] - 0s 303us/step - loss: 5188795847.9384 - mean_absolute_error: 59233.0386 - val_loss: 6545319863.8625 - val_mean_absolute_error: 61962.3808\n",
      "Epoch 2023/5000\n",
      "1169/1169 [==============================] - 0s 397us/step - loss: 5748249991.5552 - mean_absolute_error: 58947.8637 - val_loss: 5021159002.6117 - val_mean_absolute_error: 54014.3997\n",
      "Epoch 2024/5000\n",
      "1169/1169 [==============================] - 0s 388us/step - loss: 5444282940.0034 - mean_absolute_error: 58278.3260 - val_loss: 6411740478.4605 - val_mean_absolute_error: 61423.5352\n",
      "Epoch 2025/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 5339604710.8161 - mean_absolute_error: 58051.4992 - val_loss: 4199748194.5292 - val_mean_absolute_error: 49002.3955\n",
      "Epoch 2026/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 5307718453.7622 - mean_absolute_error: 59503.6876 - val_loss: 4346958966.7629 - val_mean_absolute_error: 48561.1223\n",
      "Epoch 2027/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 5567725617.4919 - mean_absolute_error: 60236.4081 - val_loss: 4498082611.0241 - val_mean_absolute_error: 49730.1348\n",
      "Epoch 2028/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 5098686672.0411 - mean_absolute_error: 57887.6946 - val_loss: 4494257276.9210 - val_mean_absolute_error: 49291.3600\n",
      "Epoch 2029/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 5028788915.5723 - mean_absolute_error: 56770.0850 - val_loss: 5060818715.2715 - val_mean_absolute_error: 52396.3836\n",
      "Epoch 2030/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 5691882284.4551 - mean_absolute_error: 59326.5787 - val_loss: 5268893239.4227 - val_mean_absolute_error: 55057.5360\n",
      "Epoch 2031/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 5240592692.1198 - mean_absolute_error: 57226.7574 - val_loss: 6704058540.4261 - val_mean_absolute_error: 61104.5977\n",
      "Epoch 2032/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 5602341453.5227 - mean_absolute_error: 60478.4968 - val_loss: 6318186487.2027 - val_mean_absolute_error: 58577.0901\n",
      "Epoch 2033/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 5694214731.3328 - mean_absolute_error: 59692.6306 - val_loss: 5766304090.6117 - val_mean_absolute_error: 57296.5671\n",
      "Epoch 2034/5000\n",
      "1169/1169 [==============================] - 1s 485us/step - loss: 5168044078.4260 - mean_absolute_error: 57301.1434 - val_loss: 5820401542.5979 - val_mean_absolute_error: 57987.4512\n",
      "Epoch 2035/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 5631437608.9512 - mean_absolute_error: 59399.9592 - val_loss: 5648357412.0687 - val_mean_absolute_error: 56984.5183\n",
      "Epoch 2036/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 5573723496.8965 - mean_absolute_error: 60267.4095 - val_loss: 5559957935.9450 - val_mean_absolute_error: 56640.4703\n",
      "Epoch 2037/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 5395279046.6245 - mean_absolute_error: 57913.5851 - val_loss: 4916106971.0515 - val_mean_absolute_error: 53461.4850\n",
      "Epoch 2038/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 5320477800.6775 - mean_absolute_error: 57628.9853 - val_loss: 5388666231.6426 - val_mean_absolute_error: 54437.7806\n",
      "Epoch 2039/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 5507632470.0633 - mean_absolute_error: 59182.8152 - val_loss: 5769682143.4502 - val_mean_absolute_error: 58015.1165\n",
      "Epoch 2040/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 5396724290.7921 - mean_absolute_error: 59549.3179 - val_loss: 6169511300.8385 - val_mean_absolute_error: 59330.4011\n",
      "Epoch 2041/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4983535639.6510 - mean_absolute_error: 57105.0544 - val_loss: 4570549553.2646 - val_mean_absolute_error: 49004.2264\n",
      "Epoch 2042/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 5561597380.8725 - mean_absolute_error: 57553.1419 - val_loss: 5406275036.8110 - val_mean_absolute_error: 53357.7626\n",
      "Epoch 2043/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 5080553302.8298 - mean_absolute_error: 57711.9253 - val_loss: 4865896106.6667 - val_mean_absolute_error: 52313.1066\n",
      "Epoch 2044/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 5163847763.6544 - mean_absolute_error: 57476.1085 - val_loss: 5228577360.9347 - val_mean_absolute_error: 54440.1457\n",
      "Epoch 2045/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 5287330997.7622 - mean_absolute_error: 58156.5667 - val_loss: 5798327327.6701 - val_mean_absolute_error: 56801.2412\n",
      "Epoch 2046/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 5201333889.8614 - mean_absolute_error: 56641.4700 - val_loss: 5344464576.6598 - val_mean_absolute_error: 53153.9731\n",
      "Epoch 2047/5000\n",
      "1169/1169 [==============================] - 0s 385us/step - loss: 4699099564.7836 - mean_absolute_error: 55189.5179 - val_loss: 3991785390.1856 - val_mean_absolute_error: 45946.8217\n",
      "Epoch 2048/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 5297564278.9119 - mean_absolute_error: 57034.0577 - val_loss: 5019835981.4158 - val_mean_absolute_error: 52868.4091\n",
      "Epoch 2049/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 5515812849.1086 - mean_absolute_error: 58999.0181 - val_loss: 4887504351.4502 - val_mean_absolute_error: 51074.5226\n",
      "Epoch 2050/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 5037800560.3422 - mean_absolute_error: 57269.8907 - val_loss: 4847483314.5842 - val_mean_absolute_error: 50311.3852\n",
      "Epoch 2051/5000\n",
      "1169/1169 [==============================] - 0s 390us/step - loss: 5046484185.4577 - mean_absolute_error: 57612.6215 - val_loss: 5118162503.2577 - val_mean_absolute_error: 53292.3921\n",
      "Epoch 2052/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 5170409263.9589 - mean_absolute_error: 57832.6917 - val_loss: 5137109183.7801 - val_mean_absolute_error: 53507.1272\n",
      "Epoch 2053/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 5105759178.1283 - mean_absolute_error: 55967.9262 - val_loss: 5047306222.4055 - val_mean_absolute_error: 53349.6445\n",
      "Epoch 2054/5000\n",
      "1169/1169 [==============================] - 0s 309us/step - loss: 5145044461.6048 - mean_absolute_error: 57536.9093 - val_loss: 4289174619.4914 - val_mean_absolute_error: 48402.8223\n",
      "Epoch 2055/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 5369558101.4063 - mean_absolute_error: 57734.6631 - val_loss: 5436135575.3127 - val_mean_absolute_error: 54273.2718\n",
      "Epoch 2056/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 5314044640.6843 - mean_absolute_error: 57752.5363 - val_loss: 4928760767.7801 - val_mean_absolute_error: 50941.3720\n",
      "Epoch 2057/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 5172888962.2994 - mean_absolute_error: 55544.4088 - val_loss: 5051473257.5670 - val_mean_absolute_error: 51251.3080\n",
      "Epoch 2058/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 5182375424.2190 - mean_absolute_error: 57053.3708 - val_loss: 5326968564.5636 - val_mean_absolute_error: 54652.6220\n",
      "Epoch 2059/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 5295902715.1822 - mean_absolute_error: 57019.5215 - val_loss: 5879963062.1031 - val_mean_absolute_error: 57344.7799\n",
      "Epoch 2060/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 5136631328.8486 - mean_absolute_error: 56790.6270 - val_loss: 4959294237.0309 - val_mean_absolute_error: 53476.5539\n",
      "Epoch 2061/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 5370191699.8734 - mean_absolute_error: 58043.5059 - val_loss: 4457786965.3333 - val_mean_absolute_error: 47827.9432\n",
      "Epoch 2062/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 5192771260.7699 - mean_absolute_error: 56074.8097 - val_loss: 4702678948.5086 - val_mean_absolute_error: 50594.1082\n",
      "Epoch 2063/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 5138494462.6861 - mean_absolute_error: 55850.7594 - val_loss: 5149498998.7629 - val_mean_absolute_error: 51860.1216\n",
      "Epoch 2064/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 5248688539.2643 - mean_absolute_error: 56742.2157 - val_loss: 5391100999.2577 - val_mean_absolute_error: 53877.6174\n",
      "Epoch 2065/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 340us/step - loss: 5056797258.0188 - mean_absolute_error: 56742.0869 - val_loss: 5834048299.1065 - val_mean_absolute_error: 57722.5923\n",
      "Epoch 2066/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 5206103480.8281 - mean_absolute_error: 56756.6167 - val_loss: 5838752848.9347 - val_mean_absolute_error: 58010.0772\n",
      "Epoch 2067/5000\n",
      "1169/1169 [==============================] - 0s 392us/step - loss: 5024252212.3388 - mean_absolute_error: 56847.2043 - val_loss: 5511749751.6426 - val_mean_absolute_error: 55339.3614\n",
      "Epoch 2068/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 4954059242.5389 - mean_absolute_error: 56869.0966 - val_loss: 5790860349.5808 - val_mean_absolute_error: 55860.4443\n",
      "Epoch 2069/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 5144043443.7913 - mean_absolute_error: 56338.1052 - val_loss: 5367912862.3505 - val_mean_absolute_error: 54154.3417\n",
      "Epoch 2070/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 4862909298.0941 - mean_absolute_error: 56100.0955 - val_loss: 4558948095.1203 - val_mean_absolute_error: 50135.2277\n",
      "Epoch 2071/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 5205410239.1788 - mean_absolute_error: 56301.0535 - val_loss: 4533345986.4192 - val_mean_absolute_error: 49823.3346\n",
      "Epoch 2072/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 5086825766.3234 - mean_absolute_error: 56722.2634 - val_loss: 4476810613.8832 - val_mean_absolute_error: 49866.0042\n",
      "Epoch 2073/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 4877622853.4200 - mean_absolute_error: 55269.0366 - val_loss: 5179559592.0275 - val_mean_absolute_error: 54947.6776\n",
      "Epoch 2074/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 4732192620.8383 - mean_absolute_error: 55468.5000 - val_loss: 4505348498.9141 - val_mean_absolute_error: 48412.4225\n",
      "Epoch 2075/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4731771161.6219 - mean_absolute_error: 55371.9791 - val_loss: 3691744804.0687 - val_mean_absolute_error: 43246.7267\n",
      "Epoch 2076/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 4757207679.0145 - mean_absolute_error: 55042.9694 - val_loss: 4472519050.1168 - val_mean_absolute_error: 48478.3438\n",
      "Epoch 2077/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 4885298108.5509 - mean_absolute_error: 55004.3127 - val_loss: 4591333962.7766 - val_mean_absolute_error: 50648.9736\n",
      "Epoch 2078/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4606701257.2524 - mean_absolute_error: 53783.0668 - val_loss: 4415689576.6873 - val_mean_absolute_error: 51009.2677\n",
      "Epoch 2079/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 4950582667.9350 - mean_absolute_error: 56118.6859 - val_loss: 5421441818.3918 - val_mean_absolute_error: 57240.7758\n",
      "Epoch 2080/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4997581502.0838 - mean_absolute_error: 55144.1501 - val_loss: 4166355760.3849 - val_mean_absolute_error: 46613.4611\n",
      "Epoch 2081/5000\n",
      "1169/1169 [==============================] - 0s 300us/step - loss: 4724416372.9410 - mean_absolute_error: 55060.8340 - val_loss: 4970753912.5223 - val_mean_absolute_error: 51774.8271\n",
      "Epoch 2082/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 4905058032.4517 - mean_absolute_error: 55128.9604 - val_loss: 5657146777.0722 - val_mean_absolute_error: 56611.9260\n",
      "Epoch 2083/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 5010749888.4927 - mean_absolute_error: 55985.1638 - val_loss: 5547121076.3436 - val_mean_absolute_error: 57151.9880\n",
      "Epoch 2084/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 4950162692.5988 - mean_absolute_error: 55352.2476 - val_loss: 5900636004.2887 - val_mean_absolute_error: 58283.7925\n",
      "Epoch 2085/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 5243424890.6347 - mean_absolute_error: 56640.3000 - val_loss: 4360317746.1443 - val_mean_absolute_error: 49344.0205\n",
      "Epoch 2086/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4936848795.7023 - mean_absolute_error: 56460.3581 - val_loss: 4495351596.8660 - val_mean_absolute_error: 48222.0999\n",
      "Epoch 2087/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4823922614.4192 - mean_absolute_error: 53530.4130 - val_loss: 4335681424.2749 - val_mean_absolute_error: 48031.1756\n",
      "Epoch 2088/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4827975309.4679 - mean_absolute_error: 54738.6981 - val_loss: 4816303191.9725 - val_mean_absolute_error: 50370.0999\n",
      "Epoch 2089/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 5060382729.6356 - mean_absolute_error: 55718.9189 - val_loss: 5451516238.2955 - val_mean_absolute_error: 52881.7704\n",
      "Epoch 2090/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 4836639487.1240 - mean_absolute_error: 53246.0783 - val_loss: 4746352202.7766 - val_mean_absolute_error: 49614.1191\n",
      "Epoch 2091/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4809241331.9555 - mean_absolute_error: 54498.8075 - val_loss: 4517644044.3162 - val_mean_absolute_error: 48307.7897\n",
      "Epoch 2092/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4498093385.7998 - mean_absolute_error: 53303.9873 - val_loss: 4210349924.2887 - val_mean_absolute_error: 46537.3268\n",
      "Epoch 2093/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 5090977377.2318 - mean_absolute_error: 55291.4821 - val_loss: 4969513313.6495 - val_mean_absolute_error: 52445.9648\n",
      "Epoch 2094/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4724803854.2344 - mean_absolute_error: 52933.5020 - val_loss: 4233032012.5361 - val_mean_absolute_error: 45664.4875\n",
      "Epoch 2095/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 4592794212.7357 - mean_absolute_error: 52619.9300 - val_loss: 4623275536.7148 - val_mean_absolute_error: 49161.3758\n",
      "Epoch 2096/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 4770856697.6493 - mean_absolute_error: 53883.7333 - val_loss: 4751203735.3127 - val_mean_absolute_error: 51047.3954\n",
      "Epoch 2097/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 4768381905.5740 - mean_absolute_error: 54638.0166 - val_loss: 4872150988.9759 - val_mean_absolute_error: 51172.5581\n",
      "Epoch 2098/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 5052203100.8520 - mean_absolute_error: 55011.8897 - val_loss: 4206886162.4742 - val_mean_absolute_error: 47244.6507\n",
      "Epoch 2099/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4757703341.0026 - mean_absolute_error: 54904.9529 - val_loss: 5115972020.3436 - val_mean_absolute_error: 53545.5662\n",
      "Epoch 2100/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 5129385040.1506 - mean_absolute_error: 55935.0598 - val_loss: 5142233558.6529 - val_mean_absolute_error: 53293.0640\n",
      "Epoch 2101/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 4640532514.6005 - mean_absolute_error: 53808.7173 - val_loss: 4394121458.8041 - val_mean_absolute_error: 47254.4999\n",
      "Epoch 2102/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4630069406.9872 - mean_absolute_error: 53130.6126 - val_loss: 4559734310.7079 - val_mean_absolute_error: 48611.3642\n",
      "Epoch 2103/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 4756256544.6296 - mean_absolute_error: 54372.0440 - val_loss: 4774960194.8591 - val_mean_absolute_error: 50094.9040\n",
      "Epoch 2104/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4942494320.1232 - mean_absolute_error: 53994.8755 - val_loss: 4405584149.9931 - val_mean_absolute_error: 47393.6274\n",
      "Epoch 2105/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4860893153.3413 - mean_absolute_error: 53480.8847 - val_loss: 4819407835.9313 - val_mean_absolute_error: 48583.3692\n",
      "Epoch 2106/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4498451825.6561 - mean_absolute_error: 52849.4373 - val_loss: 4403301138.4742 - val_mean_absolute_error: 46243.3413\n",
      "Epoch 2107/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4671872241.9846 - mean_absolute_error: 54070.8000 - val_loss: 4510007667.2440 - val_mean_absolute_error: 48207.0615\n",
      "Epoch 2108/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 4557879956.4756 - mean_absolute_error: 53090.6658 - val_loss: 3885375147.5464 - val_mean_absolute_error: 43525.0002\n",
      "Epoch 2109/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4862525383.0624 - mean_absolute_error: 54599.4522 - val_loss: 4562063339.7663 - val_mean_absolute_error: 46371.8488\n",
      "Epoch 2110/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4821275522.2994 - mean_absolute_error: 53147.9282 - val_loss: 5639296738.9691 - val_mean_absolute_error: 54068.7225\n",
      "Epoch 2111/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 4616661717.2968 - mean_absolute_error: 53530.7055 - val_loss: 4695494196.7835 - val_mean_absolute_error: 47856.4825\n",
      "Epoch 2112/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4527964757.6253 - mean_absolute_error: 51654.7015 - val_loss: 3990293081.7320 - val_mean_absolute_error: 43860.7266\n",
      "Epoch 2113/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 4851479877.2010 - mean_absolute_error: 55176.3790 - val_loss: 3989283749.3883 - val_mean_absolute_error: 43192.1203\n",
      "Epoch 2114/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 4392252282.4157 - mean_absolute_error: 52619.9611 - val_loss: 4413865610.1168 - val_mean_absolute_error: 47366.9607\n",
      "Epoch 2115/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4436077445.4748 - mean_absolute_error: 52858.9410 - val_loss: 4100157006.2955 - val_mean_absolute_error: 45645.3594\n",
      "Epoch 2116/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4789522539.5244 - mean_absolute_error: 53722.4504 - val_loss: 4490752848.9347 - val_mean_absolute_error: 47305.5515\n",
      "Epoch 2117/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 4330047327.4799 - mean_absolute_error: 52094.2612 - val_loss: 4176517298.5842 - val_mean_absolute_error: 46279.9836\n",
      "Epoch 2118/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 4519294031.2746 - mean_absolute_error: 52935.1845 - val_loss: 4366863294.0206 - val_mean_absolute_error: 47483.4205\n",
      "Epoch 2119/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 4765833334.6929 - mean_absolute_error: 51728.5243 - val_loss: 4133137409.7595 - val_mean_absolute_error: 44847.1363\n",
      "Epoch 2120/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 4592588516.6262 - mean_absolute_error: 52544.6091 - val_loss: 3929181253.4983 - val_mean_absolute_error: 45752.9722\n",
      "Epoch 2121/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 4558944955.8939 - mean_absolute_error: 52353.3528 - val_loss: 3848171327.3402 - val_mean_absolute_error: 42635.0300\n",
      "Epoch 2122/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 5055133527.3772 - mean_absolute_error: 55063.8975 - val_loss: 4745289515.9863 - val_mean_absolute_error: 49316.1701\n",
      "Epoch 2123/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 4803888043.4696 - mean_absolute_error: 54375.3537 - val_loss: 4350387152.4948 - val_mean_absolute_error: 48169.4976\n",
      "Epoch 2124/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 4876421723.1001 - mean_absolute_error: 54777.0828 - val_loss: 3753881038.7354 - val_mean_absolute_error: 45069.6240\n",
      "Epoch 2125/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 4473314708.0376 - mean_absolute_error: 51954.7609 - val_loss: 4080938061.4158 - val_mean_absolute_error: 45209.3304\n",
      "Epoch 2126/5000\n",
      "1169/1169 [==============================] - 0s 306us/step - loss: 4523789522.8879 - mean_absolute_error: 51712.7132 - val_loss: 4582184320.4399 - val_mean_absolute_error: 50003.8309\n",
      "Epoch 2127/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 4678873360.8623 - mean_absolute_error: 53645.2087 - val_loss: 4328390597.0584 - val_mean_absolute_error: 48528.4504\n",
      "Epoch 2128/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 4733367942.0222 - mean_absolute_error: 53786.2046 - val_loss: 5041102885.8282 - val_mean_absolute_error: 51944.7271\n",
      "Epoch 2129/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4528383168.2737 - mean_absolute_error: 53082.6365 - val_loss: 4701680848.4948 - val_mean_absolute_error: 48716.4182\n",
      "Epoch 2130/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 4637918228.5851 - mean_absolute_error: 52907.1776 - val_loss: 5072596832.7698 - val_mean_absolute_error: 49288.7384\n",
      "Epoch 2131/5000\n",
      "1169/1169 [==============================] - 0s 309us/step - loss: 4777487383.8700 - mean_absolute_error: 54424.0965 - val_loss: 5016754644.8935 - val_mean_absolute_error: 50221.2465\n",
      "Epoch 2132/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 4786700457.2797 - mean_absolute_error: 53126.2884 - val_loss: 4837245720.6323 - val_mean_absolute_error: 49669.6121\n",
      "Epoch 2133/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 4257396059.3191 - mean_absolute_error: 51765.2688 - val_loss: 4512210481.2646 - val_mean_absolute_error: 47665.9888\n",
      "Epoch 2134/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4466069946.3610 - mean_absolute_error: 52098.5924 - val_loss: 3864545645.0859 - val_mean_absolute_error: 43050.5723\n",
      "Epoch 2135/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 4418533241.5398 - mean_absolute_error: 52069.7446 - val_loss: 4237040792.1924 - val_mean_absolute_error: 45846.2869\n",
      "Epoch 2136/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 4643746619.3464 - mean_absolute_error: 52799.1516 - val_loss: 5188515742.3505 - val_mean_absolute_error: 51799.5558\n",
      "Epoch 2137/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 4673028316.5235 - mean_absolute_error: 53226.7392 - val_loss: 4450412572.1512 - val_mean_absolute_error: 47482.1103\n",
      "Epoch 2138/5000\n",
      "1169/1169 [==============================] - 0s 393us/step - loss: 4833496562.8606 - mean_absolute_error: 53300.2446 - val_loss: 4655731244.8660 - val_mean_absolute_error: 49217.6336\n",
      "Epoch 2139/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 4371057632.9033 - mean_absolute_error: 51290.9483 - val_loss: 4391388754.6942 - val_mean_absolute_error: 48679.6858\n",
      "Epoch 2140/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4065590877.7280 - mean_absolute_error: 49961.0183 - val_loss: 4341693529.7320 - val_mean_absolute_error: 48004.8286\n",
      "Epoch 2141/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 4411625509.2284 - mean_absolute_error: 52048.9836 - val_loss: 4058277605.6082 - val_mean_absolute_error: 44816.3149\n",
      "Epoch 2142/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 4710214112.9033 - mean_absolute_error: 52759.0241 - val_loss: 5137831314.0344 - val_mean_absolute_error: 51858.6879\n",
      "Epoch 2143/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4697456151.2130 - mean_absolute_error: 52835.6257 - val_loss: 4557493213.6907 - val_mean_absolute_error: 47664.2327\n",
      "Epoch 2144/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 4536240104.3490 - mean_absolute_error: 52334.8707 - val_loss: 4288557364.7835 - val_mean_absolute_error: 45363.6198\n",
      "Epoch 2145/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 4256890801.1634 - mean_absolute_error: 50527.1205 - val_loss: 3824271233.3196 - val_mean_absolute_error: 42648.4427\n",
      "Epoch 2146/5000\n",
      "1169/1169 [==============================] - 0s 316us/step - loss: 4310940107.8802 - mean_absolute_error: 51275.5426 - val_loss: 4556974794.3368 - val_mean_absolute_error: 46495.7309\n",
      "Epoch 2147/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 350us/step - loss: 4417227385.7588 - mean_absolute_error: 51476.5856 - val_loss: 3617163614.1306 - val_mean_absolute_error: 41442.4427\n",
      "Epoch 2148/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4687751325.6732 - mean_absolute_error: 51794.4900 - val_loss: 4252006994.6942 - val_mean_absolute_error: 45634.6827\n",
      "Epoch 2149/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4508163756.1266 - mean_absolute_error: 51559.7323 - val_loss: 4404894207.1203 - val_mean_absolute_error: 46337.2338\n",
      "Epoch 2150/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4786679316.3661 - mean_absolute_error: 52745.6192 - val_loss: 4818317074.4742 - val_mean_absolute_error: 50571.1949\n",
      "Epoch 2151/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4336526383.3020 - mean_absolute_error: 52825.4391 - val_loss: 3939591808.4399 - val_mean_absolute_error: 45566.0046\n",
      "Epoch 2152/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4558633563.5381 - mean_absolute_error: 53022.9199 - val_loss: 4206730513.5945 - val_mean_absolute_error: 46581.8790\n",
      "Epoch 2153/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 4562505672.1574 - mean_absolute_error: 52262.1377 - val_loss: 4302518338.8591 - val_mean_absolute_error: 45832.5677\n",
      "Epoch 2154/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 4461503233.9709 - mean_absolute_error: 50759.9623 - val_loss: 4044134460.7010 - val_mean_absolute_error: 44830.9424\n",
      "Epoch 2155/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4258858890.1831 - mean_absolute_error: 50457.3408 - val_loss: 4168277183.7801 - val_mean_absolute_error: 46748.8742\n",
      "Epoch 2156/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 4068899543.4867 - mean_absolute_error: 50629.6076 - val_loss: 4217569371.4914 - val_mean_absolute_error: 46603.5703\n",
      "Epoch 2157/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 4350812846.7545 - mean_absolute_error: 51579.8282 - val_loss: 5586863952.0550 - val_mean_absolute_error: 52682.6922\n",
      "Epoch 2158/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 4548133212.4140 - mean_absolute_error: 51209.3156 - val_loss: 3911605595.4914 - val_mean_absolute_error: 42726.0792\n",
      "Epoch 2159/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4592890487.1309 - mean_absolute_error: 52772.5663 - val_loss: 4072940649.5670 - val_mean_absolute_error: 44287.9235\n",
      "Epoch 2160/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 4563644180.8041 - mean_absolute_error: 52663.5133 - val_loss: 4098315843.7388 - val_mean_absolute_error: 44906.0903\n",
      "Epoch 2161/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 4462841368.3080 - mean_absolute_error: 50643.7903 - val_loss: 4287602394.1718 - val_mean_absolute_error: 46047.3815\n",
      "Epoch 2162/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 4666193921.0950 - mean_absolute_error: 52372.4512 - val_loss: 4214093729.8694 - val_mean_absolute_error: 45290.5292\n",
      "Epoch 2163/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4312624852.2019 - mean_absolute_error: 51170.4987 - val_loss: 3731085846.8729 - val_mean_absolute_error: 40991.7963\n",
      "Epoch 2164/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4382220589.3311 - mean_absolute_error: 51634.6482 - val_loss: 4140208078.7354 - val_mean_absolute_error: 44896.8950\n",
      "Epoch 2165/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4643558067.1343 - mean_absolute_error: 52513.5977 - val_loss: 4376557305.8419 - val_mean_absolute_error: 46778.1690\n",
      "Epoch 2166/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 4692773507.8323 - mean_absolute_error: 52454.2680 - val_loss: 4470197526.8729 - val_mean_absolute_error: 47317.5942\n",
      "Epoch 2167/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 4834001175.8700 - mean_absolute_error: 51991.1290 - val_loss: 4770243761.7045 - val_mean_absolute_error: 48464.8027\n",
      "Epoch 2168/5000\n",
      "1169/1169 [==============================] - ETA: 0s - loss: 4115373446.7368 - mean_absolute_error: 49754.70 - 0s 310us/step - loss: 4089215869.7006 - mean_absolute_error: 49627.7298 - val_loss: 4396256200.5773 - val_mean_absolute_error: 45774.0691\n",
      "Epoch 2169/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 4868435947.8529 - mean_absolute_error: 52337.5995 - val_loss: 4470291881.7869 - val_mean_absolute_error: 47641.9408\n",
      "Epoch 2170/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 4476649158.1865 - mean_absolute_error: 51365.0094 - val_loss: 4574914298.7216 - val_mean_absolute_error: 48536.2021\n",
      "Epoch 2171/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 4475073917.9196 - mean_absolute_error: 52610.5350 - val_loss: 4497498614.3230 - val_mean_absolute_error: 46245.2879\n",
      "Epoch 2172/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 4673871488.4380 - mean_absolute_error: 52973.5898 - val_loss: 3397391044.1787 - val_mean_absolute_error: 40146.0349\n",
      "Epoch 2173/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 4549482238.4671 - mean_absolute_error: 52533.6539 - val_loss: 4074152142.7354 - val_mean_absolute_error: 44093.5652\n",
      "Epoch 2174/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 4233761942.9940 - mean_absolute_error: 51680.1752 - val_loss: 3740721872.4948 - val_mean_absolute_error: 42525.4167\n",
      "Epoch 2175/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 4242187012.3798 - mean_absolute_error: 50465.6693 - val_loss: 4076815190.2131 - val_mean_absolute_error: 43967.4703\n",
      "Epoch 2176/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4317165249.8067 - mean_absolute_error: 50039.7397 - val_loss: 4054975177.4570 - val_mean_absolute_error: 44789.4689\n",
      "Epoch 2177/5000\n",
      "1169/1169 [==============================] - 0s 303us/step - loss: 4118739777.4782 - mean_absolute_error: 50118.9509 - val_loss: 3890094789.9381 - val_mean_absolute_error: 44581.0203\n",
      "Epoch 2178/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4296550085.2010 - mean_absolute_error: 50554.9737 - val_loss: 4222989119.3402 - val_mean_absolute_error: 46507.2114\n",
      "Epoch 2179/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4092878735.8768 - mean_absolute_error: 49841.3059 - val_loss: 3764880243.2440 - val_mean_absolute_error: 42853.6547\n",
      "Epoch 2180/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 4238430463.7810 - mean_absolute_error: 49740.8481 - val_loss: 3122005525.9931 - val_mean_absolute_error: 38807.8020\n",
      "Epoch 2181/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4211291739.1001 - mean_absolute_error: 49875.1014 - val_loss: 3758571772.4811 - val_mean_absolute_error: 40855.3939\n",
      "Epoch 2182/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4507643206.2960 - mean_absolute_error: 51466.8998 - val_loss: 2972725638.5979 - val_mean_absolute_error: 34347.0442\n",
      "Epoch 2183/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 4460541449.8546 - mean_absolute_error: 51571.5164 - val_loss: 3085591723.5464 - val_mean_absolute_error: 36138.3270\n",
      "Epoch 2184/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 4128359131.4286 - mean_absolute_error: 50197.6045 - val_loss: 3218234762.1168 - val_mean_absolute_error: 37734.9251\n",
      "Epoch 2185/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 4368728967.5552 - mean_absolute_error: 50792.0032 - val_loss: 4280361728.0000 - val_mean_absolute_error: 46443.0949\n",
      "Epoch 2186/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 4618168154.8811 - mean_absolute_error: 50949.4643 - val_loss: 3493617325.3058 - val_mean_absolute_error: 40133.4425\n",
      "Epoch 2187/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4328952559.5757 - mean_absolute_error: 51008.0242 - val_loss: 3555159568.7148 - val_mean_absolute_error: 39377.8931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2188/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 4456856629.4337 - mean_absolute_error: 50975.3535 - val_loss: 2926273559.7526 - val_mean_absolute_error: 35409.6004\n",
      "Epoch 2189/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 4056786179.2849 - mean_absolute_error: 49283.0244 - val_loss: 3583690827.6564 - val_mean_absolute_error: 41087.4835\n",
      "Epoch 2190/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4322011771.5107 - mean_absolute_error: 50101.8824 - val_loss: 4171448510.9003 - val_mean_absolute_error: 44074.3094\n",
      "Epoch 2191/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4206143828.3114 - mean_absolute_error: 49994.5751 - val_loss: 4116861208.6323 - val_mean_absolute_error: 44325.5841\n",
      "Epoch 2192/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 4090264035.5312 - mean_absolute_error: 49068.9669 - val_loss: 4048093030.0481 - val_mean_absolute_error: 44753.8382\n",
      "Epoch 2193/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3942328989.6732 - mean_absolute_error: 48623.8194 - val_loss: 3346413171.2440 - val_mean_absolute_error: 40093.3165\n",
      "Epoch 2194/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 4326350794.5663 - mean_absolute_error: 51433.1909 - val_loss: 4258121687.5326 - val_mean_absolute_error: 44233.8599\n",
      "Epoch 2195/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 4424527997.7006 - mean_absolute_error: 50545.7413 - val_loss: 3832617345.3196 - val_mean_absolute_error: 41169.3482\n",
      "Epoch 2196/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 4193739241.4440 - mean_absolute_error: 49786.7629 - val_loss: 4100201552.0550 - val_mean_absolute_error: 42882.0903\n",
      "Epoch 2197/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 4598956375.8152 - mean_absolute_error: 51633.5154 - val_loss: 3795528869.3883 - val_mean_absolute_error: 41910.3720\n",
      "Epoch 2198/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 4219365061.5295 - mean_absolute_error: 50587.5947 - val_loss: 3480858124.3162 - val_mean_absolute_error: 39468.6236\n",
      "Epoch 2199/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 4179686736.1506 - mean_absolute_error: 49829.8536 - val_loss: 4463550059.3265 - val_mean_absolute_error: 45114.4713\n",
      "Epoch 2200/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 4677851705.3755 - mean_absolute_error: 51592.8970 - val_loss: 3945011131.3814 - val_mean_absolute_error: 42116.2152\n",
      "Epoch 2201/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 4163539824.6707 - mean_absolute_error: 49262.5601 - val_loss: 3669333129.2371 - val_mean_absolute_error: 39512.1282\n",
      "Epoch 2202/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 4320049951.0967 - mean_absolute_error: 50816.3133 - val_loss: 3839093686.1031 - val_mean_absolute_error: 41131.1297\n",
      "Epoch 2203/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 4363855713.8888 - mean_absolute_error: 49902.4512 - val_loss: 3807463548.0412 - val_mean_absolute_error: 39621.1967\n",
      "Epoch 2204/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4056375152.3422 - mean_absolute_error: 48639.0620 - val_loss: 3370314705.3746 - val_mean_absolute_error: 38150.6115\n",
      "Epoch 2205/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3976618604.1814 - mean_absolute_error: 48186.0140 - val_loss: 3141736667.9313 - val_mean_absolute_error: 37585.3877\n",
      "Epoch 2206/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4174938723.8597 - mean_absolute_error: 49691.6390 - val_loss: 4082867929.2921 - val_mean_absolute_error: 43739.4654\n",
      "Epoch 2207/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 4450785874.7784 - mean_absolute_error: 51623.0591 - val_loss: 3983879798.7629 - val_mean_absolute_error: 43775.9256\n",
      "Epoch 2208/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 4212637643.4423 - mean_absolute_error: 50025.0236 - val_loss: 4472801272.0825 - val_mean_absolute_error: 47054.3541\n",
      "Epoch 2209/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4444888575.1240 - mean_absolute_error: 51934.2641 - val_loss: 4189563418.3918 - val_mean_absolute_error: 44777.1073\n",
      "Epoch 2210/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4142693210.2241 - mean_absolute_error: 48169.8665 - val_loss: 3727195727.1753 - val_mean_absolute_error: 41448.6536\n",
      "Epoch 2211/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 4020595978.2926 - mean_absolute_error: 47241.1104 - val_loss: 3847771617.2096 - val_mean_absolute_error: 42279.7525\n",
      "Epoch 2212/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3948695131.9760 - mean_absolute_error: 48347.4662 - val_loss: 4294609945.5120 - val_mean_absolute_error: 44429.8949\n",
      "Epoch 2213/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 4425885432.3353 - mean_absolute_error: 50936.2182 - val_loss: 4350250693.9381 - val_mean_absolute_error: 44963.7637\n",
      "Epoch 2214/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4249614175.6989 - mean_absolute_error: 49746.4363 - val_loss: 3905839280.8247 - val_mean_absolute_error: 42297.7450\n",
      "Epoch 2215/5000\n",
      "1169/1169 [==============================] - 0s 310us/step - loss: 4129285769.9641 - mean_absolute_error: 48651.7737 - val_loss: 3594868366.5155 - val_mean_absolute_error: 41672.3355\n",
      "Epoch 2216/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3939983605.7074 - mean_absolute_error: 49077.5881 - val_loss: 4336083871.2302 - val_mean_absolute_error: 46154.5813\n",
      "Epoch 2217/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 4216469020.2498 - mean_absolute_error: 49465.3974 - val_loss: 4157103308.9759 - val_mean_absolute_error: 44587.7390\n",
      "Epoch 2218/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 4232663557.4748 - mean_absolute_error: 49048.8624 - val_loss: 4214105515.5464 - val_mean_absolute_error: 45051.7063\n",
      "Epoch 2219/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3874454827.7981 - mean_absolute_error: 47539.6373 - val_loss: 4176160327.2577 - val_mean_absolute_error: 44588.4437\n",
      "Epoch 2220/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 3879304391.9384 - mean_absolute_error: 48531.8011 - val_loss: 4350491808.1100 - val_mean_absolute_error: 45802.0924\n",
      "Epoch 2221/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 4423079331.5860 - mean_absolute_error: 49100.4720 - val_loss: 3576894371.6289 - val_mean_absolute_error: 40983.2041\n",
      "Epoch 2222/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4158037899.0590 - mean_absolute_error: 49808.3016 - val_loss: 4324440141.4158 - val_mean_absolute_error: 44282.6811\n",
      "Epoch 2223/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 4242638188.4003 - mean_absolute_error: 48666.3790 - val_loss: 6383099018.1168 - val_mean_absolute_error: 56459.0794\n",
      "Epoch 2224/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 4580666529.1771 - mean_absolute_error: 51559.3287 - val_loss: 3385192665.2921 - val_mean_absolute_error: 38096.3707\n",
      "Epoch 2225/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3928130083.4765 - mean_absolute_error: 48496.1598 - val_loss: 3443916975.9450 - val_mean_absolute_error: 39175.9120\n",
      "Epoch 2226/5000\n",
      "1169/1169 [==============================] - 0s 315us/step - loss: 4015000124.0034 - mean_absolute_error: 48752.4468 - val_loss: 3329049351.9175 - val_mean_absolute_error: 36768.7063\n",
      "Epoch 2227/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 4054575323.4286 - mean_absolute_error: 48687.3697 - val_loss: 3741822298.6117 - val_mean_absolute_error: 38519.0121\n",
      "Epoch 2228/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 4586428480.2737 - mean_absolute_error: 50776.6208 - val_loss: 3413117762.8591 - val_mean_absolute_error: 38257.9143\n",
      "Epoch 2229/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4117987912.2669 - mean_absolute_error: 49433.2484 - val_loss: 3767055131.2715 - val_mean_absolute_error: 40258.4586\n",
      "Epoch 2230/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 4204170177.5877 - mean_absolute_error: 48984.5099 - val_loss: 3538613262.9553 - val_mean_absolute_error: 39682.5111\n",
      "Epoch 2231/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 4127805848.8554 - mean_absolute_error: 49453.3595 - val_loss: 3285634052.3986 - val_mean_absolute_error: 38020.6964\n",
      "Epoch 2232/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3901825662.5766 - mean_absolute_error: 47750.4562 - val_loss: 4362882845.0309 - val_mean_absolute_error: 43219.6402\n",
      "Epoch 2233/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4124980185.0197 - mean_absolute_error: 48078.5076 - val_loss: 4260177118.5704 - val_mean_absolute_error: 41690.8309\n",
      "Epoch 2234/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 4099716721.6561 - mean_absolute_error: 48944.2317 - val_loss: 3825350228.4536 - val_mean_absolute_error: 40394.1217\n",
      "Epoch 2235/5000\n",
      "1169/1169 [==============================] - 0s 311us/step - loss: 3898409504.8486 - mean_absolute_error: 48132.3671 - val_loss: 3431178823.2577 - val_mean_absolute_error: 36992.3786\n",
      "Epoch 2236/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3999442089.0607 - mean_absolute_error: 48188.7154 - val_loss: 3755285285.8282 - val_mean_absolute_error: 40039.5363\n",
      "Epoch 2237/5000\n",
      "1169/1169 [==============================] - 0s 316us/step - loss: 3829236415.8358 - mean_absolute_error: 47607.0281 - val_loss: 3256473831.3677 - val_mean_absolute_error: 35995.4068\n",
      "Epoch 2238/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 4169129221.9127 - mean_absolute_error: 49418.5787 - val_loss: 3943325385.4570 - val_mean_absolute_error: 40558.5667\n",
      "Epoch 2239/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4165418476.7288 - mean_absolute_error: 49236.0130 - val_loss: 3679634048.4399 - val_mean_absolute_error: 39715.7957\n",
      "Epoch 2240/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4033664019.9281 - mean_absolute_error: 47738.2721 - val_loss: 3873330169.8419 - val_mean_absolute_error: 40552.8281\n",
      "Epoch 2241/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3956789853.5090 - mean_absolute_error: 47952.2428 - val_loss: 3582711863.4227 - val_mean_absolute_error: 37963.1833\n",
      "Epoch 2242/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4213814204.7699 - mean_absolute_error: 49234.4161 - val_loss: 2777196061.0309 - val_mean_absolute_error: 32850.2718\n",
      "Epoch 2243/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4277250035.9555 - mean_absolute_error: 49898.1247 - val_loss: 3373576172.6460 - val_mean_absolute_error: 38113.1832\n",
      "Epoch 2244/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 4042424027.4286 - mean_absolute_error: 48620.1144 - val_loss: 3573428659.4639 - val_mean_absolute_error: 39326.6506\n",
      "Epoch 2245/5000\n",
      "1169/1169 [==============================] - 0s 302us/step - loss: 3944942448.7802 - mean_absolute_error: 48535.1940 - val_loss: 3567373910.2131 - val_mean_absolute_error: 39701.2204\n",
      "Epoch 2246/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3968156929.5329 - mean_absolute_error: 48195.3154 - val_loss: 3012300163.0790 - val_mean_absolute_error: 35747.1755\n",
      "Epoch 2247/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 4098790248.8965 - mean_absolute_error: 48399.2424 - val_loss: 3281275988.4536 - val_mean_absolute_error: 36921.8372\n",
      "Epoch 2248/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3923936866.1078 - mean_absolute_error: 46795.1057 - val_loss: 3191786741.4433 - val_mean_absolute_error: 36075.1000\n",
      "Epoch 2249/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3767437426.9701 - mean_absolute_error: 47261.3836 - val_loss: 3381184402.9141 - val_mean_absolute_error: 36851.2033\n",
      "Epoch 2250/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3686330915.2575 - mean_absolute_error: 46192.5907 - val_loss: 3803834529.8694 - val_mean_absolute_error: 38504.4865\n",
      "Epoch 2251/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3843623795.8460 - mean_absolute_error: 47136.1770 - val_loss: 3717270405.7182 - val_mean_absolute_error: 40180.0314\n",
      "Epoch 2252/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3794834860.7836 - mean_absolute_error: 47809.4109 - val_loss: 3537327665.2646 - val_mean_absolute_error: 38115.1391\n",
      "Epoch 2253/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3759147421.8922 - mean_absolute_error: 46659.1677 - val_loss: 3556827907.5189 - val_mean_absolute_error: 37064.6076\n",
      "Epoch 2254/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 4158756231.5552 - mean_absolute_error: 49630.0789 - val_loss: 3319388282.2818 - val_mean_absolute_error: 35740.7349\n",
      "Epoch 2255/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4012804082.8606 - mean_absolute_error: 48839.9304 - val_loss: 3857861886.2405 - val_mean_absolute_error: 40999.2941\n",
      "Epoch 2256/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3826612527.0830 - mean_absolute_error: 47168.7932 - val_loss: 4013415997.5808 - val_mean_absolute_error: 41547.2814\n",
      "Epoch 2257/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4305770333.2900 - mean_absolute_error: 48960.8513 - val_loss: 4011517966.9553 - val_mean_absolute_error: 40708.0277\n",
      "Epoch 2258/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4073621472.0274 - mean_absolute_error: 47403.7958 - val_loss: 3504271702.2131 - val_mean_absolute_error: 39052.6035\n",
      "Epoch 2259/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4065794053.0368 - mean_absolute_error: 48340.6167 - val_loss: 4537698852.9485 - val_mean_absolute_error: 44540.9372\n",
      "Epoch 2260/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3623871492.5988 - mean_absolute_error: 46058.7337 - val_loss: 3441583238.5979 - val_mean_absolute_error: 37184.0161\n",
      "Epoch 2261/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3534718419.5449 - mean_absolute_error: 46389.9027 - val_loss: 3075718426.3918 - val_mean_absolute_error: 35533.6620\n",
      "Epoch 2262/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3752884342.2549 - mean_absolute_error: 46740.9288 - val_loss: 3660215447.3127 - val_mean_absolute_error: 41066.7924\n",
      "Epoch 2263/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 4083442020.9547 - mean_absolute_error: 48860.6768 - val_loss: 3941504893.8007 - val_mean_absolute_error: 42790.6131\n",
      "Epoch 2264/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 4142906375.4457 - mean_absolute_error: 48402.6238 - val_loss: 4073180989.5808 - val_mean_absolute_error: 42594.9912\n",
      "Epoch 2265/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4388065443.5860 - mean_absolute_error: 48050.0054 - val_loss: 3216783183.1753 - val_mean_absolute_error: 35268.1929\n",
      "Epoch 2266/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3998801820.1403 - mean_absolute_error: 47686.4075 - val_loss: 3460660935.6976 - val_mean_absolute_error: 38829.6994\n",
      "Epoch 2267/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4229837553.3276 - mean_absolute_error: 49040.8580 - val_loss: 4805021099.5464 - val_mean_absolute_error: 44899.9465\n",
      "Epoch 2268/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 4034024769.9162 - mean_absolute_error: 48096.8887 - val_loss: 3352511836.3711 - val_mean_absolute_error: 34708.4461\n",
      "Epoch 2269/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3933475938.1078 - mean_absolute_error: 46865.8185 - val_loss: 2764291516.2612 - val_mean_absolute_error: 33371.0601\n",
      "Epoch 2270/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 345us/step - loss: 3759546303.6168 - mean_absolute_error: 47390.3857 - val_loss: 3117049336.0825 - val_mean_absolute_error: 35379.5942\n",
      "Epoch 2271/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 3812268279.0214 - mean_absolute_error: 46735.8073 - val_loss: 3630085303.8625 - val_mean_absolute_error: 38913.1851\n",
      "Epoch 2272/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3730573001.6903 - mean_absolute_error: 46232.7873 - val_loss: 2980013083.2715 - val_mean_absolute_error: 34732.7866\n",
      "Epoch 2273/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3722843696.5064 - mean_absolute_error: 45452.0277 - val_loss: 3264936959.1203 - val_mean_absolute_error: 34840.4415\n",
      "Epoch 2274/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3710959751.5552 - mean_absolute_error: 46949.7897 - val_loss: 4346230077.5808 - val_mean_absolute_error: 42814.8216\n",
      "Epoch 2275/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 4039899699.6818 - mean_absolute_error: 48281.8393 - val_loss: 3224247552.0000 - val_mean_absolute_error: 35900.2710\n",
      "Epoch 2276/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3712225161.9641 - mean_absolute_error: 47195.2014 - val_loss: 3718652812.7560 - val_mean_absolute_error: 39276.9496\n",
      "Epoch 2277/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3977568540.2498 - mean_absolute_error: 47510.6480 - val_loss: 3432388264.9072 - val_mean_absolute_error: 38923.7884\n",
      "Epoch 2278/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3953599309.4132 - mean_absolute_error: 47823.6254 - val_loss: 3814311159.2027 - val_mean_absolute_error: 40880.7867\n",
      "Epoch 2279/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4275354276.6809 - mean_absolute_error: 48559.7540 - val_loss: 2722702562.5292 - val_mean_absolute_error: 33196.9741\n",
      "Epoch 2280/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 4145097482.0736 - mean_absolute_error: 48315.8055 - val_loss: 3907296166.2680 - val_mean_absolute_error: 39444.3520\n",
      "Epoch 2281/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3759806612.9136 - mean_absolute_error: 46486.8666 - val_loss: 3661635715.9588 - val_mean_absolute_error: 38422.1813\n",
      "Epoch 2282/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4068091044.6809 - mean_absolute_error: 47266.4436 - val_loss: 2959646412.0962 - val_mean_absolute_error: 33349.0392\n",
      "Epoch 2283/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3742902549.2421 - mean_absolute_error: 46435.0436 - val_loss: 2884951778.5292 - val_mean_absolute_error: 32760.4183\n",
      "Epoch 2284/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 4124742957.5500 - mean_absolute_error: 48047.4200 - val_loss: 2870783153.2646 - val_mean_absolute_error: 32055.8285\n",
      "Epoch 2285/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3661640172.0719 - mean_absolute_error: 47295.8239 - val_loss: 3278816640.4399 - val_mean_absolute_error: 35070.9479\n",
      "Epoch 2286/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3898826831.2746 - mean_absolute_error: 47645.7058 - val_loss: 3351189173.2234 - val_mean_absolute_error: 35556.4241\n",
      "Epoch 2287/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3898847184.9170 - mean_absolute_error: 46518.4033 - val_loss: 3546900584.6873 - val_mean_absolute_error: 37970.1269\n",
      "Epoch 2288/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3329854415.3841 - mean_absolute_error: 44038.1063 - val_loss: 3412505843.6838 - val_mean_absolute_error: 37556.1560\n",
      "Epoch 2289/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3664439979.2506 - mean_absolute_error: 46714.7761 - val_loss: 3317850490.2818 - val_mean_absolute_error: 36591.2733\n",
      "Epoch 2290/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3731143363.9966 - mean_absolute_error: 46602.1761 - val_loss: 2896174097.5945 - val_mean_absolute_error: 33573.9128\n",
      "Epoch 2291/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3954946487.4046 - mean_absolute_error: 48310.4344 - val_loss: 2829366906.2818 - val_mean_absolute_error: 32420.1575\n",
      "Epoch 2292/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 4123279976.4585 - mean_absolute_error: 46723.2705 - val_loss: 3016121648.3849 - val_mean_absolute_error: 34480.5887\n",
      "Epoch 2293/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3617457010.5321 - mean_absolute_error: 45816.4115 - val_loss: 3563069769.8969 - val_mean_absolute_error: 38739.3178\n",
      "Epoch 2294/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 4389591623.3909 - mean_absolute_error: 48139.6806 - val_loss: 3773530484.1237 - val_mean_absolute_error: 40647.0905\n",
      "Epoch 2295/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3870356958.0565 - mean_absolute_error: 47169.0515 - val_loss: 3677726708.5636 - val_mean_absolute_error: 39487.8142\n",
      "Epoch 2296/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4119759335.6920 - mean_absolute_error: 48239.4287 - val_loss: 3693109612.2062 - val_mean_absolute_error: 36871.4987\n",
      "Epoch 2297/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 4001175071.9726 - mean_absolute_error: 48463.0277 - val_loss: 3215698936.0825 - val_mean_absolute_error: 34894.2594\n",
      "Epoch 2298/5000\n",
      "1169/1169 [==============================] - ETA: 0s - loss: 4073694265.7255 - mean_absolute_error: 47586.90 - 0s 354us/step - loss: 3887389116.9889 - mean_absolute_error: 46591.7770 - val_loss: 3005848094.7904 - val_mean_absolute_error: 33452.1618\n",
      "Epoch 2299/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 4261442166.6929 - mean_absolute_error: 48667.8043 - val_loss: 3171404668.9210 - val_mean_absolute_error: 34540.0582\n",
      "Epoch 2300/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3626130447.3293 - mean_absolute_error: 45644.8718 - val_loss: 2699246840.5223 - val_mean_absolute_error: 29677.9499\n",
      "Epoch 2301/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3959680248.3353 - mean_absolute_error: 47520.8105 - val_loss: 3587157268.2337 - val_mean_absolute_error: 37407.8378\n",
      "Epoch 2302/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3820551969.5056 - mean_absolute_error: 46626.8456 - val_loss: 3144330033.2646 - val_mean_absolute_error: 34587.4866\n",
      "Epoch 2303/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3995579533.0299 - mean_absolute_error: 47095.6899 - val_loss: 3927037659.0515 - val_mean_absolute_error: 39129.0405\n",
      "Epoch 2304/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3882945169.4098 - mean_absolute_error: 46564.5260 - val_loss: 2923581334.4330 - val_mean_absolute_error: 34220.2219\n",
      "Epoch 2305/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3840887532.9478 - mean_absolute_error: 46434.0281 - val_loss: 2764197906.4742 - val_mean_absolute_error: 31454.0796\n",
      "Epoch 2306/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3835248199.0624 - mean_absolute_error: 46934.5359 - val_loss: 3039744120.5223 - val_mean_absolute_error: 34473.8679\n",
      "Epoch 2307/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3847240572.3867 - mean_absolute_error: 46725.1503 - val_loss: 2595670482.2543 - val_mean_absolute_error: 30396.1075\n",
      "Epoch 2308/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 4108572191.9726 - mean_absolute_error: 47395.2594 - val_loss: 2724125428.5636 - val_mean_absolute_error: 31362.7622\n",
      "Epoch 2309/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3711672900.8725 - mean_absolute_error: 47029.6168 - val_loss: 2851595903.5601 - val_mean_absolute_error: 32160.0347\n",
      "Epoch 2310/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4155797641.5261 - mean_absolute_error: 47930.6422 - val_loss: 3424324926.4605 - val_mean_absolute_error: 36168.6290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2311/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3480166566.2139 - mean_absolute_error: 44998.9397 - val_loss: 3050707597.6357 - val_mean_absolute_error: 33547.2914\n",
      "Epoch 2312/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3949151275.7981 - mean_absolute_error: 45755.1581 - val_loss: 3031391605.8832 - val_mean_absolute_error: 33545.3141\n",
      "Epoch 2313/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3818399005.1257 - mean_absolute_error: 46745.6154 - val_loss: 2783674857.1271 - val_mean_absolute_error: 32053.7645\n",
      "Epoch 2314/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3792837193.3618 - mean_absolute_error: 46885.9902 - val_loss: 2937479430.1581 - val_mean_absolute_error: 33430.7612\n",
      "Epoch 2315/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 4125912705.6424 - mean_absolute_error: 48509.2296 - val_loss: 2877068059.2715 - val_mean_absolute_error: 32353.3789\n",
      "Epoch 2316/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3711732020.3388 - mean_absolute_error: 45925.3868 - val_loss: 2934521402.5017 - val_mean_absolute_error: 33212.1079\n",
      "Epoch 2317/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 4225013163.9076 - mean_absolute_error: 48884.5295 - val_loss: 2938926581.4433 - val_mean_absolute_error: 33827.6363\n",
      "Epoch 2318/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3926688621.2763 - mean_absolute_error: 46310.0045 - val_loss: 3549498784.9897 - val_mean_absolute_error: 38452.4139\n",
      "Epoch 2319/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3882915085.3584 - mean_absolute_error: 47622.9010 - val_loss: 3044415494.1581 - val_mean_absolute_error: 34835.6439\n",
      "Epoch 2320/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3748514027.8529 - mean_absolute_error: 46340.0424 - val_loss: 2955979367.8076 - val_mean_absolute_error: 34041.9615\n",
      "Epoch 2321/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3574779111.2541 - mean_absolute_error: 45513.4554 - val_loss: 2843202618.0619 - val_mean_absolute_error: 33392.2676\n",
      "Epoch 2322/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 3939151089.3276 - mean_absolute_error: 47593.0576 - val_loss: 3212198825.7869 - val_mean_absolute_error: 37406.5539\n",
      "Epoch 2323/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 4293019507.8460 - mean_absolute_error: 49003.0322 - val_loss: 2811900474.0619 - val_mean_absolute_error: 32413.7782\n",
      "Epoch 2324/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3883039984.0137 - mean_absolute_error: 47522.9019 - val_loss: 2992477967.8351 - val_mean_absolute_error: 33997.1992\n",
      "Epoch 2325/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3961121856.3832 - mean_absolute_error: 47182.5857 - val_loss: 3424027082.3368 - val_mean_absolute_error: 36264.3695\n",
      "Epoch 2326/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3570205733.6664 - mean_absolute_error: 45201.4442 - val_loss: 2955435661.6357 - val_mean_absolute_error: 33792.8380\n",
      "Epoch 2327/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3978268823.5415 - mean_absolute_error: 48002.5583 - val_loss: 2707323556.5086 - val_mean_absolute_error: 31625.4600\n",
      "Epoch 2328/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3575540382.9872 - mean_absolute_error: 45638.4791 - val_loss: 3046711049.6770 - val_mean_absolute_error: 34153.3505\n",
      "Epoch 2329/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 3954334239.7536 - mean_absolute_error: 47622.8202 - val_loss: 2978708393.7869 - val_mean_absolute_error: 34178.7477\n",
      "Epoch 2330/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 4141738210.4363 - mean_absolute_error: 48004.8787 - val_loss: 2962849394.3643 - val_mean_absolute_error: 32511.3213\n",
      "Epoch 2331/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3815148257.5603 - mean_absolute_error: 47451.3246 - val_loss: 3462316633.7320 - val_mean_absolute_error: 35618.3326\n",
      "Epoch 2332/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3769264595.7639 - mean_absolute_error: 46616.4552 - val_loss: 2629937150.2406 - val_mean_absolute_error: 30962.0757\n",
      "Epoch 2333/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3551792996.9547 - mean_absolute_error: 46035.0205 - val_loss: 2952700468.7835 - val_mean_absolute_error: 32534.6275\n",
      "Epoch 2334/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 4038701184.5475 - mean_absolute_error: 46719.3941 - val_loss: 2841528571.6014 - val_mean_absolute_error: 32389.8700\n",
      "Epoch 2335/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3662147213.2489 - mean_absolute_error: 45788.1655 - val_loss: 2815965816.0825 - val_mean_absolute_error: 31901.7933\n",
      "Epoch 2336/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3800141427.6270 - mean_absolute_error: 47796.0500 - val_loss: 2863399236.6186 - val_mean_absolute_error: 32159.2474\n",
      "Epoch 2337/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3907618821.9127 - mean_absolute_error: 46231.6937 - val_loss: 3414936507.3814 - val_mean_absolute_error: 34767.8499\n",
      "Epoch 2338/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3822049101.3037 - mean_absolute_error: 46201.1528 - val_loss: 3340095235.5189 - val_mean_absolute_error: 35559.4558\n",
      "Epoch 2339/5000\n",
      "1169/1169 [==============================] - 0s 301us/step - loss: 3877546005.0231 - mean_absolute_error: 48154.2106 - val_loss: 3528238384.3849 - val_mean_absolute_error: 38041.8200\n",
      "Epoch 2340/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3650912675.5860 - mean_absolute_error: 45794.1275 - val_loss: 3299380242.4742 - val_mean_absolute_error: 37006.0989\n",
      "Epoch 2341/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 4079815368.5954 - mean_absolute_error: 47129.6461 - val_loss: 2987994486.7629 - val_mean_absolute_error: 33520.8414\n",
      "Epoch 2342/5000\n",
      "1169/1169 [==============================] - 0s 316us/step - loss: 3591275878.7066 - mean_absolute_error: 45323.0412 - val_loss: 2953743709.2509 - val_mean_absolute_error: 33279.1401\n",
      "Epoch 2343/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3753435150.4534 - mean_absolute_error: 45103.1241 - val_loss: 2991429317.0584 - val_mean_absolute_error: 34620.5179\n",
      "Epoch 2344/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3881638930.8332 - mean_absolute_error: 46424.2476 - val_loss: 2767060056.8522 - val_mean_absolute_error: 32618.8105\n",
      "Epoch 2345/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 4178985663.3978 - mean_absolute_error: 48300.3048 - val_loss: 3379657629.4708 - val_mean_absolute_error: 36767.6175\n",
      "Epoch 2346/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3609028689.0265 - mean_absolute_error: 45639.7029 - val_loss: 3000092891.0515 - val_mean_absolute_error: 33105.3978\n",
      "Epoch 2347/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3826342993.4645 - mean_absolute_error: 47838.2910 - val_loss: 3100340613.7182 - val_mean_absolute_error: 34916.5908\n",
      "Epoch 2348/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3912543164.9889 - mean_absolute_error: 45490.3809 - val_loss: 2662548711.3677 - val_mean_absolute_error: 30642.6452\n",
      "Epoch 2349/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 4080294830.0975 - mean_absolute_error: 48284.7818 - val_loss: 3382214382.4055 - val_mean_absolute_error: 35480.1951\n",
      "Epoch 2350/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3682938110.0291 - mean_absolute_error: 46147.0129 - val_loss: 3550087795.2440 - val_mean_absolute_error: 36313.1605\n",
      "Epoch 2351/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4086580488.5406 - mean_absolute_error: 47284.9517 - val_loss: 3111528166.4880 - val_mean_absolute_error: 33761.3756\n",
      "Epoch 2352/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3546917130.2926 - mean_absolute_error: 45944.2238 - val_loss: 3445497819.0515 - val_mean_absolute_error: 37036.2420\n",
      "Epoch 2353/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3561157275.0453 - mean_absolute_error: 44030.5303 - val_loss: 3702302420.0137 - val_mean_absolute_error: 38849.0665\n",
      "Epoch 2354/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3738216631.2951 - mean_absolute_error: 46870.3339 - val_loss: 2675938103.4227 - val_mean_absolute_error: 32091.7897\n",
      "Epoch 2355/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3980960931.8050 - mean_absolute_error: 48195.7933 - val_loss: 3552655721.5670 - val_mean_absolute_error: 36853.9622\n",
      "Epoch 2356/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3705533030.2686 - mean_absolute_error: 45677.4236 - val_loss: 2832746203.4914 - val_mean_absolute_error: 31171.2197\n",
      "Epoch 2357/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3857689020.1129 - mean_absolute_error: 46165.6136 - val_loss: 2849431214.1856 - val_mean_absolute_error: 31640.8178\n",
      "Epoch 2358/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 3563703639.1583 - mean_absolute_error: 45234.9291 - val_loss: 2567389236.7835 - val_mean_absolute_error: 30332.0964\n",
      "Epoch 2359/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 4109720699.2917 - mean_absolute_error: 47751.3696 - val_loss: 2196313479.4777 - val_mean_absolute_error: 27052.3018\n",
      "Epoch 2360/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3930626130.3405 - mean_absolute_error: 47043.8278 - val_loss: 2428662413.1959 - val_mean_absolute_error: 29457.2171\n",
      "Epoch 2361/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 4156061775.0556 - mean_absolute_error: 48848.4610 - val_loss: 2757701513.2371 - val_mean_absolute_error: 31808.7739\n",
      "Epoch 2362/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 3723632176.8349 - mean_absolute_error: 46391.0582 - val_loss: 3406222050.0893 - val_mean_absolute_error: 37156.7340\n",
      "Epoch 2363/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3633360191.2883 - mean_absolute_error: 45336.2709 - val_loss: 2890948569.2921 - val_mean_absolute_error: 33746.0139\n",
      "Epoch 2364/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 4090657188.2429 - mean_absolute_error: 47981.9021 - val_loss: 3842443560.4674 - val_mean_absolute_error: 39887.7714\n",
      "Epoch 2365/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3682702127.0830 - mean_absolute_error: 45441.9133 - val_loss: 2699436609.0997 - val_mean_absolute_error: 31482.4764\n",
      "Epoch 2366/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 3538924424.8691 - mean_absolute_error: 45895.8415 - val_loss: 3235088128.0000 - val_mean_absolute_error: 34743.5035\n",
      "Epoch 2367/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3720735543.4046 - mean_absolute_error: 46710.2484 - val_loss: 3304664246.1031 - val_mean_absolute_error: 35846.1307\n",
      "Epoch 2368/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 3881675038.3302 - mean_absolute_error: 45889.0065 - val_loss: 3403331940.2887 - val_mean_absolute_error: 35186.8372\n",
      "Epoch 2369/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3668520153.0197 - mean_absolute_error: 46336.6602 - val_loss: 3403487412.3436 - val_mean_absolute_error: 35026.4496\n",
      "Epoch 2370/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 3430143906.2720 - mean_absolute_error: 44347.4501 - val_loss: 2847118973.8007 - val_mean_absolute_error: 31743.3152\n",
      "Epoch 2371/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3775568182.5287 - mean_absolute_error: 47082.9039 - val_loss: 3164479539.0241 - val_mean_absolute_error: 34458.3497\n",
      "Epoch 2372/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3788432772.2703 - mean_absolute_error: 45885.1712 - val_loss: 2678412222.0206 - val_mean_absolute_error: 30208.3431\n",
      "Epoch 2373/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3813332652.1266 - mean_absolute_error: 45940.5180 - val_loss: 3034841642.2268 - val_mean_absolute_error: 33125.2380\n",
      "Epoch 2374/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3586333041.8751 - mean_absolute_error: 45053.9599 - val_loss: 2858562533.6082 - val_mean_absolute_error: 31497.4894\n",
      "Epoch 2375/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3739862212.9820 - mean_absolute_error: 45939.6816 - val_loss: 2910075589.9381 - val_mean_absolute_error: 33020.1739\n",
      "Epoch 2376/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3919726201.5398 - mean_absolute_error: 47487.2616 - val_loss: 2994412220.2612 - val_mean_absolute_error: 33119.1236\n",
      "Epoch 2377/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3593086876.7973 - mean_absolute_error: 45230.2473 - val_loss: 2987809304.6323 - val_mean_absolute_error: 33203.4819\n",
      "Epoch 2378/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3631150062.0428 - mean_absolute_error: 46408.9130 - val_loss: 2682529380.7285 - val_mean_absolute_error: 30136.7734\n",
      "Epoch 2379/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3551343221.3790 - mean_absolute_error: 45162.0903 - val_loss: 2675883403.4364 - val_mean_absolute_error: 31084.7114\n",
      "Epoch 2380/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3571904361.5535 - mean_absolute_error: 45146.9259 - val_loss: 3176470211.2990 - val_mean_absolute_error: 34747.0533\n",
      "Epoch 2381/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 4087273968.2327 - mean_absolute_error: 47762.7604 - val_loss: 2326016117.8832 - val_mean_absolute_error: 28001.1102\n",
      "Epoch 2382/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3578839283.1891 - mean_absolute_error: 46017.8527 - val_loss: 3420238478.5155 - val_mean_absolute_error: 36758.2580\n",
      "Epoch 2383/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 3792438111.2609 - mean_absolute_error: 46040.0608 - val_loss: 3775522394.6117 - val_mean_absolute_error: 37263.0171\n",
      "Epoch 2384/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3618794828.4277 - mean_absolute_error: 45703.7214 - val_loss: 2594183027.2440 - val_mean_absolute_error: 29334.3251\n",
      "Epoch 2385/5000\n",
      "1169/1169 [==============================] - 0s 316us/step - loss: 3601129809.0265 - mean_absolute_error: 45702.4533 - val_loss: 2694905663.7801 - val_mean_absolute_error: 30696.6721\n",
      "Epoch 2386/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3742527646.7682 - mean_absolute_error: 45682.8823 - val_loss: 2975260035.9588 - val_mean_absolute_error: 33467.3669\n",
      "Epoch 2387/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3821395116.6741 - mean_absolute_error: 45284.1928 - val_loss: 3143564942.5155 - val_mean_absolute_error: 34643.3215\n",
      "Epoch 2388/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3712458578.5595 - mean_absolute_error: 45058.2551 - val_loss: 3093156944.9347 - val_mean_absolute_error: 33369.8010\n",
      "Epoch 2389/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3668628371.3807 - mean_absolute_error: 46278.4750 - val_loss: 2466968169.5670 - val_mean_absolute_error: 28591.9600\n",
      "Epoch 2390/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3567887757.4679 - mean_absolute_error: 44095.1325 - val_loss: 3018692319.4502 - val_mean_absolute_error: 33353.8300\n",
      "Epoch 2391/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3612443558.2139 - mean_absolute_error: 47062.1220 - val_loss: 3154730166.1031 - val_mean_absolute_error: 33418.3538\n",
      "Epoch 2392/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3747833772.3456 - mean_absolute_error: 46173.7717 - val_loss: 2839663537.7045 - val_mean_absolute_error: 32824.1788\n",
      "Epoch 2393/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 336us/step - loss: 3583398700.0171 - mean_absolute_error: 45402.9611 - val_loss: 3062641463.4227 - val_mean_absolute_error: 34284.8522\n",
      "Epoch 2394/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3556933418.4842 - mean_absolute_error: 44233.4395 - val_loss: 3323742939.0515 - val_mean_absolute_error: 36200.3549\n",
      "Epoch 2395/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3780296642.4636 - mean_absolute_error: 45631.0554 - val_loss: 3140217531.3814 - val_mean_absolute_error: 35641.8834\n",
      "Epoch 2396/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3656116446.0565 - mean_absolute_error: 46053.6508 - val_loss: 3107954208.5498 - val_mean_absolute_error: 34579.9147\n",
      "Epoch 2397/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3377321655.6236 - mean_absolute_error: 44251.3712 - val_loss: 3036976529.1546 - val_mean_absolute_error: 32883.0533\n",
      "Epoch 2398/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3712757537.9435 - mean_absolute_error: 45086.9979 - val_loss: 3642797077.1134 - val_mean_absolute_error: 36550.9307\n",
      "Epoch 2399/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3629845182.7408 - mean_absolute_error: 44300.1916 - val_loss: 3144231080.9072 - val_mean_absolute_error: 34062.8973\n",
      "Epoch 2400/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3652643740.5783 - mean_absolute_error: 46135.6493 - val_loss: 2998103552.8797 - val_mean_absolute_error: 33720.4208\n",
      "Epoch 2401/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3535488605.9470 - mean_absolute_error: 45090.2217 - val_loss: 2671504912.7148 - val_mean_absolute_error: 30707.4949\n",
      "Epoch 2402/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3831136039.4183 - mean_absolute_error: 46476.8826 - val_loss: 2614961922.6392 - val_mean_absolute_error: 30366.7197\n",
      "Epoch 2403/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3606570741.9264 - mean_absolute_error: 44986.3388 - val_loss: 2645205984.3299 - val_mean_absolute_error: 31387.1742\n",
      "Epoch 2404/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 4043921958.9803 - mean_absolute_error: 47934.9285 - val_loss: 2499464488.4674 - val_mean_absolute_error: 28536.1570\n",
      "Epoch 2405/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3819868041.7451 - mean_absolute_error: 46869.5686 - val_loss: 2827965049.4021 - val_mean_absolute_error: 31361.9912\n",
      "Epoch 2406/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3919326568.6775 - mean_absolute_error: 46773.5457 - val_loss: 2962476260.7285 - val_mean_absolute_error: 33204.8258\n",
      "Epoch 2407/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3772823932.6056 - mean_absolute_error: 46264.8593 - val_loss: 2977856556.8660 - val_mean_absolute_error: 33046.0653\n",
      "Epoch 2408/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3830580947.1069 - mean_absolute_error: 45558.1634 - val_loss: 4260768888.5223 - val_mean_absolute_error: 39730.7438\n",
      "Epoch 2409/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3674232457.0881 - mean_absolute_error: 44952.5493 - val_loss: 2849407601.9244 - val_mean_absolute_error: 31730.6134\n",
      "Epoch 2410/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3583707714.5731 - mean_absolute_error: 45943.4381 - val_loss: 2843990834.5842 - val_mean_absolute_error: 31958.0265\n",
      "Epoch 2411/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3485447715.0385 - mean_absolute_error: 45515.1678 - val_loss: 2950303478.3230 - val_mean_absolute_error: 32704.1431\n",
      "Epoch 2412/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3547325472.8486 - mean_absolute_error: 45076.3144 - val_loss: 3307398560.9897 - val_mean_absolute_error: 34265.4021\n",
      "Epoch 2413/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3836973818.0873 - mean_absolute_error: 46000.5771 - val_loss: 2949326030.2955 - val_mean_absolute_error: 31984.7499\n",
      "Epoch 2414/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3535953491.4354 - mean_absolute_error: 45509.9585 - val_loss: 3071567101.3608 - val_mean_absolute_error: 33434.4694\n",
      "Epoch 2415/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 4286969192.2395 - mean_absolute_error: 48110.7187 - val_loss: 3094324421.9381 - val_mean_absolute_error: 33854.6111\n",
      "Epoch 2416/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3986669945.5398 - mean_absolute_error: 46605.4994 - val_loss: 2921330216.0275 - val_mean_absolute_error: 30686.4224\n",
      "Epoch 2417/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3912884656.7254 - mean_absolute_error: 47006.5771 - val_loss: 2745763408.0550 - val_mean_absolute_error: 31164.4098\n",
      "Epoch 2418/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3600835351.8700 - mean_absolute_error: 45778.0311 - val_loss: 3051785362.0344 - val_mean_absolute_error: 33431.8243\n",
      "Epoch 2419/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 4027815325.2352 - mean_absolute_error: 47471.7173 - val_loss: 3302102299.7113 - val_mean_absolute_error: 34812.1252\n",
      "Epoch 2420/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3807943184.2053 - mean_absolute_error: 46770.4467 - val_loss: 3052086284.3162 - val_mean_absolute_error: 32951.9455\n",
      "Epoch 2421/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3896856210.9427 - mean_absolute_error: 46561.9242 - val_loss: 2439954672.6048 - val_mean_absolute_error: 29479.8062\n",
      "Epoch 2422/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3966338149.6116 - mean_absolute_error: 47348.5770 - val_loss: 3164910245.3883 - val_mean_absolute_error: 33373.9006\n",
      "Epoch 2423/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 4195453793.0128 - mean_absolute_error: 48089.9632 - val_loss: 2644475249.9244 - val_mean_absolute_error: 30231.9366\n",
      "Epoch 2424/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3602861880.0616 - mean_absolute_error: 45038.4157 - val_loss: 2575133137.8144 - val_mean_absolute_error: 29461.6694\n",
      "Epoch 2425/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3884204537.7588 - mean_absolute_error: 46515.4650 - val_loss: 2842398320.1649 - val_mean_absolute_error: 31192.3821\n",
      "Epoch 2426/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3534735402.4842 - mean_absolute_error: 46023.7120 - val_loss: 3164223512.6323 - val_mean_absolute_error: 33316.1063\n",
      "Epoch 2427/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3957059455.8905 - mean_absolute_error: 47568.2218 - val_loss: 3123184741.1684 - val_mean_absolute_error: 33709.1939\n",
      "Epoch 2428/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3855208690.6416 - mean_absolute_error: 46415.6337 - val_loss: 2653509541.8282 - val_mean_absolute_error: 31192.3637\n",
      "Epoch 2429/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3869248225.7793 - mean_absolute_error: 45756.5681 - val_loss: 2860579697.0447 - val_mean_absolute_error: 33310.0759\n",
      "Epoch 2430/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3913112881.4919 - mean_absolute_error: 47330.3999 - val_loss: 2830481304.1924 - val_mean_absolute_error: 31463.4049\n",
      "Epoch 2431/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3503804354.9016 - mean_absolute_error: 44402.7763 - val_loss: 2478949392.7148 - val_mean_absolute_error: 29506.5289\n",
      "Epoch 2432/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3650076883.9829 - mean_absolute_error: 45349.5309 - val_loss: 2544515558.9278 - val_mean_absolute_error: 30619.8437\n",
      "Epoch 2433/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3460414342.8982 - mean_absolute_error: 44994.2289 - val_loss: 2458290637.8557 - val_mean_absolute_error: 31069.1102\n",
      "Epoch 2434/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3946249385.4987 - mean_absolute_error: 47560.4440 - val_loss: 3121123655.2577 - val_mean_absolute_error: 35289.2372\n",
      "Epoch 2435/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3421020432.2053 - mean_absolute_error: 44721.7217 - val_loss: 3589479928.9622 - val_mean_absolute_error: 37795.4401\n",
      "Epoch 2436/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3711098799.6305 - mean_absolute_error: 45651.0169 - val_loss: 2670500260.9485 - val_mean_absolute_error: 31750.7893\n",
      "Epoch 2437/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3617845730.4363 - mean_absolute_error: 43996.0080 - val_loss: 2881419271.9175 - val_mean_absolute_error: 32372.4905\n",
      "Epoch 2438/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 4027070245.6664 - mean_absolute_error: 47734.8548 - val_loss: 2794114300.4811 - val_mean_absolute_error: 31645.3221\n",
      "Epoch 2439/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3594100379.2643 - mean_absolute_error: 46150.5646 - val_loss: 2662885025.4296 - val_mean_absolute_error: 30944.0255\n",
      "Epoch 2440/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3619837910.3918 - mean_absolute_error: 46148.2866 - val_loss: 2601810056.3574 - val_mean_absolute_error: 30550.1518\n",
      "Epoch 2441/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 3760737419.7160 - mean_absolute_error: 46468.1860 - val_loss: 2745962115.9588 - val_mean_absolute_error: 30770.3899\n",
      "Epoch 2442/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3452010757.2558 - mean_absolute_error: 44329.3822 - val_loss: 2677866625.3196 - val_mean_absolute_error: 30607.6284\n",
      "Epoch 2443/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3584662558.6587 - mean_absolute_error: 44477.2846 - val_loss: 2663397294.6254 - val_mean_absolute_error: 31221.8438\n",
      "Epoch 2444/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3770100880.0958 - mean_absolute_error: 45720.9722 - val_loss: 3114611427.8488 - val_mean_absolute_error: 34573.4263\n",
      "Epoch 2445/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 4081537100.6467 - mean_absolute_error: 46816.6942 - val_loss: 2829377637.1684 - val_mean_absolute_error: 32106.8051\n",
      "Epoch 2446/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3744551065.7314 - mean_absolute_error: 46914.7740 - val_loss: 2900490083.4089 - val_mean_absolute_error: 32521.4109\n",
      "Epoch 2447/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 4117680573.7553 - mean_absolute_error: 47462.2648 - val_loss: 2446860672.0000 - val_mean_absolute_error: 29447.3592\n",
      "Epoch 2448/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3513922889.3618 - mean_absolute_error: 44390.8829 - val_loss: 2904455233.9794 - val_mean_absolute_error: 32958.2321\n",
      "Epoch 2449/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3678754239.1788 - mean_absolute_error: 46260.7381 - val_loss: 2211009799.0378 - val_mean_absolute_error: 28003.0536\n",
      "Epoch 2450/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3871444903.3088 - mean_absolute_error: 45512.6343 - val_loss: 3397397030.7079 - val_mean_absolute_error: 36011.4926\n",
      "Epoch 2451/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 4102424120.0616 - mean_absolute_error: 47063.0849 - val_loss: 2493079155.2440 - val_mean_absolute_error: 29460.1525\n",
      "Epoch 2452/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 3809454755.8050 - mean_absolute_error: 47207.0386 - val_loss: 3164305810.9141 - val_mean_absolute_error: 34317.9662\n",
      "Epoch 2453/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3741351001.3482 - mean_absolute_error: 46041.7960 - val_loss: 2617826979.6289 - val_mean_absolute_error: 30926.7928\n",
      "Epoch 2454/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3434148060.5235 - mean_absolute_error: 45411.3944 - val_loss: 3089881577.1271 - val_mean_absolute_error: 33435.7635\n",
      "Epoch 2455/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3304457659.4559 - mean_absolute_error: 42803.8766 - val_loss: 2620154126.0756 - val_mean_absolute_error: 29813.0101\n",
      "Epoch 2456/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3898057199.7947 - mean_absolute_error: 46067.0950 - val_loss: 2915650618.9416 - val_mean_absolute_error: 31597.6504\n",
      "Epoch 2457/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 3552348122.1146 - mean_absolute_error: 44151.2043 - val_loss: 2749913352.7973 - val_mean_absolute_error: 30810.5891\n",
      "Epoch 2458/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3382715291.0453 - mean_absolute_error: 44876.5050 - val_loss: 2837871546.0619 - val_mean_absolute_error: 30736.9511\n",
      "Epoch 2459/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3929317744.7802 - mean_absolute_error: 46283.4256 - val_loss: 2752250141.4708 - val_mean_absolute_error: 30862.5786\n",
      "Epoch 2460/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3676798179.3122 - mean_absolute_error: 45401.2249 - val_loss: 2634743822.5155 - val_mean_absolute_error: 30555.3151\n",
      "Epoch 2461/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3741781772.0445 - mean_absolute_error: 46621.7580 - val_loss: 2530276717.9656 - val_mean_absolute_error: 29193.1557\n",
      "Epoch 2462/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3469650342.2139 - mean_absolute_error: 43656.8229 - val_loss: 2593096470.4330 - val_mean_absolute_error: 29826.2682\n",
      "Epoch 2463/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3708346388.1471 - mean_absolute_error: 46354.9187 - val_loss: 3639733036.8660 - val_mean_absolute_error: 35849.8506\n",
      "Epoch 2464/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3676413852.5783 - mean_absolute_error: 45356.4918 - val_loss: 2419766012.0412 - val_mean_absolute_error: 28305.8762\n",
      "Epoch 2465/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3880557796.6262 - mean_absolute_error: 46431.7988 - val_loss: 2545699369.7869 - val_mean_absolute_error: 29800.5468\n",
      "Epoch 2466/5000\n",
      "1169/1169 [==============================] - 0s 303us/step - loss: 3725774286.5081 - mean_absolute_error: 47021.2063 - val_loss: 2940245764.3986 - val_mean_absolute_error: 32404.5640\n",
      "Epoch 2467/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3584222353.4098 - mean_absolute_error: 45383.5453 - val_loss: 2823778578.9141 - val_mean_absolute_error: 30996.6275\n",
      "Epoch 2468/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3271371372.6193 - mean_absolute_error: 43935.0197 - val_loss: 3166306538.0069 - val_mean_absolute_error: 33030.0049\n",
      "Epoch 2469/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3543760423.4183 - mean_absolute_error: 45109.2592 - val_loss: 2547827513.6220 - val_mean_absolute_error: 29580.2449\n",
      "Epoch 2470/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3654929912.1163 - mean_absolute_error: 46295.8157 - val_loss: 3176657416.7973 - val_mean_absolute_error: 34771.3042\n",
      "Epoch 2471/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3743150489.9504 - mean_absolute_error: 46205.8254 - val_loss: 3251478599.2577 - val_mean_absolute_error: 35023.7093\n",
      "Epoch 2472/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 3519494576.7254 - mean_absolute_error: 44592.4780 - val_loss: 3462788478.6804 - val_mean_absolute_error: 36637.3413\n",
      "Epoch 2473/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 4060534302.2207 - mean_absolute_error: 47694.6005 - val_loss: 3007179486.1306 - val_mean_absolute_error: 31719.4665\n",
      "Epoch 2474/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 3760963304.5680 - mean_absolute_error: 46259.7589 - val_loss: 2804597619.6838 - val_mean_absolute_error: 31084.8102\n",
      "Epoch 2475/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 349us/step - loss: 3692757504.8760 - mean_absolute_error: 46473.4154 - val_loss: 2500194794.8866 - val_mean_absolute_error: 29448.3666\n",
      "Epoch 2476/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3566800839.5004 - mean_absolute_error: 45624.1560 - val_loss: 2835123103.2302 - val_mean_absolute_error: 31816.4158\n",
      "Epoch 2477/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3400648614.6518 - mean_absolute_error: 44514.7791 - val_loss: 3255246759.1478 - val_mean_absolute_error: 34898.1200\n",
      "Epoch 2478/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3768732463.5210 - mean_absolute_error: 46043.1868 - val_loss: 2749890756.6186 - val_mean_absolute_error: 31725.2522\n",
      "Epoch 2479/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3741325375.0693 - mean_absolute_error: 45370.6016 - val_loss: 1978357088.7698 - val_mean_absolute_error: 26175.9305\n",
      "Epoch 2480/5000\n",
      "1169/1169 [==============================] - 0s 317us/step - loss: 3861641650.6963 - mean_absolute_error: 47039.5749 - val_loss: 2922645064.1375 - val_mean_absolute_error: 32342.5841\n",
      "Epoch 2481/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3801477447.6099 - mean_absolute_error: 45150.2588 - val_loss: 2190915865.0722 - val_mean_absolute_error: 28268.6052\n",
      "Epoch 2482/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3355460756.6946 - mean_absolute_error: 43920.8541 - val_loss: 2649259550.7904 - val_mean_absolute_error: 31265.0183\n",
      "Epoch 2483/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 4061276625.1360 - mean_absolute_error: 47087.1004 - val_loss: 2717467765.8832 - val_mean_absolute_error: 31651.7622\n",
      "Epoch 2484/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3528718732.3730 - mean_absolute_error: 44435.7816 - val_loss: 2920252729.1821 - val_mean_absolute_error: 32769.9161\n",
      "Epoch 2485/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3457079857.0539 - mean_absolute_error: 43896.4924 - val_loss: 2939371754.0069 - val_mean_absolute_error: 32537.7920\n",
      "Epoch 2486/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3197280055.8426 - mean_absolute_error: 42919.5054 - val_loss: 2682422908.0412 - val_mean_absolute_error: 31188.1875\n",
      "Epoch 2487/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3766639978.8674 - mean_absolute_error: 46178.8805 - val_loss: 3161101598.7904 - val_mean_absolute_error: 33631.0548\n",
      "Epoch 2488/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3969551523.3670 - mean_absolute_error: 47398.1614 - val_loss: 2642417029.7182 - val_mean_absolute_error: 30412.5531\n",
      "Epoch 2489/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3604224075.7707 - mean_absolute_error: 44645.3058 - val_loss: 2654906622.2406 - val_mean_absolute_error: 30886.7105\n",
      "Epoch 2490/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3693391173.2010 - mean_absolute_error: 46202.3327 - val_loss: 2646593915.1615 - val_mean_absolute_error: 31210.6971\n",
      "Epoch 2491/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3471831607.1856 - mean_absolute_error: 44755.8459 - val_loss: 3249046838.5430 - val_mean_absolute_error: 34464.5827\n",
      "Epoch 2492/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 3481636408.9376 - mean_absolute_error: 44976.9871 - val_loss: 2660434080.5498 - val_mean_absolute_error: 30185.0835\n",
      "Epoch 2493/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3497985322.2652 - mean_absolute_error: 44100.5734 - val_loss: 2414631746.4192 - val_mean_absolute_error: 28450.7294\n",
      "Epoch 2494/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3583868516.2977 - mean_absolute_error: 45731.7118 - val_loss: 2720603115.7663 - val_mean_absolute_error: 29319.2202\n",
      "Epoch 2495/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3578396428.9204 - mean_absolute_error: 45293.1577 - val_loss: 2438501875.6838 - val_mean_absolute_error: 28603.5897\n",
      "Epoch 2496/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 4014117058.4636 - mean_absolute_error: 47769.2332 - val_loss: 2843058137.2921 - val_mean_absolute_error: 31781.1999\n",
      "Epoch 2497/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 4167585909.5979 - mean_absolute_error: 47267.3371 - val_loss: 3251913031.2577 - val_mean_absolute_error: 33626.4037\n",
      "Epoch 2498/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3985654458.7990 - mean_absolute_error: 47890.8568 - val_loss: 2607119999.5601 - val_mean_absolute_error: 30313.4103\n",
      "Epoch 2499/5000\n",
      "1169/1169 [==============================] - 0s 309us/step - loss: 3561637658.0599 - mean_absolute_error: 44461.8113 - val_loss: 2467599628.7560 - val_mean_absolute_error: 29615.8353\n",
      "Epoch 2500/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3814469077.4063 - mean_absolute_error: 45597.6358 - val_loss: 2962933216.3299 - val_mean_absolute_error: 32990.6866\n",
      "Epoch 2501/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3117054453.0505 - mean_absolute_error: 42250.2357 - val_loss: 2499033124.9485 - val_mean_absolute_error: 29942.7811\n",
      "Epoch 2502/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3585187380.9957 - mean_absolute_error: 45357.1461 - val_loss: 2652058007.3127 - val_mean_absolute_error: 31180.8482\n",
      "Epoch 2503/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3580774377.6630 - mean_absolute_error: 44607.6092 - val_loss: 3091538146.0893 - val_mean_absolute_error: 33341.7511\n",
      "Epoch 2504/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3907121637.9401 - mean_absolute_error: 46351.1355 - val_loss: 2473286327.8625 - val_mean_absolute_error: 29522.4623\n",
      "Epoch 2505/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 4011378449.8477 - mean_absolute_error: 46606.9315 - val_loss: 2353026731.5464 - val_mean_absolute_error: 28737.6090\n",
      "Epoch 2506/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3432687844.8452 - mean_absolute_error: 44253.5528 - val_loss: 2995589505.3196 - val_mean_absolute_error: 32564.0409\n",
      "Epoch 2507/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3588858141.5637 - mean_absolute_error: 45591.3953 - val_loss: 2566352479.4502 - val_mean_absolute_error: 29693.1503\n",
      "Epoch 2508/5000\n",
      "1169/1169 [==============================] - 0s 311us/step - loss: 3613364001.9435 - mean_absolute_error: 45033.6124 - val_loss: 3273079970.7491 - val_mean_absolute_error: 34024.5353\n",
      "Epoch 2509/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3940087016.1300 - mean_absolute_error: 46721.6572 - val_loss: 3212873037.4158 - val_mean_absolute_error: 34143.3126\n",
      "Epoch 2510/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3380095639.9795 - mean_absolute_error: 43561.8893 - val_loss: 3189485648.0550 - val_mean_absolute_error: 34530.0194\n",
      "Epoch 2511/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3486750213.2558 - mean_absolute_error: 43765.1622 - val_loss: 2730233280.6598 - val_mean_absolute_error: 31137.0075\n",
      "Epoch 2512/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3375466785.7246 - mean_absolute_error: 44055.1586 - val_loss: 2599342282.3368 - val_mean_absolute_error: 30616.3116\n",
      "Epoch 2513/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3755235637.6527 - mean_absolute_error: 45672.1741 - val_loss: 2614037969.3746 - val_mean_absolute_error: 29771.0347\n",
      "Epoch 2514/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3634028507.2096 - mean_absolute_error: 44356.8663 - val_loss: 2360705174.4330 - val_mean_absolute_error: 27526.7322\n",
      "Epoch 2515/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3515173185.0402 - mean_absolute_error: 44864.5985 - val_loss: 2415297088.6598 - val_mean_absolute_error: 28219.0753\n",
      "Epoch 2516/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3638117970.3405 - mean_absolute_error: 44878.7425 - val_loss: 2921798395.6014 - val_mean_absolute_error: 30926.2434\n",
      "Epoch 2517/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3638688688.2874 - mean_absolute_error: 43896.2470 - val_loss: 2513869868.8660 - val_mean_absolute_error: 29655.9702\n",
      "Epoch 2518/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3518733834.7305 - mean_absolute_error: 44338.3151 - val_loss: 2900163728.7148 - val_mean_absolute_error: 31252.2344\n",
      "Epoch 2519/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3657460651.4696 - mean_absolute_error: 45015.3181 - val_loss: 3450551052.3162 - val_mean_absolute_error: 34810.8555\n",
      "Epoch 2520/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3736472877.1121 - mean_absolute_error: 45902.1103 - val_loss: 3170321158.1581 - val_mean_absolute_error: 33343.7567\n",
      "Epoch 2521/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3641926230.2823 - mean_absolute_error: 45911.0020 - val_loss: 2564063590.4880 - val_mean_absolute_error: 29904.7084\n",
      "Epoch 2522/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3584979756.8931 - mean_absolute_error: 45313.6741 - val_loss: 2573794063.3952 - val_mean_absolute_error: 30184.9902\n",
      "Epoch 2523/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3726975615.0145 - mean_absolute_error: 45818.9554 - val_loss: 2457742268.7010 - val_mean_absolute_error: 29635.4829\n",
      "Epoch 2524/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3435184804.4619 - mean_absolute_error: 44370.8713 - val_loss: 2467520599.9725 - val_mean_absolute_error: 30638.4484\n",
      "Epoch 2525/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3867784951.7879 - mean_absolute_error: 46450.2901 - val_loss: 2836857989.7182 - val_mean_absolute_error: 32452.0351\n",
      "Epoch 2526/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3668883791.2746 - mean_absolute_error: 45139.2518 - val_loss: 2560730127.3952 - val_mean_absolute_error: 30151.4183\n",
      "Epoch 2527/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3610626076.4688 - mean_absolute_error: 44517.9177 - val_loss: 3014129632.3299 - val_mean_absolute_error: 33919.6869\n",
      "Epoch 2528/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3505440654.1249 - mean_absolute_error: 45281.4419 - val_loss: 2779944583.4777 - val_mean_absolute_error: 32571.7308\n",
      "Epoch 2529/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3636306813.4816 - mean_absolute_error: 44708.2161 - val_loss: 3162045729.4296 - val_mean_absolute_error: 34950.9694\n",
      "Epoch 2530/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3625052631.9247 - mean_absolute_error: 45448.1753 - val_loss: 2710684792.9622 - val_mean_absolute_error: 30943.3662\n",
      "Epoch 2531/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3578496082.3405 - mean_absolute_error: 45737.0397 - val_loss: 3167017363.7938 - val_mean_absolute_error: 34670.8043\n",
      "Epoch 2532/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3605965688.2258 - mean_absolute_error: 45421.0063 - val_loss: 2784281399.4227 - val_mean_absolute_error: 32319.2309\n",
      "Epoch 2533/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3697943753.4713 - mean_absolute_error: 44802.7220 - val_loss: 2474529671.0378 - val_mean_absolute_error: 30252.7693\n",
      "Epoch 2534/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3969042620.1129 - mean_absolute_error: 46436.2471 - val_loss: 3224174086.1581 - val_mean_absolute_error: 35102.8548\n",
      "Epoch 2535/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 3681911092.3388 - mean_absolute_error: 45402.6091 - val_loss: 2532600182.3230 - val_mean_absolute_error: 29638.3285\n",
      "Epoch 2536/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3572859232.3559 - mean_absolute_error: 44752.7544 - val_loss: 2218441003.1065 - val_mean_absolute_error: 27598.5752\n",
      "Epoch 2537/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 4058884007.9658 - mean_absolute_error: 47033.0436 - val_loss: 2929413427.0241 - val_mean_absolute_error: 31715.9568\n",
      "Epoch 2538/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 4049282941.0436 - mean_absolute_error: 48099.5838 - val_loss: 2743527991.4227 - val_mean_absolute_error: 31959.0422\n",
      "Epoch 2539/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3856153697.6698 - mean_absolute_error: 46746.6251 - val_loss: 2370967589.3883 - val_mean_absolute_error: 29369.3908\n",
      "Epoch 2540/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 3661062211.2301 - mean_absolute_error: 44363.2063 - val_loss: 2759710141.1409 - val_mean_absolute_error: 32280.8767\n",
      "Epoch 2541/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3438060357.4200 - mean_absolute_error: 43569.3499 - val_loss: 2711595488.3299 - val_mean_absolute_error: 32115.9119\n",
      "Epoch 2542/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3802489737.5261 - mean_absolute_error: 45709.8856 - val_loss: 2357016783.1753 - val_mean_absolute_error: 29391.2665\n",
      "Epoch 2543/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 3404175494.4602 - mean_absolute_error: 44450.1384 - val_loss: 2915898727.8076 - val_mean_absolute_error: 33352.8607\n",
      "Epoch 2544/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3416319833.5672 - mean_absolute_error: 45130.6837 - val_loss: 2549423597.9656 - val_mean_absolute_error: 29651.8196\n",
      "Epoch 2545/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3661329092.2156 - mean_absolute_error: 45697.1357 - val_loss: 2333370488.0825 - val_mean_absolute_error: 28549.7106\n",
      "Epoch 2546/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3808475293.2352 - mean_absolute_error: 45554.9753 - val_loss: 2561578378.5567 - val_mean_absolute_error: 29774.5632\n",
      "Epoch 2547/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3510949009.6287 - mean_absolute_error: 45094.2989 - val_loss: 2280699173.8282 - val_mean_absolute_error: 27971.5080\n",
      "Epoch 2548/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3777402166.0907 - mean_absolute_error: 45429.9638 - val_loss: 2911642046.9003 - val_mean_absolute_error: 32542.1750\n",
      "Epoch 2549/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3428849619.5449 - mean_absolute_error: 43694.0456 - val_loss: 2340237889.9794 - val_mean_absolute_error: 28299.8850\n",
      "Epoch 2550/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3279772291.3944 - mean_absolute_error: 43946.9072 - val_loss: 2876003674.6117 - val_mean_absolute_error: 32725.5930\n",
      "Epoch 2551/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3184262022.8982 - mean_absolute_error: 42611.0864 - val_loss: 2966868978.8041 - val_mean_absolute_error: 34237.3234\n",
      "Epoch 2552/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3537755923.0522 - mean_absolute_error: 44703.4088 - val_loss: 3347880635.3814 - val_mean_absolute_error: 36001.4422\n",
      "Epoch 2553/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3842647826.6142 - mean_absolute_error: 45365.0230 - val_loss: 2648486500.2887 - val_mean_absolute_error: 31262.7946\n",
      "Epoch 2554/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3481226165.7622 - mean_absolute_error: 45134.2174 - val_loss: 2376043260.4811 - val_mean_absolute_error: 28566.2188\n",
      "Epoch 2555/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 3611912238.4260 - mean_absolute_error: 44827.7875 - val_loss: 2448051653.4983 - val_mean_absolute_error: 29355.1846\n",
      "Epoch 2556/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3476657346.0257 - mean_absolute_error: 44804.8388 - val_loss: 3054615032.0825 - val_mean_absolute_error: 33980.0681\n",
      "Epoch 2557/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 344us/step - loss: 3901113834.5389 - mean_absolute_error: 46423.2228 - val_loss: 2448393620.2337 - val_mean_absolute_error: 29169.1772\n",
      "Epoch 2558/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3645137181.5637 - mean_absolute_error: 44589.1244 - val_loss: 2637242080.7698 - val_mean_absolute_error: 30395.9283\n",
      "Epoch 2559/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3592686594.4089 - mean_absolute_error: 44960.7234 - val_loss: 2374675913.8969 - val_mean_absolute_error: 29163.2243\n",
      "Epoch 2560/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3797073965.1121 - mean_absolute_error: 44245.1087 - val_loss: 3111762090.6667 - val_mean_absolute_error: 34701.9461\n",
      "Epoch 2561/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3232282605.6048 - mean_absolute_error: 42591.4092 - val_loss: 2617204179.1340 - val_mean_absolute_error: 31380.6304\n",
      "Epoch 2562/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 4060411444.5577 - mean_absolute_error: 46136.3402 - val_loss: 2362379465.4570 - val_mean_absolute_error: 29058.9413\n",
      "Epoch 2563/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 4070174304.7938 - mean_absolute_error: 47183.7416 - val_loss: 2518808253.1409 - val_mean_absolute_error: 30827.3649\n",
      "Epoch 2564/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3616983116.8657 - mean_absolute_error: 44348.1631 - val_loss: 2392591890.4742 - val_mean_absolute_error: 29154.0473\n",
      "Epoch 2565/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3797218146.7648 - mean_absolute_error: 46229.7344 - val_loss: 2265276431.3952 - val_mean_absolute_error: 28331.9663\n",
      "Epoch 2566/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3475867126.8024 - mean_absolute_error: 45002.4461 - val_loss: 2704605766.3780 - val_mean_absolute_error: 31120.5436\n",
      "Epoch 2567/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3819144922.5526 - mean_absolute_error: 45614.3673 - val_loss: 2492835376.3849 - val_mean_absolute_error: 30360.5566\n",
      "Epoch 2568/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3343287499.2233 - mean_absolute_error: 44413.6546 - val_loss: 2312261169.7045 - val_mean_absolute_error: 29506.5273\n",
      "Epoch 2569/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3455289524.4482 - mean_absolute_error: 43933.8245 - val_loss: 2408646468.6186 - val_mean_absolute_error: 30464.6584\n",
      "Epoch 2570/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3516606136.3901 - mean_absolute_error: 45169.9127 - val_loss: 2133244405.8832 - val_mean_absolute_error: 27711.1129\n",
      "Epoch 2571/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3560937359.8768 - mean_absolute_error: 46162.9358 - val_loss: 2602513105.3746 - val_mean_absolute_error: 29903.2044\n",
      "Epoch 2572/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3695844395.7981 - mean_absolute_error: 45684.9590 - val_loss: 2446409119.6701 - val_mean_absolute_error: 29317.8538\n",
      "Epoch 2573/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3604823622.7340 - mean_absolute_error: 44941.2225 - val_loss: 2721935749.2784 - val_mean_absolute_error: 31534.3903\n",
      "Epoch 2574/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3347853624.7186 - mean_absolute_error: 43438.3850 - val_loss: 2667206155.4364 - val_mean_absolute_error: 31545.8015\n",
      "Epoch 2575/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3567119767.9795 - mean_absolute_error: 44304.1056 - val_loss: 2647411957.4433 - val_mean_absolute_error: 31123.2637\n",
      "Epoch 2576/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3386836133.3379 - mean_absolute_error: 43782.7156 - val_loss: 2419637751.6426 - val_mean_absolute_error: 29819.6188\n",
      "Epoch 2577/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3411833626.7169 - mean_absolute_error: 44580.7438 - val_loss: 2805060117.9931 - val_mean_absolute_error: 32488.2988\n",
      "Epoch 2578/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3819825516.8383 - mean_absolute_error: 45072.8643 - val_loss: 3491492071.3677 - val_mean_absolute_error: 35532.5795\n",
      "Epoch 2579/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 3909780357.3653 - mean_absolute_error: 44702.4002 - val_loss: 3372796730.9416 - val_mean_absolute_error: 33800.3653\n",
      "Epoch 2580/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3676726542.2344 - mean_absolute_error: 45878.5706 - val_loss: 2879548294.5979 - val_mean_absolute_error: 31521.6618\n",
      "Epoch 2581/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3688288429.8785 - mean_absolute_error: 45395.2334 - val_loss: 3051129389.7457 - val_mean_absolute_error: 33411.8281\n",
      "Epoch 2582/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3665966068.1745 - mean_absolute_error: 45089.8839 - val_loss: 2334872595.3540 - val_mean_absolute_error: 29508.0446\n",
      "Epoch 2583/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3469419896.6638 - mean_absolute_error: 44290.6422 - val_loss: 2241397658.3918 - val_mean_absolute_error: 29053.0380\n",
      "Epoch 2584/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3774581538.6005 - mean_absolute_error: 45934.6568 - val_loss: 2971586229.2234 - val_mean_absolute_error: 33008.5647\n",
      "Epoch 2585/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3832435939.3122 - mean_absolute_error: 46159.5612 - val_loss: 2413073743.1753 - val_mean_absolute_error: 29475.1536\n",
      "Epoch 2586/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3409474382.1796 - mean_absolute_error: 43488.4227 - val_loss: 2731914272.1100 - val_mean_absolute_error: 31068.4739\n",
      "Epoch 2587/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3497426693.4748 - mean_absolute_error: 43299.3934 - val_loss: 2932345932.5361 - val_mean_absolute_error: 32425.8198\n",
      "Epoch 2588/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3711247178.6758 - mean_absolute_error: 45603.4597 - val_loss: 2920975399.5876 - val_mean_absolute_error: 32253.4099\n",
      "Epoch 2589/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 3424165733.6116 - mean_absolute_error: 44128.4519 - val_loss: 2756499638.5430 - val_mean_absolute_error: 31170.6600\n",
      "Epoch 2590/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3345468610.0257 - mean_absolute_error: 43080.3464 - val_loss: 2009031999.7801 - val_mean_absolute_error: 27278.6402\n",
      "Epoch 2591/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3406118853.5295 - mean_absolute_error: 42952.6026 - val_loss: 2611181158.0481 - val_mean_absolute_error: 32039.8017\n",
      "Epoch 2592/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3712054810.4979 - mean_absolute_error: 44637.1031 - val_loss: 2854711069.9107 - val_mean_absolute_error: 33065.8847\n",
      "Epoch 2593/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3583271313.1908 - mean_absolute_error: 44827.6851 - val_loss: 3319071861.8832 - val_mean_absolute_error: 34486.2638\n",
      "Epoch 2594/5000\n",
      "1169/1169 [==============================] - 0s 400us/step - loss: 3461082643.2712 - mean_absolute_error: 45261.3909 - val_loss: 2342405789.0309 - val_mean_absolute_error: 28071.0913\n",
      "Epoch 2595/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3579362624.8212 - mean_absolute_error: 44604.9294 - val_loss: 2607678784.2199 - val_mean_absolute_error: 30201.0734\n",
      "Epoch 2596/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3600075337.5808 - mean_absolute_error: 43670.1778 - val_loss: 1885465803.2165 - val_mean_absolute_error: 26671.1369\n",
      "Epoch 2597/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3424784126.0291 - mean_absolute_error: 43734.5821 - val_loss: 2015613688.5223 - val_mean_absolute_error: 26779.9470\n",
      "Epoch 2598/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3899499653.1463 - mean_absolute_error: 46277.8797 - val_loss: 2340164768.9897 - val_mean_absolute_error: 29390.5795\n",
      "Epoch 2599/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 3488114002.9974 - mean_absolute_error: 44241.7441 - val_loss: 3008671186.6942 - val_mean_absolute_error: 33917.4043\n",
      "Epoch 2600/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3788405513.8546 - mean_absolute_error: 44523.3562 - val_loss: 2653208635.8213 - val_mean_absolute_error: 31307.0890\n",
      "Epoch 2601/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 4141304722.5047 - mean_absolute_error: 46163.4301 - val_loss: 2475277318.5979 - val_mean_absolute_error: 30160.0559\n",
      "Epoch 2602/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 3743537416.1027 - mean_absolute_error: 45443.8246 - val_loss: 2157030986.7766 - val_mean_absolute_error: 28041.1774\n",
      "Epoch 2603/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3574005570.1352 - mean_absolute_error: 44020.6524 - val_loss: 2392796032.0000 - val_mean_absolute_error: 29643.9575\n",
      "Epoch 2604/5000\n",
      "1169/1169 [==============================] - 0s 321us/step - loss: 3564441448.4585 - mean_absolute_error: 44553.8928 - val_loss: 2270345095.4777 - val_mean_absolute_error: 28039.9699\n",
      "Epoch 2605/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3352555492.4072 - mean_absolute_error: 44267.1374 - val_loss: 2498635283.7938 - val_mean_absolute_error: 30114.1718\n",
      "Epoch 2606/5000\n",
      "1169/1169 [==============================] - 0s 319us/step - loss: 3376861083.7023 - mean_absolute_error: 44279.3964 - val_loss: 2227366715.8213 - val_mean_absolute_error: 27995.4471\n",
      "Epoch 2607/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3783337029.6390 - mean_absolute_error: 45275.7919 - val_loss: 2783157441.5395 - val_mean_absolute_error: 30621.6660\n",
      "Epoch 2608/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3590255635.0522 - mean_absolute_error: 44663.7222 - val_loss: 2451026733.7457 - val_mean_absolute_error: 29169.6450\n",
      "Epoch 2609/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3635825338.1420 - mean_absolute_error: 45811.8010 - val_loss: 2742137756.5911 - val_mean_absolute_error: 31477.8330\n",
      "Epoch 2610/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3353225969.3276 - mean_absolute_error: 43492.0538 - val_loss: 2639699338.1168 - val_mean_absolute_error: 31052.3166\n",
      "Epoch 2611/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3778571482.5526 - mean_absolute_error: 46230.6773 - val_loss: 2741091337.6770 - val_mean_absolute_error: 31124.5865\n",
      "Epoch 2612/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3475347324.1677 - mean_absolute_error: 44015.1770 - val_loss: 3163371485.2509 - val_mean_absolute_error: 32622.1159\n",
      "Epoch 2613/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3526744629.4337 - mean_absolute_error: 45181.1600 - val_loss: 2344264181.8832 - val_mean_absolute_error: 28206.0872\n",
      "Epoch 2614/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3448203885.4953 - mean_absolute_error: 44356.6728 - val_loss: 2513759605.0034 - val_mean_absolute_error: 29025.9318\n",
      "Epoch 2615/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3417487807.6168 - mean_absolute_error: 44123.8949 - val_loss: 2701442364.2612 - val_mean_absolute_error: 30441.2993\n",
      "Epoch 2616/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 3447288789.2968 - mean_absolute_error: 44335.8738 - val_loss: 2484696107.5464 - val_mean_absolute_error: 29553.5843\n",
      "Epoch 2617/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3523934045.0710 - mean_absolute_error: 45128.6815 - val_loss: 2461431859.4639 - val_mean_absolute_error: 28697.5718\n",
      "Epoch 2618/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3352325305.2660 - mean_absolute_error: 43569.9646 - val_loss: 2476914922.0069 - val_mean_absolute_error: 28364.3557\n",
      "Epoch 2619/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3902827634.7511 - mean_absolute_error: 46996.9013 - val_loss: 2687778251.2165 - val_mean_absolute_error: 29709.9503\n",
      "Epoch 2620/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3617348151.6236 - mean_absolute_error: 46169.7674 - val_loss: 2697474124.9759 - val_mean_absolute_error: 31325.8806\n",
      "Epoch 2621/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3604401042.9427 - mean_absolute_error: 43897.1489 - val_loss: 2943373468.5911 - val_mean_absolute_error: 31740.5610\n",
      "Epoch 2622/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3381168067.5586 - mean_absolute_error: 44323.4666 - val_loss: 2526221584.2749 - val_mean_absolute_error: 29361.6391\n",
      "Epoch 2623/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3553916559.2198 - mean_absolute_error: 46314.9565 - val_loss: 2741417936.4948 - val_mean_absolute_error: 30417.0239\n",
      "Epoch 2624/5000\n",
      "1169/1169 [==============================] - 0s 397us/step - loss: 4069956481.8614 - mean_absolute_error: 46290.6506 - val_loss: 2488783719.8076 - val_mean_absolute_error: 28809.2171\n",
      "Epoch 2625/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3342126828.5098 - mean_absolute_error: 44843.4854 - val_loss: 2638062970.2818 - val_mean_absolute_error: 30608.2127\n",
      "Epoch 2626/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3887985725.7553 - mean_absolute_error: 45231.8311 - val_loss: 2227792315.3814 - val_mean_absolute_error: 27203.7489\n",
      "Epoch 2627/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3851654253.4953 - mean_absolute_error: 46499.0838 - val_loss: 2414297082.7216 - val_mean_absolute_error: 28699.4848\n",
      "Epoch 2628/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3580368165.2284 - mean_absolute_error: 44672.7731 - val_loss: 2708691155.1340 - val_mean_absolute_error: 30324.1034\n",
      "Epoch 2629/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3630770851.5860 - mean_absolute_error: 44492.6288 - val_loss: 2660048956.7010 - val_mean_absolute_error: 30363.7462\n",
      "Epoch 2630/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3530575238.2412 - mean_absolute_error: 44406.2576 - val_loss: 2337263736.0825 - val_mean_absolute_error: 28241.3882\n",
      "Epoch 2631/5000\n",
      "1169/1169 [==============================] - 0s 383us/step - loss: 3795300287.6168 - mean_absolute_error: 46167.5780 - val_loss: 3053391126.8729 - val_mean_absolute_error: 32470.2811\n",
      "Epoch 2632/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3320534270.0291 - mean_absolute_error: 44629.8004 - val_loss: 2546957955.5189 - val_mean_absolute_error: 30184.7101\n",
      "Epoch 2633/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3456942828.0719 - mean_absolute_error: 44179.9540 - val_loss: 2613733709.8557 - val_mean_absolute_error: 30089.9730\n",
      "Epoch 2634/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3550842875.1822 - mean_absolute_error: 44645.0949 - val_loss: 3264542238.7904 - val_mean_absolute_error: 33098.1192\n",
      "Epoch 2635/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 3725903536.9444 - mean_absolute_error: 45776.6070 - val_loss: 2577787203.2990 - val_mean_absolute_error: 29665.1666\n",
      "Epoch 2636/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3423536013.2489 - mean_absolute_error: 44441.8998 - val_loss: 2547813320.5773 - val_mean_absolute_error: 29535.6385\n",
      "Epoch 2637/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3827595172.6809 - mean_absolute_error: 46338.9676 - val_loss: 2253225504.1100 - val_mean_absolute_error: 27885.5224\n",
      "Epoch 2638/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3729858207.8631 - mean_absolute_error: 45458.3487 - val_loss: 2877504859.4914 - val_mean_absolute_error: 31921.5888\n",
      "Epoch 2639/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 340us/step - loss: 3517588029.7553 - mean_absolute_error: 43936.2795 - val_loss: 2562073823.0103 - val_mean_absolute_error: 30265.4302\n",
      "Epoch 2640/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3665069902.8366 - mean_absolute_error: 45432.7002 - val_loss: 2415054046.5704 - val_mean_absolute_error: 28773.2828\n",
      "Epoch 2641/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3403961719.7879 - mean_absolute_error: 44187.2923 - val_loss: 2637287124.8935 - val_mean_absolute_error: 31162.3912\n",
      "Epoch 2642/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3636875316.3388 - mean_absolute_error: 45978.0995 - val_loss: 2667954019.4089 - val_mean_absolute_error: 31180.3083\n",
      "Epoch 2643/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3698574600.5406 - mean_absolute_error: 45890.6471 - val_loss: 2989940289.0997 - val_mean_absolute_error: 32205.4145\n",
      "Epoch 2644/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3413195982.7271 - mean_absolute_error: 43306.7700 - val_loss: 3210742860.5361 - val_mean_absolute_error: 33467.5134\n",
      "Epoch 2645/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3204889519.1925 - mean_absolute_error: 43495.0437 - val_loss: 2686503954.9141 - val_mean_absolute_error: 30231.5584\n",
      "Epoch 2646/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3632521626.9358 - mean_absolute_error: 44616.2147 - val_loss: 2004063512.6323 - val_mean_absolute_error: 26206.2535\n",
      "Epoch 2647/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3388413445.6938 - mean_absolute_error: 43797.3979 - val_loss: 1923030479.6151 - val_mean_absolute_error: 24626.9510\n",
      "Epoch 2648/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3453478339.9966 - mean_absolute_error: 44717.8674 - val_loss: 2376079966.1306 - val_mean_absolute_error: 29072.7824\n",
      "Epoch 2649/5000\n",
      "1169/1169 [==============================] - 0s 311us/step - loss: 3659850607.9042 - mean_absolute_error: 44975.8405 - val_loss: 2915411726.9553 - val_mean_absolute_error: 32076.6273\n",
      "Epoch 2650/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3723209649.1634 - mean_absolute_error: 45706.4979 - val_loss: 2621839393.4296 - val_mean_absolute_error: 30651.1411\n",
      "Epoch 2651/5000\n",
      "1169/1169 [==============================] - 0s 313us/step - loss: 3588613073.7930 - mean_absolute_error: 45510.9276 - val_loss: 2586284565.1134 - val_mean_absolute_error: 30328.7118\n",
      "Epoch 2652/5000\n",
      "1169/1169 [==============================] - 0s 389us/step - loss: 3549247141.1189 - mean_absolute_error: 45022.3078 - val_loss: 2799373933.5258 - val_mean_absolute_error: 31552.6414\n",
      "Epoch 2653/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 3644650024.2943 - mean_absolute_error: 44592.1151 - val_loss: 2102149379.0790 - val_mean_absolute_error: 27484.5520\n",
      "Epoch 2654/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3809991683.0659 - mean_absolute_error: 45780.1451 - val_loss: 2500438768.1649 - val_mean_absolute_error: 30546.8179\n",
      "Epoch 2655/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3638684724.5577 - mean_absolute_error: 45791.3384 - val_loss: 2598645936.8247 - val_mean_absolute_error: 30716.8989\n",
      "Epoch 2656/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3515399427.0659 - mean_absolute_error: 44711.2956 - val_loss: 2108883298.9691 - val_mean_absolute_error: 27607.7130\n",
      "Epoch 2657/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 3548503278.2618 - mean_absolute_error: 45194.4966 - val_loss: 2266959336.2474 - val_mean_absolute_error: 28151.9938\n",
      "Epoch 2658/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3179207613.8648 - mean_absolute_error: 43331.5764 - val_loss: 2621235687.8076 - val_mean_absolute_error: 30677.3563\n",
      "Epoch 2659/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 3455622071.2951 - mean_absolute_error: 43412.1081 - val_loss: 2859827082.1168 - val_mean_absolute_error: 31246.3004\n",
      "Epoch 2660/5000\n",
      "1169/1169 [==============================] - 0s 379us/step - loss: 3449929314.1078 - mean_absolute_error: 44517.0708 - val_loss: 2311789804.6460 - val_mean_absolute_error: 29985.5073\n",
      "Epoch 2661/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3806821903.3293 - mean_absolute_error: 45730.7494 - val_loss: 2897464905.8969 - val_mean_absolute_error: 32337.0782\n",
      "Epoch 2662/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3559981787.8666 - mean_absolute_error: 44677.5716 - val_loss: 2753626302.9003 - val_mean_absolute_error: 30941.6113\n",
      "Epoch 2663/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3485906453.4611 - mean_absolute_error: 45189.6373 - val_loss: 2606405134.9553 - val_mean_absolute_error: 29602.1168\n",
      "Epoch 2664/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3712183872.1642 - mean_absolute_error: 45389.2510 - val_loss: 2007521959.5876 - val_mean_absolute_error: 26823.5337\n",
      "Epoch 2665/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3482237600.3011 - mean_absolute_error: 43979.2254 - val_loss: 2047408978.2543 - val_mean_absolute_error: 26523.2646\n",
      "Epoch 2666/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3491593311.4799 - mean_absolute_error: 43246.6521 - val_loss: 2038462595.9588 - val_mean_absolute_error: 26538.4377\n",
      "Epoch 2667/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3883237952.3832 - mean_absolute_error: 46013.3493 - val_loss: 2128435009.9794 - val_mean_absolute_error: 27079.5988\n",
      "Epoch 2668/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3692151382.5013 - mean_absolute_error: 45725.5947 - val_loss: 2418699691.9863 - val_mean_absolute_error: 28551.0539\n",
      "Epoch 2669/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3972020381.6732 - mean_absolute_error: 46791.4509 - val_loss: 2563837273.7320 - val_mean_absolute_error: 29098.0400\n",
      "Epoch 2670/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3380131031.2678 - mean_absolute_error: 44832.7523 - val_loss: 2444411378.8041 - val_mean_absolute_error: 28665.0117\n",
      "Epoch 2671/5000\n",
      "1169/1169 [==============================] - 0s 386us/step - loss: 3545756795.0727 - mean_absolute_error: 45626.9775 - val_loss: 2610136325.2784 - val_mean_absolute_error: 29991.1853\n",
      "Epoch 2672/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3645657128.7322 - mean_absolute_error: 45414.2320 - val_loss: 2213943517.2509 - val_mean_absolute_error: 28763.3472\n",
      "Epoch 2673/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3350566787.1754 - mean_absolute_error: 44409.5809 - val_loss: 1933583150.1856 - val_mean_absolute_error: 26174.0290\n",
      "Epoch 2674/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3354759033.5398 - mean_absolute_error: 44420.5215 - val_loss: 2094546768.9347 - val_mean_absolute_error: 27047.3264\n",
      "Epoch 2675/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3628092197.2284 - mean_absolute_error: 45361.1079 - val_loss: 2484387487.2302 - val_mean_absolute_error: 29316.6440\n",
      "Epoch 2676/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3722173210.4979 - mean_absolute_error: 45674.1989 - val_loss: 2393274711.5326 - val_mean_absolute_error: 28980.7220\n",
      "Epoch 2677/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3410682877.8101 - mean_absolute_error: 43939.7864 - val_loss: 2614299930.3918 - val_mean_absolute_error: 29168.7354\n",
      "Epoch 2678/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3563550841.7588 - mean_absolute_error: 44655.5730 - val_loss: 2689166300.8110 - val_mean_absolute_error: 30211.1697\n",
      "Epoch 2679/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3383064228.6809 - mean_absolute_error: 43684.0876 - val_loss: 2164990661.9381 - val_mean_absolute_error: 27136.1465\n",
      "Epoch 2680/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3880429388.4277 - mean_absolute_error: 46306.0907 - val_loss: 2753871481.8419 - val_mean_absolute_error: 30824.4121\n",
      "Epoch 2681/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 3743540865.6424 - mean_absolute_error: 46084.8489 - val_loss: 2364806690.7491 - val_mean_absolute_error: 28753.0921\n",
      "Epoch 2682/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3583798940.3593 - mean_absolute_error: 45530.7268 - val_loss: 2496110019.2990 - val_mean_absolute_error: 29061.1542\n",
      "Epoch 2683/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3473385337.1018 - mean_absolute_error: 44037.8356 - val_loss: 2994415273.7869 - val_mean_absolute_error: 30982.6784\n",
      "Epoch 2684/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3552954064.9170 - mean_absolute_error: 45722.5024 - val_loss: 2820958204.4811 - val_mean_absolute_error: 31494.2035\n",
      "Epoch 2685/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3595295170.6826 - mean_absolute_error: 44392.3454 - val_loss: 2742251621.6082 - val_mean_absolute_error: 31504.1453\n",
      "Epoch 2686/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 3561362301.9196 - mean_absolute_error: 45087.3755 - val_loss: 2962307868.1512 - val_mean_absolute_error: 33051.4165\n",
      "Epoch 2687/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3704599099.3464 - mean_absolute_error: 45468.5437 - val_loss: 2195408481.6495 - val_mean_absolute_error: 28640.6473\n",
      "Epoch 2688/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3655800911.7126 - mean_absolute_error: 45550.5528 - val_loss: 2273990882.9691 - val_mean_absolute_error: 29289.4936\n",
      "Epoch 2689/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 3335318644.9410 - mean_absolute_error: 43341.0412 - val_loss: 2759618185.6770 - val_mean_absolute_error: 31446.5775\n",
      "Epoch 2690/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3245590602.4568 - mean_absolute_error: 43269.4595 - val_loss: 3316674101.6632 - val_mean_absolute_error: 34396.0680\n",
      "Epoch 2691/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3752872964.3798 - mean_absolute_error: 46643.1662 - val_loss: 2575770551.4227 - val_mean_absolute_error: 31278.1824\n",
      "Epoch 2692/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3537286043.0453 - mean_absolute_error: 44718.1601 - val_loss: 2453997410.9691 - val_mean_absolute_error: 30430.7860\n",
      "Epoch 2693/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3657749751.4594 - mean_absolute_error: 45065.0777 - val_loss: 2886876638.1306 - val_mean_absolute_error: 32211.5744\n",
      "Epoch 2694/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3541197785.4577 - mean_absolute_error: 44610.6981 - val_loss: 2612894822.0481 - val_mean_absolute_error: 30662.1502\n",
      "Epoch 2695/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3545864089.7314 - mean_absolute_error: 44113.1977 - val_loss: 3189181917.2509 - val_mean_absolute_error: 32873.7567\n",
      "Epoch 2696/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3877708142.1523 - mean_absolute_error: 46686.8421 - val_loss: 2182890499.5189 - val_mean_absolute_error: 27043.2525\n",
      "Epoch 2697/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3574668693.5706 - mean_absolute_error: 45250.9036 - val_loss: 2392493504.6598 - val_mean_absolute_error: 28853.7896\n",
      "Epoch 2698/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3711614856.8691 - mean_absolute_error: 45270.6434 - val_loss: 2338966280.3574 - val_mean_absolute_error: 27441.0509\n",
      "Epoch 2699/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3946472478.2207 - mean_absolute_error: 46734.6855 - val_loss: 2788543545.1821 - val_mean_absolute_error: 30514.2614\n",
      "Epoch 2700/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3593208663.8152 - mean_absolute_error: 44862.0818 - val_loss: 2805997403.4914 - val_mean_absolute_error: 30182.7374\n",
      "Epoch 2701/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3699490337.7246 - mean_absolute_error: 46056.0680 - val_loss: 2445769536.6598 - val_mean_absolute_error: 27601.4013\n",
      "Epoch 2702/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3534146750.5218 - mean_absolute_error: 45238.3025 - val_loss: 2455146969.2921 - val_mean_absolute_error: 27252.8162\n",
      "Epoch 2703/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3833333224.7870 - mean_absolute_error: 45596.7757 - val_loss: 2477073159.4777 - val_mean_absolute_error: 27872.7507\n",
      "Epoch 2704/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3438821929.1702 - mean_absolute_error: 44945.7206 - val_loss: 2514236559.8351 - val_mean_absolute_error: 28831.9525\n",
      "Epoch 2705/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3563004571.0453 - mean_absolute_error: 44796.6518 - val_loss: 2479870798.2955 - val_mean_absolute_error: 28350.0329\n",
      "Epoch 2706/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3726436972.6193 - mean_absolute_error: 45306.1750 - val_loss: 2519549688.9622 - val_mean_absolute_error: 27235.1413\n",
      "Epoch 2707/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3403663063.9247 - mean_absolute_error: 44219.0349 - val_loss: 2702637152.7698 - val_mean_absolute_error: 30013.5060\n",
      "Epoch 2708/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3586169899.7981 - mean_absolute_error: 44993.9174 - val_loss: 3380343126.2131 - val_mean_absolute_error: 34029.8360\n",
      "Epoch 2709/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3648286363.4833 - mean_absolute_error: 45821.0618 - val_loss: 2397996424.7973 - val_mean_absolute_error: 28183.7143\n",
      "Epoch 2710/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 3332917509.4748 - mean_absolute_error: 43717.0831 - val_loss: 2591192915.5739 - val_mean_absolute_error: 30429.1243\n",
      "Epoch 2711/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 3403128897.6972 - mean_absolute_error: 44134.6833 - val_loss: 2728030631.1478 - val_mean_absolute_error: 30750.7602\n",
      "Epoch 2712/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3391327277.1121 - mean_absolute_error: 44317.3178 - val_loss: 2708647771.4914 - val_mean_absolute_error: 31602.1237\n",
      "Epoch 2713/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 4037287719.5278 - mean_absolute_error: 47197.6015 - val_loss: 2950917276.1512 - val_mean_absolute_error: 31947.4363\n",
      "Epoch 2714/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 3647234136.0342 - mean_absolute_error: 45707.5464 - val_loss: 2616988346.0619 - val_mean_absolute_error: 30153.8935\n",
      "Epoch 2715/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3544797091.8050 - mean_absolute_error: 45217.8210 - val_loss: 2244845826.1993 - val_mean_absolute_error: 27937.6362\n",
      "Epoch 2716/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3690053180.4414 - mean_absolute_error: 46057.3361 - val_loss: 2335439755.8763 - val_mean_absolute_error: 27818.0760\n",
      "Epoch 2717/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3711280093.3995 - mean_absolute_error: 45536.4650 - val_loss: 2533407432.5773 - val_mean_absolute_error: 28997.9969\n",
      "Epoch 2718/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3541756291.1754 - mean_absolute_error: 44599.2073 - val_loss: 2915752829.3608 - val_mean_absolute_error: 32045.3238\n",
      "Epoch 2719/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3454709343.4799 - mean_absolute_error: 44189.5179 - val_loss: 2442319115.8763 - val_mean_absolute_error: 29431.2255\n",
      "Epoch 2720/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3561456229.1737 - mean_absolute_error: 45161.7766 - val_loss: 2526715059.9038 - val_mean_absolute_error: 29053.9997\n",
      "Epoch 2721/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 354us/step - loss: 3441724201.8272 - mean_absolute_error: 43832.5139 - val_loss: 2253354421.2234 - val_mean_absolute_error: 28390.1881\n",
      "Epoch 2722/5000\n",
      "1169/1169 [==============================] - 0s 308us/step - loss: 3449766931.7092 - mean_absolute_error: 44936.0439 - val_loss: 2404134984.1375 - val_mean_absolute_error: 29593.8383\n",
      "Epoch 2723/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3663949557.7074 - mean_absolute_error: 45164.4855 - val_loss: 2951737921.5395 - val_mean_absolute_error: 32462.6370\n",
      "Epoch 2724/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3321974156.8109 - mean_absolute_error: 44715.8088 - val_loss: 2337044781.3058 - val_mean_absolute_error: 29083.7874\n",
      "Epoch 2725/5000\n",
      "1169/1169 [==============================] - ETA: 0s - loss: 3464642681.2632 - mean_absolute_error: 44447.18 - 0s 356us/step - loss: 3441161870.1249 - mean_absolute_error: 44318.9842 - val_loss: 2597980425.6770 - val_mean_absolute_error: 30262.1568\n",
      "Epoch 2726/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3270878577.4371 - mean_absolute_error: 43547.5438 - val_loss: 2195122363.8213 - val_mean_absolute_error: 27586.5057\n",
      "Epoch 2727/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3481817703.5825 - mean_absolute_error: 43875.1902 - val_loss: 2521262559.0103 - val_mean_absolute_error: 28698.7308\n",
      "Epoch 2728/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 3565923937.6698 - mean_absolute_error: 45478.4580 - val_loss: 2307688308.1237 - val_mean_absolute_error: 27820.3045\n",
      "Epoch 2729/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 3280727252.8589 - mean_absolute_error: 43827.0510 - val_loss: 2654504547.4089 - val_mean_absolute_error: 30293.3423\n",
      "Epoch 2730/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3737898646.4465 - mean_absolute_error: 46017.1328 - val_loss: 2693404010.0069 - val_mean_absolute_error: 31303.3492\n",
      "Epoch 2731/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3763106492.7699 - mean_absolute_error: 45957.5615 - val_loss: 2413090436.3986 - val_mean_absolute_error: 29032.4757\n",
      "Epoch 2732/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3612822762.5389 - mean_absolute_error: 45514.6085 - val_loss: 2609291637.4433 - val_mean_absolute_error: 29266.7769\n",
      "Epoch 2733/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 2968454961.2729 - mean_absolute_error: 42005.6178 - val_loss: 2428629982.5704 - val_mean_absolute_error: 29280.4849\n",
      "Epoch 2734/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3352787130.7990 - mean_absolute_error: 43636.0321 - val_loss: 2418005820.7010 - val_mean_absolute_error: 29213.0291\n",
      "Epoch 2735/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3701945420.8657 - mean_absolute_error: 45932.1710 - val_loss: 2613223901.2509 - val_mean_absolute_error: 31002.4434\n",
      "Epoch 2736/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3559352912.5885 - mean_absolute_error: 44891.8539 - val_loss: 2268073888.5498 - val_mean_absolute_error: 28153.1348\n",
      "Epoch 2737/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3967719048.6501 - mean_absolute_error: 46144.7695 - val_loss: 3043134342.5979 - val_mean_absolute_error: 31883.1123\n",
      "Epoch 2738/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3563556841.9914 - mean_absolute_error: 45119.5184 - val_loss: 2819066707.5739 - val_mean_absolute_error: 31448.3830\n",
      "Epoch 2739/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3547410928.6707 - mean_absolute_error: 45368.8738 - val_loss: 2828545090.8591 - val_mean_absolute_error: 31028.2742\n",
      "Epoch 2740/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3562880956.1129 - mean_absolute_error: 44077.9358 - val_loss: 2929238416.2749 - val_mean_absolute_error: 31797.9388\n",
      "Epoch 2741/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3320281244.7973 - mean_absolute_error: 42613.5042 - val_loss: 2912974780.2612 - val_mean_absolute_error: 31717.5017\n",
      "Epoch 2742/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3226452175.3841 - mean_absolute_error: 43026.0385 - val_loss: 2667897824.3299 - val_mean_absolute_error: 30019.6428\n",
      "Epoch 2743/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3554175088.1232 - mean_absolute_error: 45028.4899 - val_loss: 2825899326.4605 - val_mean_absolute_error: 31285.0767\n",
      "Epoch 2744/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3392309781.0231 - mean_absolute_error: 43392.4669 - val_loss: 2819131111.3677 - val_mean_absolute_error: 30797.3379\n",
      "Epoch 2745/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3773546162.6963 - mean_absolute_error: 46722.9991 - val_loss: 2073968226.5292 - val_mean_absolute_error: 26408.2316\n",
      "Epoch 2746/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3626693010.5047 - mean_absolute_error: 45437.3343 - val_loss: 2276269060.8385 - val_mean_absolute_error: 28083.9431\n",
      "Epoch 2747/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3353129005.3311 - mean_absolute_error: 44855.7893 - val_loss: 2567644460.4261 - val_mean_absolute_error: 29517.9765\n",
      "Epoch 2748/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3577335418.4157 - mean_absolute_error: 45633.5368 - val_loss: 2452979536.0550 - val_mean_absolute_error: 28594.8438\n",
      "Epoch 2749/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3450233162.2378 - mean_absolute_error: 43768.6394 - val_loss: 4098520197.7182 - val_mean_absolute_error: 38384.1778\n",
      "Epoch 2750/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3935281970.8058 - mean_absolute_error: 46695.2515 - val_loss: 2837785846.3230 - val_mean_absolute_error: 30478.4480\n",
      "Epoch 2751/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3471655119.1651 - mean_absolute_error: 45130.7056 - val_loss: 2506332355.2990 - val_mean_absolute_error: 29815.3678\n",
      "Epoch 2752/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3776547722.1831 - mean_absolute_error: 45163.0212 - val_loss: 2306203322.0619 - val_mean_absolute_error: 28274.4889\n",
      "Epoch 2753/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3470140638.4944 - mean_absolute_error: 43864.3781 - val_loss: 2371488939.5464 - val_mean_absolute_error: 28400.6298\n",
      "Epoch 2754/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3649690849.7793 - mean_absolute_error: 45644.0290 - val_loss: 2203188478.6804 - val_mean_absolute_error: 27062.8897\n",
      "Epoch 2755/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3392746423.9521 - mean_absolute_error: 44212.7661 - val_loss: 2358090482.8041 - val_mean_absolute_error: 28530.2394\n",
      "Epoch 2756/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3517359545.0470 - mean_absolute_error: 43994.3422 - val_loss: 2038345890.7491 - val_mean_absolute_error: 26200.7433\n",
      "Epoch 2757/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 3791686807.5415 - mean_absolute_error: 46046.6132 - val_loss: 2537362985.7869 - val_mean_absolute_error: 29258.6639\n",
      "Epoch 2758/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 3518557035.5244 - mean_absolute_error: 45140.7402 - val_loss: 2659440348.8110 - val_mean_absolute_error: 29297.9333\n",
      "Epoch 2759/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3736103753.3618 - mean_absolute_error: 45128.3339 - val_loss: 2276878917.9381 - val_mean_absolute_error: 27454.7816\n",
      "Epoch 2760/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 3633952252.7151 - mean_absolute_error: 45475.5716 - val_loss: 2235196303.3952 - val_mean_absolute_error: 27835.0971\n",
      "Epoch 2761/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3232899743.2062 - mean_absolute_error: 42789.9842 - val_loss: 2722448923.2715 - val_mean_absolute_error: 30535.9884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2762/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3793391129.8409 - mean_absolute_error: 46459.6378 - val_loss: 2594664401.8144 - val_mean_absolute_error: 29934.0467\n",
      "Epoch 2763/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3446373375.5620 - mean_absolute_error: 44052.1277 - val_loss: 2702564903.1478 - val_mean_absolute_error: 30910.6159\n",
      "Epoch 2764/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3447252227.7228 - mean_absolute_error: 44110.2977 - val_loss: 2436203315.0241 - val_mean_absolute_error: 29207.1692\n",
      "Epoch 2765/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3623999895.3225 - mean_absolute_error: 45510.8261 - val_loss: 2975073809.5945 - val_mean_absolute_error: 31494.9334\n",
      "Epoch 2766/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3561780938.3473 - mean_absolute_error: 45566.4700 - val_loss: 2891812124.5911 - val_mean_absolute_error: 31684.5976\n",
      "Epoch 2767/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3414952935.4731 - mean_absolute_error: 44169.2358 - val_loss: 2360371478.8729 - val_mean_absolute_error: 28107.5082\n",
      "Epoch 2768/5000\n",
      "1169/1169 [==============================] - 1s 482us/step - loss: 3518667920.0958 - mean_absolute_error: 44751.3562 - val_loss: 2713834883.9588 - val_mean_absolute_error: 28947.1256\n",
      "Epoch 2769/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 3675332139.7981 - mean_absolute_error: 45678.3179 - val_loss: 2366231877.0584 - val_mean_absolute_error: 28102.1016\n",
      "Epoch 2770/5000\n",
      "1169/1169 [==============================] - 0s 384us/step - loss: 3638485745.3276 - mean_absolute_error: 45675.3772 - val_loss: 3174472372.3436 - val_mean_absolute_error: 33417.5966\n",
      "Epoch 2771/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3603776864.1369 - mean_absolute_error: 45181.7654 - val_loss: 2446491117.9656 - val_mean_absolute_error: 29118.4094\n",
      "Epoch 2772/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3570870567.4183 - mean_absolute_error: 44476.4826 - val_loss: 2173141748.5636 - val_mean_absolute_error: 27792.2627\n",
      "Epoch 2773/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3391936572.8794 - mean_absolute_error: 44654.8923 - val_loss: 1972937909.0034 - val_mean_absolute_error: 26885.8006\n",
      "Epoch 2774/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3641952771.0659 - mean_absolute_error: 43919.3146 - val_loss: 2727399786.8866 - val_mean_absolute_error: 31873.0438\n",
      "Epoch 2775/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3569868675.3944 - mean_absolute_error: 44543.2263 - val_loss: 2626316999.2577 - val_mean_absolute_error: 30991.5450\n",
      "Epoch 2776/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3689202137.0197 - mean_absolute_error: 45453.0582 - val_loss: 3084716256.7698 - val_mean_absolute_error: 32277.5104\n",
      "Epoch 2777/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3619034347.7434 - mean_absolute_error: 46417.1504 - val_loss: 2739125521.5945 - val_mean_absolute_error: 30820.6063\n",
      "Epoch 2778/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3899601957.6664 - mean_absolute_error: 46246.9945 - val_loss: 2551428309.7732 - val_mean_absolute_error: 29167.5972\n",
      "Epoch 2779/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3843960581.4748 - mean_absolute_error: 46059.2535 - val_loss: 2226516481.7594 - val_mean_absolute_error: 28358.7297\n",
      "Epoch 2780/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3735336750.6450 - mean_absolute_error: 44569.0589 - val_loss: 2272712144.9347 - val_mean_absolute_error: 27633.3766\n",
      "Epoch 2781/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3418921647.6305 - mean_absolute_error: 43797.2102 - val_loss: 2670071013.1684 - val_mean_absolute_error: 30085.7817\n",
      "Epoch 2782/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3374983057.1908 - mean_absolute_error: 44557.0949 - val_loss: 2179150207.1203 - val_mean_absolute_error: 27566.4907\n",
      "Epoch 2783/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3542405076.6399 - mean_absolute_error: 45339.5366 - val_loss: 2576268474.5017 - val_mean_absolute_error: 30374.2644\n",
      "Epoch 2784/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3843425265.5466 - mean_absolute_error: 45678.5320 - val_loss: 2260689411.0790 - val_mean_absolute_error: 28353.1477\n",
      "Epoch 2785/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3583964686.0154 - mean_absolute_error: 45314.0388 - val_loss: 2446618760.3574 - val_mean_absolute_error: 28912.5113\n",
      "Epoch 2786/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3313743152.3969 - mean_absolute_error: 43236.0338 - val_loss: 2527816867.6289 - val_mean_absolute_error: 29294.3271\n",
      "Epoch 2787/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3214120263.1719 - mean_absolute_error: 43429.0524 - val_loss: 2385847727.5052 - val_mean_absolute_error: 28057.0110\n",
      "Epoch 2788/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3345750591.5073 - mean_absolute_error: 44047.4843 - val_loss: 2595925694.0206 - val_mean_absolute_error: 29543.9713\n",
      "Epoch 2789/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3392726711.5141 - mean_absolute_error: 44100.9520 - val_loss: 2283178751.1203 - val_mean_absolute_error: 27820.2910\n",
      "Epoch 2790/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3232075260.4962 - mean_absolute_error: 42918.5377 - val_loss: 2829690570.7766 - val_mean_absolute_error: 31426.9124\n",
      "Epoch 2791/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3573321732.8178 - mean_absolute_error: 44201.3728 - val_loss: 2156971393.7594 - val_mean_absolute_error: 27712.3999\n",
      "Epoch 2792/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3141189522.7237 - mean_absolute_error: 43555.0994 - val_loss: 2580113034.9966 - val_mean_absolute_error: 29778.3158\n",
      "Epoch 2793/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 4079490673.8751 - mean_absolute_error: 46575.8725 - val_loss: 2278115076.3986 - val_mean_absolute_error: 28748.8200\n",
      "Epoch 2794/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3771431028.5030 - mean_absolute_error: 46579.6165 - val_loss: 2593074193.5945 - val_mean_absolute_error: 30489.1629\n",
      "Epoch 2795/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3800198017.4234 - mean_absolute_error: 46116.9967 - val_loss: 2135608459.8763 - val_mean_absolute_error: 27422.6693\n",
      "Epoch 2796/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3436004354.1899 - mean_absolute_error: 43830.1044 - val_loss: 2524855371.6564 - val_mean_absolute_error: 29201.2253\n",
      "Epoch 2797/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3593926617.4577 - mean_absolute_error: 44239.6868 - val_loss: 2350391109.9381 - val_mean_absolute_error: 28170.4795\n",
      "Epoch 2798/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3569760468.4209 - mean_absolute_error: 44590.3775 - val_loss: 2576980506.3918 - val_mean_absolute_error: 30371.7948\n",
      "Epoch 2799/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3316935168.4380 - mean_absolute_error: 43752.0075 - val_loss: 2699782696.0275 - val_mean_absolute_error: 31123.8549\n",
      "Epoch 2800/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3687074256.6980 - mean_absolute_error: 45468.9996 - val_loss: 2736237817.8419 - val_mean_absolute_error: 30403.6279\n",
      "Epoch 2801/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3210494277.8580 - mean_absolute_error: 43386.5878 - val_loss: 2554229981.2509 - val_mean_absolute_error: 29493.9679\n",
      "Epoch 2802/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3535011748.8999 - mean_absolute_error: 44581.9789 - val_loss: 2457379794.6942 - val_mean_absolute_error: 28391.9590\n",
      "Epoch 2803/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3258892892.4140 - mean_absolute_error: 43310.3513 - val_loss: 2892594873.1821 - val_mean_absolute_error: 31696.4813\n",
      "Epoch 2804/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3568363701.3242 - mean_absolute_error: 44663.9555 - val_loss: 2433296913.5945 - val_mean_absolute_error: 28740.2315\n",
      "Epoch 2805/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3463782535.7742 - mean_absolute_error: 44027.4126 - val_loss: 2642376765.1409 - val_mean_absolute_error: 30081.5062\n",
      "Epoch 2806/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3774031989.8169 - mean_absolute_error: 45251.2191 - val_loss: 2135863968.3299 - val_mean_absolute_error: 27199.3768\n",
      "Epoch 2807/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3675249942.5560 - mean_absolute_error: 45591.5348 - val_loss: 2267178537.3471 - val_mean_absolute_error: 28585.4167\n",
      "Epoch 2808/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3548130404.2977 - mean_absolute_error: 45235.8603 - val_loss: 2272946128.0550 - val_mean_absolute_error: 28524.7563\n",
      "Epoch 2809/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3589344277.4611 - mean_absolute_error: 44922.1841 - val_loss: 2395921687.3127 - val_mean_absolute_error: 29560.7614\n",
      "Epoch 2810/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3764690724.3524 - mean_absolute_error: 45625.6867 - val_loss: 2606910621.0309 - val_mean_absolute_error: 30688.6538\n",
      "Epoch 2811/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3519316722.2036 - mean_absolute_error: 44422.3823 - val_loss: 2548759312.7148 - val_mean_absolute_error: 30026.9058\n",
      "Epoch 2812/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3374116729.1018 - mean_absolute_error: 44811.3057 - val_loss: 2259491253.2234 - val_mean_absolute_error: 27893.3861\n",
      "Epoch 2813/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 3942156204.7836 - mean_absolute_error: 47474.7364 - val_loss: 2654513755.4914 - val_mean_absolute_error: 31094.6762\n",
      "Epoch 2814/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3588630754.3268 - mean_absolute_error: 45691.7650 - val_loss: 2627320450.1993 - val_mean_absolute_error: 31708.3956\n",
      "Epoch 2815/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 3812829425.6561 - mean_absolute_error: 46031.2427 - val_loss: 3096500993.7594 - val_mean_absolute_error: 33559.1972\n",
      "Epoch 2816/5000\n",
      "1169/1169 [==============================] - 1s 430us/step - loss: 3430067342.7819 - mean_absolute_error: 45246.5987 - val_loss: 2540082776.8522 - val_mean_absolute_error: 29580.5368\n",
      "Epoch 2817/5000\n",
      "1169/1169 [==============================] - 0s 381us/step - loss: 3460252009.7725 - mean_absolute_error: 44953.6021 - val_loss: 2532707314.8041 - val_mean_absolute_error: 30103.1221\n",
      "Epoch 2818/5000\n",
      "1169/1169 [==============================] - 0s 401us/step - loss: 3495620441.1292 - mean_absolute_error: 43889.1687 - val_loss: 2562436403.4639 - val_mean_absolute_error: 30053.1288\n",
      "Epoch 2819/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3632047965.5090 - mean_absolute_error: 44870.5437 - val_loss: 3375657846.7629 - val_mean_absolute_error: 34471.5404\n",
      "Epoch 2820/5000\n",
      "1169/1169 [==============================] - 1s 464us/step - loss: 3624065697.1771 - mean_absolute_error: 44778.7241 - val_loss: 2772246569.7869 - val_mean_absolute_error: 31854.2652\n",
      "Epoch 2821/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 3356399330.4363 - mean_absolute_error: 43821.0442 - val_loss: 2653644861.5808 - val_mean_absolute_error: 31522.6653\n",
      "Epoch 2822/5000\n",
      "1169/1169 [==============================] - 0s 386us/step - loss: 3898824660.6399 - mean_absolute_error: 45343.3592 - val_loss: 2120233990.5979 - val_mean_absolute_error: 28111.3075\n",
      "Epoch 2823/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 3467579527.7742 - mean_absolute_error: 44464.6580 - val_loss: 2210144762.2818 - val_mean_absolute_error: 28198.4010\n",
      "Epoch 2824/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3628114546.3131 - mean_absolute_error: 44226.2298 - val_loss: 2195870243.6289 - val_mean_absolute_error: 28045.1200\n",
      "Epoch 2825/5000\n",
      "1169/1169 [==============================] - 0s 408us/step - loss: 3369502800.1506 - mean_absolute_error: 44203.3321 - val_loss: 2417611577.6220 - val_mean_absolute_error: 28667.8158\n",
      "Epoch 2826/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3433364731.8392 - mean_absolute_error: 44512.2046 - val_loss: 2269350836.7835 - val_mean_absolute_error: 27530.9451\n",
      "Epoch 2827/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3589923346.3952 - mean_absolute_error: 45383.1939 - val_loss: 2283285248.8797 - val_mean_absolute_error: 28675.8564\n",
      "Epoch 2828/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 3275105274.7442 - mean_absolute_error: 42576.5707 - val_loss: 2330424152.4124 - val_mean_absolute_error: 28428.7558\n",
      "Epoch 2829/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3225817293.6322 - mean_absolute_error: 42751.9041 - val_loss: 1974153012.3436 - val_mean_absolute_error: 25976.1551\n",
      "Epoch 2830/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3350697385.9367 - mean_absolute_error: 43527.0153 - val_loss: 1888021075.1340 - val_mean_absolute_error: 25751.2437\n",
      "Epoch 2831/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3406090175.6168 - mean_absolute_error: 44901.1358 - val_loss: 2000453155.6289 - val_mean_absolute_error: 27296.1260\n",
      "Epoch 2832/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3174666982.3781 - mean_absolute_error: 42471.9697 - val_loss: 1858916872.3574 - val_mean_absolute_error: 25762.0518\n",
      "Epoch 2833/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3527752844.1540 - mean_absolute_error: 44565.1844 - val_loss: 2176945521.0447 - val_mean_absolute_error: 27975.6309\n",
      "Epoch 2834/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3444802044.4962 - mean_absolute_error: 44419.1816 - val_loss: 2112155515.6014 - val_mean_absolute_error: 27509.9310\n",
      "Epoch 2835/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3154138037.7622 - mean_absolute_error: 42890.8052 - val_loss: 2528714488.5223 - val_mean_absolute_error: 29940.3555\n",
      "Epoch 2836/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3234151178.2926 - mean_absolute_error: 44063.8847 - val_loss: 2447299153.8144 - val_mean_absolute_error: 29157.1153\n",
      "Epoch 2837/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3620557811.9555 - mean_absolute_error: 46112.5840 - val_loss: 2613081658.9416 - val_mean_absolute_error: 30363.6054\n",
      "Epoch 2838/5000\n",
      "1169/1169 [==============================] - 0s 319us/step - loss: 3611833584.4517 - mean_absolute_error: 45925.3831 - val_loss: 2364381380.6186 - val_mean_absolute_error: 28460.9362\n",
      "Epoch 2839/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 3587450708.9683 - mean_absolute_error: 45669.2844 - val_loss: 2171003139.0790 - val_mean_absolute_error: 27575.8636\n",
      "Epoch 2840/5000\n",
      "1169/1169 [==============================] - 0s 315us/step - loss: 3448708376.7459 - mean_absolute_error: 43885.5842 - val_loss: 1935328881.0447 - val_mean_absolute_error: 25801.8026\n",
      "Epoch 2841/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3565745292.5920 - mean_absolute_error: 44792.2594 - val_loss: 2399546847.4502 - val_mean_absolute_error: 28926.4820\n",
      "Epoch 2842/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3109717738.7579 - mean_absolute_error: 42297.3853 - val_loss: 2515116040.7973 - val_mean_absolute_error: 30081.8239\n",
      "Epoch 2843/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3700797244.6604 - mean_absolute_error: 43997.3325 - val_loss: 2804229151.6701 - val_mean_absolute_error: 31730.1480\n",
      "Epoch 2844/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 329us/step - loss: 3723210332.4140 - mean_absolute_error: 45570.4788 - val_loss: 2361346087.5876 - val_mean_absolute_error: 28967.4781\n",
      "Epoch 2845/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3322558873.0744 - mean_absolute_error: 43079.4104 - val_loss: 2490235784.3574 - val_mean_absolute_error: 30277.5556\n",
      "Epoch 2846/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3512950030.2344 - mean_absolute_error: 45070.7402 - val_loss: 2450684210.1443 - val_mean_absolute_error: 29860.8178\n",
      "Epoch 2847/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3445764911.0830 - mean_absolute_error: 43580.5244 - val_loss: 2546496076.5361 - val_mean_absolute_error: 30224.3714\n",
      "Epoch 2848/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3398961748.0924 - mean_absolute_error: 44103.9899 - val_loss: 2675580054.8729 - val_mean_absolute_error: 30920.6814\n",
      "Epoch 2849/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 3330901850.0051 - mean_absolute_error: 44530.2454 - val_loss: 2255470707.2440 - val_mean_absolute_error: 28247.0768\n",
      "Epoch 2850/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3738167488.7117 - mean_absolute_error: 44490.4188 - val_loss: 2036412367.1753 - val_mean_absolute_error: 25801.7876\n",
      "Epoch 2851/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3800079664.3969 - mean_absolute_error: 45233.7469 - val_loss: 2033538608.3849 - val_mean_absolute_error: 26387.3912\n",
      "Epoch 2852/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3595284436.2019 - mean_absolute_error: 44296.3474 - val_loss: 2090442157.7457 - val_mean_absolute_error: 27149.7511\n",
      "Epoch 2853/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3409664165.1189 - mean_absolute_error: 44040.3043 - val_loss: 2240077637.4983 - val_mean_absolute_error: 28410.1974\n",
      "Epoch 2854/5000\n",
      "1169/1169 [==============================] - 0s 327us/step - loss: 3556223545.8135 - mean_absolute_error: 45030.7077 - val_loss: 2216884127.6701 - val_mean_absolute_error: 28188.2155\n",
      "Epoch 2855/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3274377633.8340 - mean_absolute_error: 43245.4829 - val_loss: 2417427928.4124 - val_mean_absolute_error: 29531.7404\n",
      "Epoch 2856/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3690039238.6245 - mean_absolute_error: 45543.9508 - val_loss: 2560935240.5773 - val_mean_absolute_error: 30152.8431\n",
      "Epoch 2857/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3641058917.6116 - mean_absolute_error: 45011.5822 - val_loss: 2396217011.4639 - val_mean_absolute_error: 28895.7236\n",
      "Epoch 2858/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3335391504.8623 - mean_absolute_error: 43184.7780 - val_loss: 2140520850.4742 - val_mean_absolute_error: 27567.9170\n",
      "Epoch 2859/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3451381230.9187 - mean_absolute_error: 44241.8828 - val_loss: 2352011947.5464 - val_mean_absolute_error: 28630.4605\n",
      "Epoch 2860/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3652751987.6270 - mean_absolute_error: 44278.6682 - val_loss: 2802015265.4296 - val_mean_absolute_error: 31685.1536\n",
      "Epoch 2861/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3968325148.0308 - mean_absolute_error: 46454.2508 - val_loss: 2368234188.0962 - val_mean_absolute_error: 28952.8395\n",
      "Epoch 2862/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 3436983568.3148 - mean_absolute_error: 43722.6003 - val_loss: 2371142538.1168 - val_mean_absolute_error: 29107.4356\n",
      "Epoch 2863/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 3468378418.5868 - mean_absolute_error: 44286.9664 - val_loss: 2059182953.1271 - val_mean_absolute_error: 27009.7443\n",
      "Epoch 2864/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3459511495.7194 - mean_absolute_error: 44049.5038 - val_loss: 2227717382.1581 - val_mean_absolute_error: 28201.3084\n",
      "Epoch 2865/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3486805162.3747 - mean_absolute_error: 43935.7039 - val_loss: 2740026932.3436 - val_mean_absolute_error: 31722.2863\n",
      "Epoch 2866/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 3679752246.7476 - mean_absolute_error: 45935.0217 - val_loss: 2871778672.1649 - val_mean_absolute_error: 31789.1937\n",
      "Epoch 2867/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3966448926.8777 - mean_absolute_error: 46742.0347 - val_loss: 2214428447.6701 - val_mean_absolute_error: 28304.4385\n",
      "Epoch 2868/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 3710065727.2883 - mean_absolute_error: 45760.4524 - val_loss: 2458346064.4948 - val_mean_absolute_error: 29590.0373\n",
      "Epoch 2869/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 3737444069.9401 - mean_absolute_error: 45735.2409 - val_loss: 2042351327.4502 - val_mean_absolute_error: 27027.5224\n",
      "Epoch 2870/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3681938548.5030 - mean_absolute_error: 46130.1001 - val_loss: 2566723036.3711 - val_mean_absolute_error: 29364.5133\n",
      "Epoch 2871/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3333132812.7015 - mean_absolute_error: 43760.8326 - val_loss: 2453644117.3333 - val_mean_absolute_error: 29711.1368\n",
      "Epoch 2872/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3652334415.9316 - mean_absolute_error: 46015.6874 - val_loss: 2415604221.3608 - val_mean_absolute_error: 29330.5942\n",
      "Epoch 2873/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3789880013.4132 - mean_absolute_error: 46070.4067 - val_loss: 2115276547.9588 - val_mean_absolute_error: 27556.3259\n",
      "Epoch 2874/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3562719659.9076 - mean_absolute_error: 44737.5520 - val_loss: 2362314987.3265 - val_mean_absolute_error: 28778.7691\n",
      "Epoch 2875/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3527201086.8503 - mean_absolute_error: 45705.4904 - val_loss: 2680196762.3918 - val_mean_absolute_error: 31038.4546\n",
      "Epoch 2876/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3572356563.1069 - mean_absolute_error: 45438.4508 - val_loss: 2305207804.9210 - val_mean_absolute_error: 28935.8502\n",
      "Epoch 2877/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3462009657.5945 - mean_absolute_error: 44764.4416 - val_loss: 2142161417.6770 - val_mean_absolute_error: 26768.1607\n",
      "Epoch 2878/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 3765122306.1899 - mean_absolute_error: 45575.8032 - val_loss: 2654873469.8007 - val_mean_absolute_error: 29850.1224\n",
      "Epoch 2879/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3250401376.1369 - mean_absolute_error: 43829.3312 - val_loss: 2600845653.7732 - val_mean_absolute_error: 30049.1003\n",
      "Epoch 2880/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3708265136.8349 - mean_absolute_error: 45148.4466 - val_loss: 1832624682.6667 - val_mean_absolute_error: 25354.4050\n",
      "Epoch 2881/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3594147473.1908 - mean_absolute_error: 45426.2104 - val_loss: 1936095013.8282 - val_mean_absolute_error: 25798.1677\n",
      "Epoch 2882/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3377248750.9187 - mean_absolute_error: 44094.1816 - val_loss: 2500858623.5601 - val_mean_absolute_error: 26857.5589\n",
      "Epoch 2883/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3618346117.3653 - mean_absolute_error: 45492.7660 - val_loss: 2340175534.6254 - val_mean_absolute_error: 28295.6088\n",
      "Epoch 2884/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3696386136.4722 - mean_absolute_error: 45606.3760 - val_loss: 2463083562.2268 - val_mean_absolute_error: 29761.5063\n",
      "Epoch 2885/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3675594604.8383 - mean_absolute_error: 45891.8744 - val_loss: 3317505519.2852 - val_mean_absolute_error: 34723.9001\n",
      "Epoch 2886/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3687699991.4320 - mean_absolute_error: 45440.7226 - val_loss: 2776749663.0103 - val_mean_absolute_error: 31553.4866\n",
      "Epoch 2887/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3862367863.5689 - mean_absolute_error: 44679.6800 - val_loss: 2703090489.1821 - val_mean_absolute_error: 31003.8405\n",
      "Epoch 2888/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3408646240.5749 - mean_absolute_error: 43011.9588 - val_loss: 2748363812.9485 - val_mean_absolute_error: 31499.5707\n",
      "Epoch 2889/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3627618897.2455 - mean_absolute_error: 45580.5059 - val_loss: 2264464670.3505 - val_mean_absolute_error: 27640.4243\n",
      "Epoch 2890/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3328852697.8956 - mean_absolute_error: 43171.6052 - val_loss: 2228263924.5636 - val_mean_absolute_error: 27503.7475\n",
      "Epoch 2891/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3434675178.9769 - mean_absolute_error: 44006.2011 - val_loss: 2418171475.5739 - val_mean_absolute_error: 28494.8823\n",
      "Epoch 2892/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3240606905.4850 - mean_absolute_error: 43400.1735 - val_loss: 2779736772.6186 - val_mean_absolute_error: 31203.9108\n",
      "Epoch 2893/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3128815831.4867 - mean_absolute_error: 42697.5763 - val_loss: 2880695358.4605 - val_mean_absolute_error: 32022.6997\n",
      "Epoch 2894/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3374859035.8118 - mean_absolute_error: 43809.5777 - val_loss: 2685417053.6907 - val_mean_absolute_error: 31058.6661\n",
      "Epoch 2895/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3462902486.6108 - mean_absolute_error: 44159.9898 - val_loss: 2911215853.5258 - val_mean_absolute_error: 32023.9291\n",
      "Epoch 2896/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3987216417.0676 - mean_absolute_error: 47143.1057 - val_loss: 2594104450.6392 - val_mean_absolute_error: 28561.7836\n",
      "Epoch 2897/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3442092050.2857 - mean_absolute_error: 44525.2593 - val_loss: 2465798807.7526 - val_mean_absolute_error: 28895.2395\n",
      "Epoch 2898/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3568927821.5227 - mean_absolute_error: 45456.1936 - val_loss: 2567446797.1959 - val_mean_absolute_error: 30853.9936\n",
      "Epoch 2899/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 3765744155.3738 - mean_absolute_error: 45116.4092 - val_loss: 2909434365.3608 - val_mean_absolute_error: 32561.4272\n",
      "Epoch 2900/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3423880412.3045 - mean_absolute_error: 43538.7224 - val_loss: 2987690283.1065 - val_mean_absolute_error: 32513.3516\n",
      "Epoch 2901/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3271938538.5389 - mean_absolute_error: 42644.5175 - val_loss: 2839814108.8110 - val_mean_absolute_error: 31449.7472\n",
      "Epoch 2902/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3628650799.5210 - mean_absolute_error: 45407.6428 - val_loss: 2300082913.6495 - val_mean_absolute_error: 27471.5050\n",
      "Epoch 2903/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3457521101.8512 - mean_absolute_error: 44051.4089 - val_loss: 2625670443.9863 - val_mean_absolute_error: 30331.0039\n",
      "Epoch 2904/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3695235198.1386 - mean_absolute_error: 46021.9113 - val_loss: 2668818666.8866 - val_mean_absolute_error: 30713.0417\n",
      "Epoch 2905/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3529710242.9290 - mean_absolute_error: 44657.5321 - val_loss: 2898236100.1787 - val_mean_absolute_error: 32307.7606\n",
      "Epoch 2906/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3531618037.0505 - mean_absolute_error: 45317.6853 - val_loss: 2613408910.9553 - val_mean_absolute_error: 30972.1213\n",
      "Epoch 2907/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3432248988.3593 - mean_absolute_error: 44028.2279 - val_loss: 2897878771.6838 - val_mean_absolute_error: 32406.2263\n",
      "Epoch 2908/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3285216895.4525 - mean_absolute_error: 43301.8469 - val_loss: 2412659507.4639 - val_mean_absolute_error: 29370.5487\n",
      "Epoch 2909/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3545011369.4987 - mean_absolute_error: 45323.4452 - val_loss: 2646385885.6907 - val_mean_absolute_error: 30363.1545\n",
      "Epoch 2910/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3515358307.4217 - mean_absolute_error: 44219.1356 - val_loss: 3516880745.5670 - val_mean_absolute_error: 34336.0074\n",
      "Epoch 2911/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3208084565.4063 - mean_absolute_error: 42785.3822 - val_loss: 2527203905.9794 - val_mean_absolute_error: 28641.8538\n",
      "Epoch 2912/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3337829923.0385 - mean_absolute_error: 43512.3914 - val_loss: 2193674536.4674 - val_mean_absolute_error: 27223.5498\n",
      "Epoch 2913/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3233132288.8760 - mean_absolute_error: 42628.9965 - val_loss: 2412599398.4880 - val_mean_absolute_error: 27958.6047\n",
      "Epoch 2914/5000\n",
      "1169/1169 [==============================] - 0s 374us/step - loss: 3492614751.2609 - mean_absolute_error: 44864.7206 - val_loss: 2770549533.9107 - val_mean_absolute_error: 30476.4723\n",
      "Epoch 2915/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3592942325.2695 - mean_absolute_error: 44470.0014 - val_loss: 2511738358.7629 - val_mean_absolute_error: 28971.7910\n",
      "Epoch 2916/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3861546717.8375 - mean_absolute_error: 46490.1354 - val_loss: 2721923288.4124 - val_mean_absolute_error: 30726.1630\n",
      "Epoch 2917/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3427541414.2139 - mean_absolute_error: 43226.2374 - val_loss: 3108605710.0756 - val_mean_absolute_error: 32727.1080\n",
      "Epoch 2918/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3234101730.2173 - mean_absolute_error: 44045.3239 - val_loss: 2888174984.7973 - val_mean_absolute_error: 31620.6572\n",
      "Epoch 2919/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3372032247.2404 - mean_absolute_error: 44331.3286 - val_loss: 2682270533.9381 - val_mean_absolute_error: 30072.1395\n",
      "Epoch 2920/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3408473709.4953 - mean_absolute_error: 43025.0314 - val_loss: 2845222195.4639 - val_mean_absolute_error: 31135.2379\n",
      "Epoch 2921/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3757402503.1172 - mean_absolute_error: 45717.3994 - val_loss: 2453830492.8110 - val_mean_absolute_error: 28813.3754\n",
      "Epoch 2922/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3749749100.2908 - mean_absolute_error: 45698.1329 - val_loss: 2406137038.7354 - val_mean_absolute_error: 29096.9463\n",
      "Epoch 2923/5000\n",
      "1169/1169 [==============================] - ETA: 0s - loss: 3837417344.0000 - mean_absolute_error: 45826.13 - 0s 357us/step - loss: 3860676850.2036 - mean_absolute_error: 46096.8698 - val_loss: 2778888830.6804 - val_mean_absolute_error: 31445.7066\n",
      "Epoch 2924/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 3106720676.8999 - mean_absolute_error: 42011.1372 - val_loss: 3292062813.2509 - val_mean_absolute_error: 34531.2965\n",
      "Epoch 2925/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3462247254.5013 - mean_absolute_error: 44885.3977 - val_loss: 2711763125.2234 - val_mean_absolute_error: 31054.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2926/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3662509555.5175 - mean_absolute_error: 45308.9709 - val_loss: 3057804650.4467 - val_mean_absolute_error: 32747.5550\n",
      "Epoch 2927/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3607337179.4286 - mean_absolute_error: 45143.0060 - val_loss: 2366682860.6460 - val_mean_absolute_error: 28149.8470\n",
      "Epoch 2928/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3589351014.7066 - mean_absolute_error: 44776.2074 - val_loss: 2569393549.6357 - val_mean_absolute_error: 29468.7624\n",
      "Epoch 2929/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3615861663.8631 - mean_absolute_error: 44841.6527 - val_loss: 2059763406.2955 - val_mean_absolute_error: 26246.2826\n",
      "Epoch 2930/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3605948168.9786 - mean_absolute_error: 45122.2446 - val_loss: 2449294391.4227 - val_mean_absolute_error: 28814.8988\n",
      "Epoch 2931/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3487422511.9589 - mean_absolute_error: 45270.8756 - val_loss: 2598397566.6804 - val_mean_absolute_error: 30054.3692\n",
      "Epoch 2932/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3636177716.9957 - mean_absolute_error: 45406.5257 - val_loss: 2348950148.8385 - val_mean_absolute_error: 28601.4972\n",
      "Epoch 2933/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3135368829.7006 - mean_absolute_error: 43045.3995 - val_loss: 1922793210.7216 - val_mean_absolute_error: 25343.5764\n",
      "Epoch 2934/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3452213705.9093 - mean_absolute_error: 44397.0658 - val_loss: 2488511725.5258 - val_mean_absolute_error: 29488.4166\n",
      "Epoch 2935/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3483821972.2566 - mean_absolute_error: 44911.9575 - val_loss: 2476639062.2131 - val_mean_absolute_error: 28887.8478\n",
      "Epoch 2936/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3185898491.5107 - mean_absolute_error: 42582.9966 - val_loss: 2327723494.9278 - val_mean_absolute_error: 28829.1978\n",
      "Epoch 2937/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3000973462.5560 - mean_absolute_error: 40855.0733 - val_loss: 2362306060.3162 - val_mean_absolute_error: 28871.3745\n",
      "Epoch 2938/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3665265123.6407 - mean_absolute_error: 45323.0696 - val_loss: 2378802600.0275 - val_mean_absolute_error: 28746.6703\n",
      "Epoch 2939/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3260866974.1112 - mean_absolute_error: 43812.2705 - val_loss: 2221302517.8832 - val_mean_absolute_error: 28350.3129\n",
      "Epoch 2940/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3292537414.7340 - mean_absolute_error: 43811.3768 - val_loss: 2631361053.0309 - val_mean_absolute_error: 30325.4003\n",
      "Epoch 2941/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3591911795.6270 - mean_absolute_error: 45620.6236 - val_loss: 2328057358.5155 - val_mean_absolute_error: 29101.7901\n",
      "Epoch 2942/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3226807534.6997 - mean_absolute_error: 44359.5213 - val_loss: 2308494082.1993 - val_mean_absolute_error: 28853.8329\n",
      "Epoch 2943/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3344921898.0462 - mean_absolute_error: 44061.5458 - val_loss: 1964007723.1065 - val_mean_absolute_error: 26038.0732\n",
      "Epoch 2944/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3243948207.8494 - mean_absolute_error: 41543.6404 - val_loss: 2628787276.5361 - val_mean_absolute_error: 30274.0312\n",
      "Epoch 2945/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3668595595.0590 - mean_absolute_error: 44656.4011 - val_loss: 2703083132.9210 - val_mean_absolute_error: 29795.6231\n",
      "Epoch 2946/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3314905554.8879 - mean_absolute_error: 43316.6584 - val_loss: 2993256156.8110 - val_mean_absolute_error: 31667.1976\n",
      "Epoch 2947/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3548205724.3593 - mean_absolute_error: 45268.1409 - val_loss: 2675956982.7629 - val_mean_absolute_error: 30660.0857\n",
      "Epoch 2948/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3841428958.7134 - mean_absolute_error: 45478.4261 - val_loss: 2966186057.0172 - val_mean_absolute_error: 31976.8759\n",
      "Epoch 2949/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3525588590.5902 - mean_absolute_error: 44704.9775 - val_loss: 2375421968.7148 - val_mean_absolute_error: 29273.7507\n",
      "Epoch 2950/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3326961723.1275 - mean_absolute_error: 43792.7086 - val_loss: 2341678513.7045 - val_mean_absolute_error: 29500.0048\n",
      "Epoch 2951/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3661702903.2404 - mean_absolute_error: 46409.3687 - val_loss: 2407914664.9072 - val_mean_absolute_error: 29042.4923\n",
      "Epoch 2952/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 3549918134.2002 - mean_absolute_error: 44918.2535 - val_loss: 1907335077.3883 - val_mean_absolute_error: 25980.7568\n",
      "Epoch 2953/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3720265067.0864 - mean_absolute_error: 45068.8816 - val_loss: 2435429076.0137 - val_mean_absolute_error: 29037.9443\n",
      "Epoch 2954/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3545663848.2395 - mean_absolute_error: 44299.7109 - val_loss: 2273934196.1237 - val_mean_absolute_error: 27925.9669\n",
      "Epoch 2955/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3389700484.0513 - mean_absolute_error: 43591.0893 - val_loss: 2756209364.0137 - val_mean_absolute_error: 31109.5235\n",
      "Epoch 2956/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3614558972.7151 - mean_absolute_error: 44011.1812 - val_loss: 2020311822.9553 - val_mean_absolute_error: 26157.7605\n",
      "Epoch 2957/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3715616667.2643 - mean_absolute_error: 45117.8528 - val_loss: 2612108302.5155 - val_mean_absolute_error: 30211.0011\n",
      "Epoch 2958/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 3612213755.9487 - mean_absolute_error: 45062.3505 - val_loss: 2278292685.4158 - val_mean_absolute_error: 27751.9261\n",
      "Epoch 2959/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3563751854.9735 - mean_absolute_error: 44694.0347 - val_loss: 2248959810.4192 - val_mean_absolute_error: 26367.3935\n",
      "Epoch 2960/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3318110861.9059 - mean_absolute_error: 44064.1923 - val_loss: 2396183641.7320 - val_mean_absolute_error: 29460.6089\n",
      "Epoch 2961/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3551457906.7511 - mean_absolute_error: 45255.2129 - val_loss: 2450157057.3196 - val_mean_absolute_error: 29367.3086\n",
      "Epoch 2962/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3442916253.4542 - mean_absolute_error: 44752.7191 - val_loss: 2471587046.4880 - val_mean_absolute_error: 29292.2232\n",
      "Epoch 2963/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3535323858.6689 - mean_absolute_error: 43788.5989 - val_loss: 2587080019.1340 - val_mean_absolute_error: 30415.4075\n",
      "Epoch 2964/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3435014214.5150 - mean_absolute_error: 44473.9766 - val_loss: 2208082814.2406 - val_mean_absolute_error: 27723.3339\n",
      "Epoch 2965/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 3302170143.0967 - mean_absolute_error: 44435.0399 - val_loss: 2054165511.0378 - val_mean_absolute_error: 26580.2736\n",
      "Epoch 2966/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 3526335439.4936 - mean_absolute_error: 45181.9408 - val_loss: 2915490258.2543 - val_mean_absolute_error: 32409.7498\n",
      "Epoch 2967/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3596771412.0924 - mean_absolute_error: 45144.9377 - val_loss: 2439643359.4502 - val_mean_absolute_error: 29949.5419\n",
      "Epoch 2968/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3499211376.5612 - mean_absolute_error: 44333.1342 - val_loss: 2220193756.8110 - val_mean_absolute_error: 28081.4039\n",
      "Epoch 2969/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3469543475.6818 - mean_absolute_error: 44543.3134 - val_loss: 2201904610.0893 - val_mean_absolute_error: 28039.1159\n",
      "Epoch 2970/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3344955367.6920 - mean_absolute_error: 44032.0301 - val_loss: 2321326235.7113 - val_mean_absolute_error: 28256.0544\n",
      "Epoch 2971/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3399976125.6459 - mean_absolute_error: 44646.9764 - val_loss: 2218241587.0241 - val_mean_absolute_error: 28248.7369\n",
      "Epoch 2972/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3310738786.5458 - mean_absolute_error: 43478.0578 - val_loss: 2280616878.6254 - val_mean_absolute_error: 29207.9533\n",
      "Epoch 2973/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3591886224.3148 - mean_absolute_error: 45140.2858 - val_loss: 2228236971.9863 - val_mean_absolute_error: 28920.5554\n",
      "Epoch 2974/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3418083026.6689 - mean_absolute_error: 44093.7201 - val_loss: 2384659023.6151 - val_mean_absolute_error: 29727.1945\n",
      "Epoch 2975/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3337462130.9701 - mean_absolute_error: 42983.5954 - val_loss: 2128639751.9175 - val_mean_absolute_error: 26670.5776\n",
      "Epoch 2976/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3627082755.9418 - mean_absolute_error: 43785.6988 - val_loss: 2140319018.6667 - val_mean_absolute_error: 27242.0630\n",
      "Epoch 2977/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3540708519.0898 - mean_absolute_error: 43643.3127 - val_loss: 2164288835.7388 - val_mean_absolute_error: 27544.3205\n",
      "Epoch 2978/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3247155601.1908 - mean_absolute_error: 43155.1411 - val_loss: 2358467053.5258 - val_mean_absolute_error: 28890.9115\n",
      "Epoch 2979/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3427881295.9316 - mean_absolute_error: 44235.8180 - val_loss: 2696004085.0034 - val_mean_absolute_error: 30557.2075\n",
      "Epoch 2980/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3528902122.5389 - mean_absolute_error: 44302.4217 - val_loss: 2794338724.5086 - val_mean_absolute_error: 30701.6986\n",
      "Epoch 2981/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3904275930.1146 - mean_absolute_error: 46250.4623 - val_loss: 2551058938.2818 - val_mean_absolute_error: 29463.3450\n",
      "Epoch 2982/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 3809793331.4628 - mean_absolute_error: 46324.6364 - val_loss: 2451887335.8076 - val_mean_absolute_error: 29529.1628\n",
      "Epoch 2983/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3904714847.4799 - mean_absolute_error: 47290.9450 - val_loss: 2047268110.0756 - val_mean_absolute_error: 26836.5386\n",
      "Epoch 2984/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3414213800.6228 - mean_absolute_error: 44369.6511 - val_loss: 2710096554.2268 - val_mean_absolute_error: 30547.3285\n",
      "Epoch 2985/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3860318338.0804 - mean_absolute_error: 46261.6919 - val_loss: 2873331492.0687 - val_mean_absolute_error: 31695.5166\n",
      "Epoch 2986/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3772393262.6450 - mean_absolute_error: 46186.6090 - val_loss: 2110440422.0481 - val_mean_absolute_error: 27330.9658\n",
      "Epoch 2987/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3487160273.3550 - mean_absolute_error: 45289.7552 - val_loss: 2057697915.1615 - val_mean_absolute_error: 26963.4556\n",
      "Epoch 2988/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3766451803.9760 - mean_absolute_error: 44712.5352 - val_loss: 2439354121.2371 - val_mean_absolute_error: 29721.6336\n",
      "Epoch 2989/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3632467714.4089 - mean_absolute_error: 44871.9304 - val_loss: 2634802220.8660 - val_mean_absolute_error: 30246.8741\n",
      "Epoch 2990/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3857367354.2515 - mean_absolute_error: 45513.7879 - val_loss: 2919867359.8900 - val_mean_absolute_error: 31846.6971\n",
      "Epoch 2991/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3503424743.6920 - mean_absolute_error: 44842.5742 - val_loss: 2607444652.8660 - val_mean_absolute_error: 30533.8376\n",
      "Epoch 2992/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3619011424.1369 - mean_absolute_error: 44982.7596 - val_loss: 2515506957.1959 - val_mean_absolute_error: 29765.0979\n",
      "Epoch 2993/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3629113719.7879 - mean_absolute_error: 45562.2468 - val_loss: 2730133280.5498 - val_mean_absolute_error: 31320.0914\n",
      "Epoch 2994/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3473268536.2806 - mean_absolute_error: 44381.6737 - val_loss: 2672667125.0034 - val_mean_absolute_error: 30606.9852\n",
      "Epoch 2995/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3333416527.9316 - mean_absolute_error: 43550.6469 - val_loss: 2535371494.0481 - val_mean_absolute_error: 29898.3372\n",
      "Epoch 2996/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3313667095.6510 - mean_absolute_error: 43443.1963 - val_loss: 2224993290.1168 - val_mean_absolute_error: 28457.7595\n",
      "Epoch 2997/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3645478162.6142 - mean_absolute_error: 44840.5394 - val_loss: 2476439883.2165 - val_mean_absolute_error: 30129.2855\n",
      "Epoch 2998/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3841498738.5321 - mean_absolute_error: 45079.7450 - val_loss: 2761615868.9210 - val_mean_absolute_error: 31608.6041\n",
      "Epoch 2999/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3704070308.2429 - mean_absolute_error: 44459.2007 - val_loss: 2927551033.1821 - val_mean_absolute_error: 32754.6077\n",
      "Epoch 3000/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3421165857.7246 - mean_absolute_error: 44454.5745 - val_loss: 2469464387.7388 - val_mean_absolute_error: 29872.5348\n",
      "Epoch 3001/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 3387083296.8486 - mean_absolute_error: 43850.5536 - val_loss: 2351662362.8316 - val_mean_absolute_error: 29003.7589\n",
      "Epoch 3002/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3460829002.6758 - mean_absolute_error: 44124.0423 - val_loss: 2633392785.5945 - val_mean_absolute_error: 30324.6045\n",
      "Epoch 3003/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3570298198.2823 - mean_absolute_error: 45795.7551 - val_loss: 2153387432.4674 - val_mean_absolute_error: 26573.5502\n",
      "Epoch 3004/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3715613142.3918 - mean_absolute_error: 44554.7587 - val_loss: 2725559969.8694 - val_mean_absolute_error: 30112.2339\n",
      "Epoch 3005/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3526555593.4713 - mean_absolute_error: 43004.1641 - val_loss: 2429233100.0962 - val_mean_absolute_error: 28880.5651\n",
      "Epoch 3006/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3647390710.3644 - mean_absolute_error: 44883.3642 - val_loss: 2553768525.4158 - val_mean_absolute_error: 29599.6587\n",
      "Epoch 3007/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3215926459.8939 - mean_absolute_error: 43839.6514 - val_loss: 2190551674.7216 - val_mean_absolute_error: 26985.8922\n",
      "Epoch 3008/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 370us/step - loss: 3720491145.0881 - mean_absolute_error: 45213.6759 - val_loss: 2438384743.8076 - val_mean_absolute_error: 28769.3600\n",
      "Epoch 3009/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 3433016770.4636 - mean_absolute_error: 44450.9266 - val_loss: 2661643297.4296 - val_mean_absolute_error: 31300.6803\n",
      "Epoch 3010/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3873081697.4508 - mean_absolute_error: 46312.4599 - val_loss: 2393996740.1787 - val_mean_absolute_error: 28286.3207\n",
      "Epoch 3011/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3640957275.7571 - mean_absolute_error: 46536.4085 - val_loss: 2231046527.1203 - val_mean_absolute_error: 26879.1300\n",
      "Epoch 3012/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3506718775.1856 - mean_absolute_error: 45143.5197 - val_loss: 2284013118.9003 - val_mean_absolute_error: 27901.0319\n",
      "Epoch 3013/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3662129885.8375 - mean_absolute_error: 44597.3174 - val_loss: 2362362926.6254 - val_mean_absolute_error: 29392.8514\n",
      "Epoch 3014/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3435082570.6758 - mean_absolute_error: 44356.7449 - val_loss: 2017428629.9931 - val_mean_absolute_error: 26491.2948\n",
      "Epoch 3015/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3388530511.2746 - mean_absolute_error: 44249.0463 - val_loss: 2273150418.6942 - val_mean_absolute_error: 27479.4285\n",
      "Epoch 3016/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3564816979.3259 - mean_absolute_error: 44868.3807 - val_loss: 2378444527.2852 - val_mean_absolute_error: 28574.6459\n",
      "Epoch 3017/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3219248505.3208 - mean_absolute_error: 42451.4838 - val_loss: 2378122153.7869 - val_mean_absolute_error: 27954.3901\n",
      "Epoch 3018/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3570130950.5697 - mean_absolute_error: 45520.1226 - val_loss: 2538900606.6804 - val_mean_absolute_error: 30120.8659\n",
      "Epoch 3019/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3137780570.7716 - mean_absolute_error: 42702.7205 - val_loss: 2720967656.6873 - val_mean_absolute_error: 31055.3913\n",
      "Epoch 3020/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3085355481.2387 - mean_absolute_error: 41696.0942 - val_loss: 3272692514.3093 - val_mean_absolute_error: 32822.9202\n",
      "Epoch 3021/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3134163495.4183 - mean_absolute_error: 42723.3592 - val_loss: 2411202773.3333 - val_mean_absolute_error: 28954.9361\n",
      "Epoch 3022/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 3641336968.4311 - mean_absolute_error: 45341.2361 - val_loss: 2604447230.6804 - val_mean_absolute_error: 30357.2503\n",
      "Epoch 3023/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3351106398.3849 - mean_absolute_error: 43953.8925 - val_loss: 2383508589.9656 - val_mean_absolute_error: 29064.4813\n",
      "Epoch 3024/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 3800256071.3909 - mean_absolute_error: 46127.4961 - val_loss: 2930125389.8557 - val_mean_absolute_error: 32102.2801\n",
      "Epoch 3025/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3019149963.2780 - mean_absolute_error: 41010.6348 - val_loss: 2644551282.3643 - val_mean_absolute_error: 30206.4551\n",
      "Epoch 3026/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3593532138.3199 - mean_absolute_error: 44594.6985 - val_loss: 2774271959.9725 - val_mean_absolute_error: 29930.0832\n",
      "Epoch 3027/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3532182187.9076 - mean_absolute_error: 44305.4689 - val_loss: 2766140032.0000 - val_mean_absolute_error: 29454.9442\n",
      "Epoch 3028/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3411053136.1506 - mean_absolute_error: 43610.3381 - val_loss: 2614202207.0103 - val_mean_absolute_error: 30028.2502\n",
      "Epoch 3029/5000\n",
      "1169/1169 [==============================] - 0s 391us/step - loss: 3452478251.7981 - mean_absolute_error: 45187.3325 - val_loss: 2930499568.6048 - val_mean_absolute_error: 31869.0160\n",
      "Epoch 3030/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3626379474.4500 - mean_absolute_error: 44127.4665 - val_loss: 3049996077.7457 - val_mean_absolute_error: 33101.6544\n",
      "Epoch 3031/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3267088904.7596 - mean_absolute_error: 42878.2205 - val_loss: 2574459234.0893 - val_mean_absolute_error: 30123.6421\n",
      "Epoch 3032/5000\n",
      "1169/1169 [==============================] - 0s 423us/step - loss: 3553982200.5543 - mean_absolute_error: 43509.1837 - val_loss: 2766337312.1100 - val_mean_absolute_error: 30386.2464\n",
      "Epoch 3033/5000\n",
      "1169/1169 [==============================] - 0s 421us/step - loss: 3059399086.5355 - mean_absolute_error: 40871.4497 - val_loss: 2587634004.8935 - val_mean_absolute_error: 29620.8035\n",
      "Epoch 3034/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 3120703959.2678 - mean_absolute_error: 42276.7510 - val_loss: 2902890602.8866 - val_mean_absolute_error: 31486.1795\n",
      "Epoch 3035/5000\n",
      "1169/1169 [==============================] - 0s 378us/step - loss: 3161185552.8623 - mean_absolute_error: 41781.3956 - val_loss: 2659884847.0653 - val_mean_absolute_error: 30689.5828\n",
      "Epoch 3036/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 3351627339.7707 - mean_absolute_error: 43658.3510 - val_loss: 2952287698.2543 - val_mean_absolute_error: 32356.0602\n",
      "Epoch 3037/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3279956435.3259 - mean_absolute_error: 42197.0990 - val_loss: 3094693458.6942 - val_mean_absolute_error: 32232.2903\n",
      "Epoch 3038/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3244628981.9264 - mean_absolute_error: 42376.4608 - val_loss: 2616298496.4399 - val_mean_absolute_error: 29640.0515\n",
      "Epoch 3039/5000\n",
      "1169/1169 [==============================] - 0s 419us/step - loss: 3277729971.1343 - mean_absolute_error: 42639.7573 - val_loss: 2585474627.2990 - val_mean_absolute_error: 29893.0812\n",
      "Epoch 3040/5000\n",
      "1169/1169 [==============================] - 0s 383us/step - loss: 3141645252.0513 - mean_absolute_error: 42148.9631 - val_loss: 2619641184.7698 - val_mean_absolute_error: 30016.8614\n",
      "Epoch 3041/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3119055614.9050 - mean_absolute_error: 41870.0335 - val_loss: 2868820831.0103 - val_mean_absolute_error: 31314.4468\n",
      "Epoch 3042/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3136776301.2763 - mean_absolute_error: 41639.8849 - val_loss: 2525920695.4227 - val_mean_absolute_error: 29338.6969\n",
      "Epoch 3043/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3148413693.8101 - mean_absolute_error: 41838.7018 - val_loss: 2870438715.8213 - val_mean_absolute_error: 31417.4857\n",
      "Epoch 3044/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3803024119.4594 - mean_absolute_error: 44548.7257 - val_loss: 2601080373.6632 - val_mean_absolute_error: 29502.6995\n",
      "Epoch 3045/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3351452571.2643 - mean_absolute_error: 43032.3445 - val_loss: 2354780274.3643 - val_mean_absolute_error: 28349.3451\n",
      "Epoch 3046/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3384928983.4867 - mean_absolute_error: 43292.3217 - val_loss: 2930850464.5498 - val_mean_absolute_error: 32243.0746\n",
      "Epoch 3047/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3225767694.2344 - mean_absolute_error: 42179.0408 - val_loss: 2542321832.4674 - val_mean_absolute_error: 29972.6020\n",
      "Epoch 3048/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3482694443.5791 - mean_absolute_error: 43152.4239 - val_loss: 2997245943.6426 - val_mean_absolute_error: 31527.9166\n",
      "Epoch 3049/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3493055170.0257 - mean_absolute_error: 43655.7397 - val_loss: 2093614361.9519 - val_mean_absolute_error: 26839.9270\n",
      "Epoch 3050/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3242663667.9555 - mean_absolute_error: 42320.7811 - val_loss: 2259011074.1993 - val_mean_absolute_error: 27355.0945\n",
      "Epoch 3051/5000\n",
      "1169/1169 [==============================] - 0s 329us/step - loss: 3366707757.3311 - mean_absolute_error: 42298.1179 - val_loss: 2311166148.1787 - val_mean_absolute_error: 28086.2141\n",
      "Epoch 3052/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3395030674.2857 - mean_absolute_error: 41767.5753 - val_loss: 2586463490.6392 - val_mean_absolute_error: 29500.5332\n",
      "Epoch 3053/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3034071950.3439 - mean_absolute_error: 41318.9084 - val_loss: 2373860015.9450 - val_mean_absolute_error: 27917.4794\n",
      "Epoch 3054/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3260132584.1300 - mean_absolute_error: 42448.4520 - val_loss: 2801744750.4055 - val_mean_absolute_error: 30601.8986\n",
      "Epoch 3055/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3151042395.9760 - mean_absolute_error: 41236.6111 - val_loss: 2437205701.0584 - val_mean_absolute_error: 27327.5757\n",
      "Epoch 3056/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3214193130.7579 - mean_absolute_error: 41904.5634 - val_loss: 2404926489.9519 - val_mean_absolute_error: 28104.4180\n",
      "Epoch 3057/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 2948111580.0855 - mean_absolute_error: 40178.7997 - val_loss: 2690279403.7663 - val_mean_absolute_error: 29820.7612\n",
      "Epoch 3058/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 3562492176.8623 - mean_absolute_error: 44193.4908 - val_loss: 2745130090.8866 - val_mean_absolute_error: 30641.8051\n",
      "Epoch 3059/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3189047704.1985 - mean_absolute_error: 42701.4583 - val_loss: 2316728703.5601 - val_mean_absolute_error: 27163.3957\n",
      "Epoch 3060/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3169298402.2173 - mean_absolute_error: 41693.2361 - val_loss: 2608463377.1546 - val_mean_absolute_error: 28795.1873\n",
      "Epoch 3061/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3375928605.1257 - mean_absolute_error: 42712.5323 - val_loss: 2687363025.3746 - val_mean_absolute_error: 29665.3180\n",
      "Epoch 3062/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3435456532.3661 - mean_absolute_error: 41755.2054 - val_loss: 2606070662.5979 - val_mean_absolute_error: 28587.3735\n",
      "Epoch 3063/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3064429413.8306 - mean_absolute_error: 41025.4771 - val_loss: 2764765381.0584 - val_mean_absolute_error: 29788.7267\n",
      "Epoch 3064/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3316419910.7340 - mean_absolute_error: 42504.6671 - val_loss: 2981228411.6014 - val_mean_absolute_error: 30100.2802\n",
      "Epoch 3065/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3245004390.2686 - mean_absolute_error: 41818.2920 - val_loss: 2164623881.6770 - val_mean_absolute_error: 25684.0548\n",
      "Epoch 3066/5000\n",
      "1169/1169 [==============================] - 1s 429us/step - loss: 3463770346.3199 - mean_absolute_error: 43030.6111 - val_loss: 2553091847.9175 - val_mean_absolute_error: 28923.5283\n",
      "Epoch 3067/5000\n",
      "1169/1169 [==============================] - 0s 392us/step - loss: 3564766975.7810 - mean_absolute_error: 43141.3604 - val_loss: 2326990567.8076 - val_mean_absolute_error: 28294.9934\n",
      "Epoch 3068/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3227915099.7571 - mean_absolute_error: 42195.6732 - val_loss: 2341414044.1512 - val_mean_absolute_error: 27224.2101\n",
      "Epoch 3069/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 2938824812.6193 - mean_absolute_error: 41076.4523 - val_loss: 2499657546.7766 - val_mean_absolute_error: 27910.2953\n",
      "Epoch 3070/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3408388487.5552 - mean_absolute_error: 43652.3314 - val_loss: 2317376907.8763 - val_mean_absolute_error: 26703.4669\n",
      "Epoch 3071/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 2993565996.0171 - mean_absolute_error: 40570.1092 - val_loss: 2306586504.7973 - val_mean_absolute_error: 27862.3420\n",
      "Epoch 3072/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3115522207.8631 - mean_absolute_error: 41627.1374 - val_loss: 2464318800.9347 - val_mean_absolute_error: 29048.9022\n",
      "Epoch 3073/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3101391904.4106 - mean_absolute_error: 41335.0466 - val_loss: 2511551872.4399 - val_mean_absolute_error: 28556.8573\n",
      "Epoch 3074/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3031159187.5997 - mean_absolute_error: 42079.4532 - val_loss: 2456321570.7491 - val_mean_absolute_error: 28646.1938\n",
      "Epoch 3075/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3466684948.3661 - mean_absolute_error: 43256.0351 - val_loss: 2624964343.2027 - val_mean_absolute_error: 30404.3233\n",
      "Epoch 3076/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3094674101.7622 - mean_absolute_error: 41983.0161 - val_loss: 1739459944.9072 - val_mean_absolute_error: 22717.9903\n",
      "Epoch 3077/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3081565845.5706 - mean_absolute_error: 42089.4429 - val_loss: 2217547920.2749 - val_mean_absolute_error: 26702.8370\n",
      "Epoch 3078/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 2988418366.6313 - mean_absolute_error: 40470.6740 - val_loss: 2122255602.3643 - val_mean_absolute_error: 26169.0877\n",
      "Epoch 3079/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3415509981.1805 - mean_absolute_error: 42530.3880 - val_loss: 2421586389.3333 - val_mean_absolute_error: 28452.3680\n",
      "Epoch 3080/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3323500209.8751 - mean_absolute_error: 41729.4369 - val_loss: 2496210599.5876 - val_mean_absolute_error: 29890.9959\n",
      "Epoch 3081/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3059382710.4192 - mean_absolute_error: 40473.9535 - val_loss: 2606133049.6220 - val_mean_absolute_error: 29861.0543\n",
      "Epoch 3082/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3240033339.8939 - mean_absolute_error: 42809.7793 - val_loss: 2646154399.2302 - val_mean_absolute_error: 30145.6504\n",
      "Epoch 3083/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3103147895.5689 - mean_absolute_error: 41948.2718 - val_loss: 2465751526.0481 - val_mean_absolute_error: 28593.3393\n",
      "Epoch 3084/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3119298055.0077 - mean_absolute_error: 42055.2093 - val_loss: 2208016827.3814 - val_mean_absolute_error: 27466.2793\n",
      "Epoch 3085/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3065068106.6758 - mean_absolute_error: 40835.7787 - val_loss: 1962308304.4948 - val_mean_absolute_error: 25778.1419\n",
      "Epoch 3086/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 2940797140.8589 - mean_absolute_error: 40519.6451 - val_loss: 2567091176.6873 - val_mean_absolute_error: 29787.7527\n",
      "Epoch 3087/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3444195298.2173 - mean_absolute_error: 42564.0793 - val_loss: 3031273302.6529 - val_mean_absolute_error: 32977.7758\n",
      "Epoch 3088/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3287772845.4405 - mean_absolute_error: 41480.3612 - val_loss: 2100774313.7869 - val_mean_absolute_error: 26597.2486\n",
      "Epoch 3089/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3268219227.9760 - mean_absolute_error: 42187.6079 - val_loss: 2827490269.6907 - val_mean_absolute_error: 31063.7302\n",
      "Epoch 3090/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 363us/step - loss: 3383767009.1223 - mean_absolute_error: 42691.9553 - val_loss: 2897211340.0962 - val_mean_absolute_error: 31893.0280\n",
      "Epoch 3091/5000\n",
      "1169/1169 [==============================] - 0s 401us/step - loss: 2965677310.2481 - mean_absolute_error: 40717.0247 - val_loss: 2313946628.8385 - val_mean_absolute_error: 28546.2811\n",
      "Epoch 3092/5000\n",
      "1169/1169 [==============================] - 0s 379us/step - loss: 3265688883.4628 - mean_absolute_error: 43448.1946 - val_loss: 2964129556.6735 - val_mean_absolute_error: 32768.9796\n",
      "Epoch 3093/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3217592740.4619 - mean_absolute_error: 41137.3162 - val_loss: 2250722782.5704 - val_mean_absolute_error: 27694.5853\n",
      "Epoch 3094/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3407823430.7340 - mean_absolute_error: 43574.7469 - val_loss: 2312589469.9107 - val_mean_absolute_error: 27612.0325\n",
      "Epoch 3095/5000\n",
      "1169/1169 [==============================] - 1s 449us/step - loss: 3294665134.8640 - mean_absolute_error: 42674.5438 - val_loss: 2438398637.7457 - val_mean_absolute_error: 28417.0364\n",
      "Epoch 3096/5000\n",
      "1169/1169 [==============================] - 0s 401us/step - loss: 3081665455.3841 - mean_absolute_error: 42053.9342 - val_loss: 2400031542.1031 - val_mean_absolute_error: 28605.6384\n",
      "Epoch 3097/5000\n",
      "1169/1169 [==============================] - 0s 385us/step - loss: 3432259432.0205 - mean_absolute_error: 42237.5781 - val_loss: 2164988559.8351 - val_mean_absolute_error: 26744.6648\n",
      "Epoch 3098/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 3169742159.0556 - mean_absolute_error: 41879.8085 - val_loss: 2464222684.8110 - val_mean_absolute_error: 29430.3901\n",
      "Epoch 3099/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3109614748.7973 - mean_absolute_error: 41528.3852 - val_loss: 2405762119.6976 - val_mean_absolute_error: 28741.0372\n",
      "Epoch 3100/5000\n",
      "1169/1169 [==============================] - 0s 326us/step - loss: 3257779318.9119 - mean_absolute_error: 41563.7861 - val_loss: 2987977461.0034 - val_mean_absolute_error: 31008.1802\n",
      "Epoch 3101/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3308612152.9376 - mean_absolute_error: 42701.0669 - val_loss: 2737869295.7251 - val_mean_absolute_error: 28773.5756\n",
      "Epoch 3102/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3347712922.3884 - mean_absolute_error: 42524.1185 - val_loss: 2757702565.3883 - val_mean_absolute_error: 29259.2098\n",
      "Epoch 3103/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3330011707.5654 - mean_absolute_error: 42061.3801 - val_loss: 2379726299.4914 - val_mean_absolute_error: 27985.8984\n",
      "Epoch 3104/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3538128033.1771 - mean_absolute_error: 42653.5174 - val_loss: 2376546753.5395 - val_mean_absolute_error: 27696.5157\n",
      "Epoch 3105/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3253182404.6536 - mean_absolute_error: 42671.0386 - val_loss: 2114697802.3368 - val_mean_absolute_error: 26757.2546\n",
      "Epoch 3106/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3784646613.0778 - mean_absolute_error: 44952.4130 - val_loss: 1748848952.0825 - val_mean_absolute_error: 24196.2992\n",
      "Epoch 3107/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3234655984.2327 - mean_absolute_error: 41849.4773 - val_loss: 2182922254.0756 - val_mean_absolute_error: 27334.1792\n",
      "Epoch 3108/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 3225906922.3199 - mean_absolute_error: 41081.9429 - val_loss: 1982670510.6254 - val_mean_absolute_error: 26089.1041\n",
      "Epoch 3109/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3316558678.5013 - mean_absolute_error: 42731.5283 - val_loss: 1729845248.2199 - val_mean_absolute_error: 24658.9196\n",
      "Epoch 3110/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3255307319.8426 - mean_absolute_error: 42598.3780 - val_loss: 2836481236.0137 - val_mean_absolute_error: 31127.3982\n",
      "Epoch 3111/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 3437477317.7485 - mean_absolute_error: 42434.8683 - val_loss: 2170952764.7010 - val_mean_absolute_error: 26678.8496\n",
      "Epoch 3112/5000\n",
      "1169/1169 [==============================] - 0s 302us/step - loss: 3159751474.3678 - mean_absolute_error: 40306.4596 - val_loss: 2802952054.7629 - val_mean_absolute_error: 30075.1808\n",
      "Epoch 3113/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3096669328.7528 - mean_absolute_error: 41273.1479 - val_loss: 2510610380.9759 - val_mean_absolute_error: 29260.0630\n",
      "Epoch 3114/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 2821926149.4748 - mean_absolute_error: 40328.0943 - val_loss: 2061185453.7457 - val_mean_absolute_error: 26301.7310\n",
      "Epoch 3115/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3267044174.8366 - mean_absolute_error: 42094.6381 - val_loss: 2534726177.4296 - val_mean_absolute_error: 29899.8178\n",
      "Epoch 3116/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 3405572590.9187 - mean_absolute_error: 43357.0581 - val_loss: 2540612895.6701 - val_mean_absolute_error: 29497.1505\n",
      "Epoch 3117/5000\n",
      "1169/1169 [==============================] - 0s 330us/step - loss: 2943293226.9222 - mean_absolute_error: 39457.7900 - val_loss: 2879972790.9828 - val_mean_absolute_error: 31563.5812\n",
      "Epoch 3118/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 3155948623.4936 - mean_absolute_error: 40962.6248 - val_loss: 2565037066.9966 - val_mean_absolute_error: 30584.5895\n",
      "Epoch 3119/5000\n",
      "1169/1169 [==============================] - 0s 373us/step - loss: 3261407493.4748 - mean_absolute_error: 42514.9908 - val_loss: 2659633332.3436 - val_mean_absolute_error: 29997.4729\n",
      "Epoch 3120/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 2791954069.6801 - mean_absolute_error: 39168.0041 - val_loss: 2718845524.0137 - val_mean_absolute_error: 30583.2969\n",
      "Epoch 3121/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3348378428.6604 - mean_absolute_error: 41860.6064 - val_loss: 2502845401.7320 - val_mean_absolute_error: 29772.7209\n",
      "Epoch 3122/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 2933884041.8546 - mean_absolute_error: 40480.2867 - val_loss: 2333038949.1684 - val_mean_absolute_error: 28713.3015\n",
      "Epoch 3123/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3251910039.7605 - mean_absolute_error: 43132.5150 - val_loss: 1991996330.6667 - val_mean_absolute_error: 25663.4912\n",
      "Epoch 3124/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 3806560289.2866 - mean_absolute_error: 44364.6314 - val_loss: 2155969309.9107 - val_mean_absolute_error: 26796.4141\n",
      "Epoch 3125/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3185554350.8640 - mean_absolute_error: 41805.0668 - val_loss: 2427142480.9347 - val_mean_absolute_error: 28716.9605\n",
      "Epoch 3126/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3395685608.1300 - mean_absolute_error: 43622.7922 - val_loss: 2757693314.1993 - val_mean_absolute_error: 30562.1074\n",
      "Epoch 3127/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3579821563.4012 - mean_absolute_error: 43643.6500 - val_loss: 2595708024.9622 - val_mean_absolute_error: 29749.0662\n",
      "Epoch 3128/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3504024003.5586 - mean_absolute_error: 41783.5198 - val_loss: 2397943743.7801 - val_mean_absolute_error: 28175.2650\n",
      "Epoch 3129/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3468700778.2104 - mean_absolute_error: 42881.1317 - val_loss: 3152914213.3883 - val_mean_absolute_error: 31243.7034\n",
      "Epoch 3130/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3123864390.7340 - mean_absolute_error: 41702.3471 - val_loss: 2458243456.8797 - val_mean_absolute_error: 29183.2591\n",
      "Epoch 3131/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3292689195.6886 - mean_absolute_error: 42662.9364 - val_loss: 2196333176.0825 - val_mean_absolute_error: 27406.2634\n",
      "Epoch 3132/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3163260132.8452 - mean_absolute_error: 41101.3100 - val_loss: 1765696531.5739 - val_mean_absolute_error: 24864.2784\n",
      "Epoch 3133/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3153289614.5629 - mean_absolute_error: 41771.7738 - val_loss: 2369875380.7835 - val_mean_absolute_error: 28639.8125\n",
      "Epoch 3134/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3393477419.1411 - mean_absolute_error: 41056.2401 - val_loss: 2010038285.6357 - val_mean_absolute_error: 26150.5540\n",
      "Epoch 3135/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3255113732.8178 - mean_absolute_error: 42513.9202 - val_loss: 2114463699.1340 - val_mean_absolute_error: 26415.0500\n",
      "Epoch 3136/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3406545752.6912 - mean_absolute_error: 42981.5066 - val_loss: 2421280110.8454 - val_mean_absolute_error: 28747.6427\n",
      "Epoch 3137/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3253708895.9179 - mean_absolute_error: 42463.7517 - val_loss: 2076144738.0893 - val_mean_absolute_error: 25632.7321\n",
      "Epoch 3138/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3114465140.0650 - mean_absolute_error: 41722.7251 - val_loss: 2659782758.4880 - val_mean_absolute_error: 30139.0489\n",
      "Epoch 3139/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3358328259.9966 - mean_absolute_error: 43072.2078 - val_loss: 2302941361.2646 - val_mean_absolute_error: 28092.4368\n",
      "Epoch 3140/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3367415917.2763 - mean_absolute_error: 42452.7673 - val_loss: 1939274875.8213 - val_mean_absolute_error: 25134.2136\n",
      "Epoch 3141/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3074754554.5252 - mean_absolute_error: 41453.7873 - val_loss: 2351027630.1856 - val_mean_absolute_error: 27695.2168\n",
      "Epoch 3142/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3315539574.9119 - mean_absolute_error: 41952.6498 - val_loss: 2213596953.0722 - val_mean_absolute_error: 27171.8562\n",
      "Epoch 3143/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3112139705.1565 - mean_absolute_error: 41195.8051 - val_loss: 2318703839.0103 - val_mean_absolute_error: 28746.2178\n",
      "Epoch 3144/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3184940189.0163 - mean_absolute_error: 42398.3634 - val_loss: 2382583488.6598 - val_mean_absolute_error: 28833.0898\n",
      "Epoch 3145/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3388449232.2601 - mean_absolute_error: 42351.8396 - val_loss: 3012197849.7320 - val_mean_absolute_error: 31768.2804\n",
      "Epoch 3146/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 2947817559.3772 - mean_absolute_error: 41376.6201 - val_loss: 2386103310.5155 - val_mean_absolute_error: 28843.9182\n",
      "Epoch 3147/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3656380707.0385 - mean_absolute_error: 43557.0505 - val_loss: 2089806757.1684 - val_mean_absolute_error: 26327.3070\n",
      "Epoch 3148/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 2816061979.3738 - mean_absolute_error: 39862.4052 - val_loss: 2092707657.8969 - val_mean_absolute_error: 26964.9833\n",
      "Epoch 3149/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 3290838049.7246 - mean_absolute_error: 42355.4285 - val_loss: 2497011565.5258 - val_mean_absolute_error: 29660.2910\n",
      "Epoch 3150/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3455573801.1702 - mean_absolute_error: 43079.1933 - val_loss: 2264006531.0790 - val_mean_absolute_error: 27465.8285\n",
      "Epoch 3151/5000\n",
      "1169/1169 [==============================] - 0s 332us/step - loss: 3528192936.1848 - mean_absolute_error: 43980.4115 - val_loss: 2329084559.3952 - val_mean_absolute_error: 28208.8921\n",
      "Epoch 3152/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3187641724.1677 - mean_absolute_error: 42167.2931 - val_loss: 2512418098.1443 - val_mean_absolute_error: 28530.1149\n",
      "Epoch 3153/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3224536627.6818 - mean_absolute_error: 42539.9586 - val_loss: 2612121441.6495 - val_mean_absolute_error: 29698.4943\n",
      "Epoch 3154/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3332552848.7528 - mean_absolute_error: 42935.1423 - val_loss: 2407396962.5292 - val_mean_absolute_error: 28041.6424\n",
      "Epoch 3155/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3107284809.3618 - mean_absolute_error: 41664.1190 - val_loss: 2199202381.8557 - val_mean_absolute_error: 26845.9329\n",
      "Epoch 3156/5000\n",
      "1169/1169 [==============================] - 0s 336us/step - loss: 3095076488.6501 - mean_absolute_error: 41716.7709 - val_loss: 2683329397.4433 - val_mean_absolute_error: 30034.3688\n",
      "Epoch 3157/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3269202073.9504 - mean_absolute_error: 42190.7285 - val_loss: 2367395299.4089 - val_mean_absolute_error: 28244.3017\n",
      "Epoch 3158/5000\n",
      "1169/1169 [==============================] - 0s 384us/step - loss: 2794760812.1814 - mean_absolute_error: 40172.2840 - val_loss: 2191845490.8041 - val_mean_absolute_error: 26949.7601\n",
      "Epoch 3159/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3023833178.0051 - mean_absolute_error: 41818.5798 - val_loss: 2291932950.8729 - val_mean_absolute_error: 27437.2611\n",
      "Epoch 3160/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3482284247.7605 - mean_absolute_error: 43182.8520 - val_loss: 2304108264.6873 - val_mean_absolute_error: 27473.1456\n",
      "Epoch 3161/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3603617863.1719 - mean_absolute_error: 44228.6420 - val_loss: 2774655837.6907 - val_mean_absolute_error: 29578.8327\n",
      "Epoch 3162/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3484413338.8263 - mean_absolute_error: 43406.3660 - val_loss: 2446965824.6598 - val_mean_absolute_error: 28835.9606\n",
      "Epoch 3163/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3165487707.7571 - mean_absolute_error: 42308.2429 - val_loss: 1883625568.9897 - val_mean_absolute_error: 25449.5039\n",
      "Epoch 3164/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 2959187554.4363 - mean_absolute_error: 40021.6076 - val_loss: 2143533670.4880 - val_mean_absolute_error: 27031.2317\n",
      "Epoch 3165/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3471537020.6056 - mean_absolute_error: 43456.4077 - val_loss: 2480876079.0653 - val_mean_absolute_error: 28972.3758\n",
      "Epoch 3166/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3147192484.4619 - mean_absolute_error: 40354.8433 - val_loss: 2746694893.9656 - val_mean_absolute_error: 30846.9106\n",
      "Epoch 3167/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3155699317.1600 - mean_absolute_error: 41598.4769 - val_loss: 2510923820.8660 - val_mean_absolute_error: 29293.8975\n",
      "Epoch 3168/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3776019134.3028 - mean_absolute_error: 44831.6877 - val_loss: 2555867269.7182 - val_mean_absolute_error: 29322.9619\n",
      "Epoch 3169/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 2996440254.5218 - mean_absolute_error: 40930.9021 - val_loss: 2009564254.5704 - val_mean_absolute_error: 25982.0277\n",
      "Epoch 3170/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3032563451.1822 - mean_absolute_error: 41589.3112 - val_loss: 2654283704.3024 - val_mean_absolute_error: 29702.4906\n",
      "Epoch 3171/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 2943883383.5689 - mean_absolute_error: 40450.1522 - val_loss: 2084610195.3540 - val_mean_absolute_error: 26241.0422\n",
      "Epoch 3172/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 346us/step - loss: 3197301086.6039 - mean_absolute_error: 40585.4249 - val_loss: 2526816394.5567 - val_mean_absolute_error: 29221.5485\n",
      "Epoch 3173/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3007560214.1180 - mean_absolute_error: 41000.4253 - val_loss: 2194068204.6460 - val_mean_absolute_error: 27322.4686\n",
      "Epoch 3174/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3689657319.0351 - mean_absolute_error: 44180.3322 - val_loss: 2482877668.2887 - val_mean_absolute_error: 28977.1641\n",
      "Epoch 3175/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3285841139.9555 - mean_absolute_error: 42309.8807 - val_loss: 2051489255.3677 - val_mean_absolute_error: 26227.4024\n",
      "Epoch 3176/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 3098689304.3080 - mean_absolute_error: 41459.4808 - val_loss: 1763947201.7595 - val_mean_absolute_error: 24139.5708\n",
      "Epoch 3177/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3139578474.6484 - mean_absolute_error: 42620.3321 - val_loss: 2339106693.7182 - val_mean_absolute_error: 28736.4305\n",
      "Epoch 3178/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3595693698.5184 - mean_absolute_error: 43429.8074 - val_loss: 2198013425.0447 - val_mean_absolute_error: 27828.0952\n",
      "Epoch 3179/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3169056979.9829 - mean_absolute_error: 41699.1190 - val_loss: 2078083646.0206 - val_mean_absolute_error: 27069.7145\n",
      "Epoch 3180/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3465345269.4885 - mean_absolute_error: 42045.2933 - val_loss: 2207009158.1581 - val_mean_absolute_error: 27937.8806\n",
      "Epoch 3181/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3086928505.3208 - mean_absolute_error: 40275.8752 - val_loss: 1927427395.9588 - val_mean_absolute_error: 26463.3736\n",
      "Epoch 3182/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3238284054.7750 - mean_absolute_error: 41636.7312 - val_loss: 2073237033.7869 - val_mean_absolute_error: 26796.2668\n",
      "Epoch 3183/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3097265004.1814 - mean_absolute_error: 41152.5385 - val_loss: 2009755881.7869 - val_mean_absolute_error: 26423.5809\n",
      "Epoch 3184/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3201737306.4431 - mean_absolute_error: 41223.7793 - val_loss: 1986132243.3540 - val_mean_absolute_error: 26900.8586\n",
      "Epoch 3185/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3178616574.0291 - mean_absolute_error: 42250.9169 - val_loss: 2419570608.3849 - val_mean_absolute_error: 28336.7344\n",
      "Epoch 3186/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 3255787988.6399 - mean_absolute_error: 41964.9671 - val_loss: 2051403422.3505 - val_mean_absolute_error: 25682.3956\n",
      "Epoch 3187/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 2811500281.2113 - mean_absolute_error: 39821.3378 - val_loss: 2346628374.4330 - val_mean_absolute_error: 27687.8468\n",
      "Epoch 3188/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3196293297.1634 - mean_absolute_error: 42009.3017 - val_loss: 2335567981.9656 - val_mean_absolute_error: 27912.6491\n",
      "Epoch 3189/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3489930111.0145 - mean_absolute_error: 43494.6938 - val_loss: 2325996601.1821 - val_mean_absolute_error: 27344.9364\n",
      "Epoch 3190/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3276902372.8452 - mean_absolute_error: 42133.5975 - val_loss: 2576733860.0687 - val_mean_absolute_error: 28675.0699\n",
      "Epoch 3191/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3260418823.0077 - mean_absolute_error: 41619.8935 - val_loss: 2354887902.1306 - val_mean_absolute_error: 27888.1556\n",
      "Epoch 3192/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3354204537.7588 - mean_absolute_error: 42033.6232 - val_loss: 1973899645.8007 - val_mean_absolute_error: 25301.4028\n",
      "Epoch 3193/5000\n",
      "1169/1169 [==============================] - 0s 389us/step - loss: 3419857169.0813 - mean_absolute_error: 42600.2812 - val_loss: 2464017179.7113 - val_mean_absolute_error: 29171.2680\n",
      "Epoch 3194/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3300231319.5415 - mean_absolute_error: 42818.4175 - val_loss: 2375848375.8625 - val_mean_absolute_error: 28652.2910\n",
      "Epoch 3195/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3142438585.7040 - mean_absolute_error: 41240.3539 - val_loss: 2321879922.8041 - val_mean_absolute_error: 28147.3161\n",
      "Epoch 3196/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3336357020.0308 - mean_absolute_error: 42249.6404 - val_loss: 2605815121.8144 - val_mean_absolute_error: 30027.9029\n",
      "Epoch 3197/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3320368224.9581 - mean_absolute_error: 41794.4330 - val_loss: 2691600553.3471 - val_mean_absolute_error: 30111.3786\n",
      "Epoch 3198/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 2939364439.5962 - mean_absolute_error: 40641.6005 - val_loss: 2367433358.9553 - val_mean_absolute_error: 28273.6827\n",
      "Epoch 3199/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3135652107.9350 - mean_absolute_error: 41711.1382 - val_loss: 2327182584.0825 - val_mean_absolute_error: 27678.8011\n",
      "Epoch 3200/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 2947402794.3747 - mean_absolute_error: 40520.2303 - val_loss: 2110627217.8144 - val_mean_absolute_error: 25617.9691\n",
      "Epoch 3201/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3454577039.2198 - mean_absolute_error: 42017.4249 - val_loss: 2170356785.7045 - val_mean_absolute_error: 26205.6844\n",
      "Epoch 3202/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 2995974096.6980 - mean_absolute_error: 40842.4754 - val_loss: 2047355036.3711 - val_mean_absolute_error: 25418.8315\n",
      "Epoch 3203/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3213226525.7827 - mean_absolute_error: 40824.5111 - val_loss: 1981681363.1340 - val_mean_absolute_error: 24878.2311\n",
      "Epoch 3204/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3166255427.6681 - mean_absolute_error: 41014.8318 - val_loss: 2140305136.6048 - val_mean_absolute_error: 26612.9408\n",
      "Epoch 3205/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 2914003209.6356 - mean_absolute_error: 40733.8241 - val_loss: 1929724055.0928 - val_mean_absolute_error: 24946.7136\n",
      "Epoch 3206/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 2949499805.8922 - mean_absolute_error: 40921.2240 - val_loss: 2078811091.5739 - val_mean_absolute_error: 27035.1555\n",
      "Epoch 3207/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3355168300.0171 - mean_absolute_error: 42404.2723 - val_loss: 2258227790.2955 - val_mean_absolute_error: 27372.9254\n",
      "Epoch 3208/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3312389775.2198 - mean_absolute_error: 42236.2348 - val_loss: 2216838013.3608 - val_mean_absolute_error: 27297.4943\n",
      "Epoch 3209/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 2868753677.5774 - mean_absolute_error: 39755.8573 - val_loss: 2177143160.5223 - val_mean_absolute_error: 27208.8727\n",
      "Epoch 3210/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3417082222.8092 - mean_absolute_error: 42672.7208 - val_loss: 2502441594.2818 - val_mean_absolute_error: 29792.6239\n",
      "Epoch 3211/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 2766586777.8409 - mean_absolute_error: 39519.8185 - val_loss: 2209297397.0034 - val_mean_absolute_error: 27759.3463\n",
      "Epoch 3212/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3306249379.8050 - mean_absolute_error: 43753.8842 - val_loss: 2001849452.6460 - val_mean_absolute_error: 25707.9765\n",
      "Epoch 3213/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3215145059.0932 - mean_absolute_error: 41832.2823 - val_loss: 1818661919.6701 - val_mean_absolute_error: 25038.9367\n",
      "Epoch 3214/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 2997647674.4705 - mean_absolute_error: 40226.9642 - val_loss: 2043251243.1065 - val_mean_absolute_error: 25723.1134\n",
      "Epoch 3215/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 3063674364.2772 - mean_absolute_error: 41706.5455 - val_loss: 2402111525.8282 - val_mean_absolute_error: 28069.5344\n",
      "Epoch 3216/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3221029728.9033 - mean_absolute_error: 41960.8254 - val_loss: 2531807357.3608 - val_mean_absolute_error: 28997.4238\n",
      "Epoch 3217/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3067917736.1848 - mean_absolute_error: 41049.7524 - val_loss: 2251311835.4914 - val_mean_absolute_error: 27398.5238\n",
      "Epoch 3218/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3180267665.4098 - mean_absolute_error: 40924.8001 - val_loss: 3591257940.8935 - val_mean_absolute_error: 32533.2591\n",
      "Epoch 3219/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3133635248.0684 - mean_absolute_error: 41144.9413 - val_loss: 2041185750.2131 - val_mean_absolute_error: 26685.2626\n",
      "Epoch 3220/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 3524653270.8298 - mean_absolute_error: 43337.2090 - val_loss: 1957895506.6942 - val_mean_absolute_error: 25648.6073\n",
      "Epoch 3221/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3077615637.4611 - mean_absolute_error: 41277.7709 - val_loss: 2161094339.0790 - val_mean_absolute_error: 26347.7230\n",
      "Epoch 3222/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 3529851145.6356 - mean_absolute_error: 44168.5541 - val_loss: 2311802527.2302 - val_mean_absolute_error: 27604.0770\n",
      "Epoch 3223/5000\n",
      "1169/1169 [==============================] - 0s 315us/step - loss: 3213410525.3995 - mean_absolute_error: 41205.0268 - val_loss: 2558586775.3127 - val_mean_absolute_error: 29804.8911\n",
      "Epoch 3224/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3406857395.5723 - mean_absolute_error: 42372.4766 - val_loss: 2133230683.9313 - val_mean_absolute_error: 27293.6687\n",
      "Epoch 3225/5000\n",
      "1169/1169 [==============================] - 1s 433us/step - loss: 3152790830.2070 - mean_absolute_error: 40931.0048 - val_loss: 2691912218.8316 - val_mean_absolute_error: 30356.9455\n",
      "Epoch 3226/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3137868531.5175 - mean_absolute_error: 41179.3257 - val_loss: 2808892680.3574 - val_mean_absolute_error: 31093.5618\n",
      "Epoch 3227/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3388289623.8152 - mean_absolute_error: 42723.3147 - val_loss: 2220824826.7216 - val_mean_absolute_error: 28189.9568\n",
      "Epoch 3228/5000\n",
      "1169/1169 [==============================] - 0s 368us/step - loss: 3216881431.4320 - mean_absolute_error: 41891.0119 - val_loss: 2330463667.9038 - val_mean_absolute_error: 28463.0045\n",
      "Epoch 3229/5000\n",
      "1169/1169 [==============================] - 0s 422us/step - loss: 3285136968.2669 - mean_absolute_error: 42086.7713 - val_loss: 2141604542.9003 - val_mean_absolute_error: 27237.2036\n",
      "Epoch 3230/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 3343332811.4423 - mean_absolute_error: 41651.3126 - val_loss: 2871967798.5430 - val_mean_absolute_error: 30927.8928\n",
      "Epoch 3231/5000\n",
      "1169/1169 [==============================] - 0s 323us/step - loss: 3104612165.6390 - mean_absolute_error: 41093.0035 - val_loss: 1956302413.1959 - val_mean_absolute_error: 25084.9765\n",
      "Epoch 3232/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3156221994.4842 - mean_absolute_error: 42147.7682 - val_loss: 2468791643.0515 - val_mean_absolute_error: 29336.5798\n",
      "Epoch 3233/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3331047810.7374 - mean_absolute_error: 42628.6537 - val_loss: 2072494131.0241 - val_mean_absolute_error: 26904.9708\n",
      "Epoch 3234/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 3446728524.8657 - mean_absolute_error: 43669.6009 - val_loss: 2563603725.6357 - val_mean_absolute_error: 29090.9606\n",
      "Epoch 3235/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3342360942.7545 - mean_absolute_error: 42779.4692 - val_loss: 2122269897.8969 - val_mean_absolute_error: 27785.1460\n",
      "Epoch 3236/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3009864743.9658 - mean_absolute_error: 40424.9490 - val_loss: 2177693192.1375 - val_mean_absolute_error: 27654.0496\n",
      "Epoch 3237/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 2849830123.1959 - mean_absolute_error: 39567.1635 - val_loss: 2374424980.6735 - val_mean_absolute_error: 28130.6352\n",
      "Epoch 3238/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3596887882.0188 - mean_absolute_error: 42450.3706 - val_loss: 2342028639.8900 - val_mean_absolute_error: 27648.4133\n",
      "Epoch 3239/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3208752870.9256 - mean_absolute_error: 42209.2965 - val_loss: 2194688942.6254 - val_mean_absolute_error: 26978.8784\n",
      "Epoch 3240/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3019974472.4859 - mean_absolute_error: 40670.9154 - val_loss: 2529873411.5189 - val_mean_absolute_error: 28721.4255\n",
      "Epoch 3241/5000\n",
      "1169/1169 [==============================] - 0s 341us/step - loss: 2902726766.1523 - mean_absolute_error: 40504.3349 - val_loss: 2397769916.7010 - val_mean_absolute_error: 27867.2350\n",
      "Epoch 3242/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3285484274.7237 - mean_absolute_error: 42375.2572 - val_loss: 2466765836.7560 - val_mean_absolute_error: 28504.6418\n",
      "Epoch 3243/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3389932367.4936 - mean_absolute_error: 42680.8835 - val_loss: 2333408672.9897 - val_mean_absolute_error: 27571.5756\n",
      "Epoch 3244/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 3120530684.9341 - mean_absolute_error: 42296.4655 - val_loss: 2204217197.9656 - val_mean_absolute_error: 26193.3235\n",
      "Epoch 3245/5000\n",
      "1169/1169 [==============================] - 0s 400us/step - loss: 2881462145.2044 - mean_absolute_error: 40119.5404 - val_loss: 2246007126.2131 - val_mean_absolute_error: 27218.6250\n",
      "Epoch 3246/5000\n",
      "1169/1169 [==============================] - 0s 346us/step - loss: 3117590085.6390 - mean_absolute_error: 40452.5352 - val_loss: 1869128185.8419 - val_mean_absolute_error: 24287.0999\n",
      "Epoch 3247/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3176641203.5723 - mean_absolute_error: 41850.9306 - val_loss: 2161927250.6942 - val_mean_absolute_error: 26624.3782\n",
      "Epoch 3248/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 2871642503.9932 - mean_absolute_error: 40640.1717 - val_loss: 2407581202.0344 - val_mean_absolute_error: 28103.0089\n",
      "Epoch 3249/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3352731864.8007 - mean_absolute_error: 42846.9277 - val_loss: 2220113280.8797 - val_mean_absolute_error: 26310.0112\n",
      "Epoch 3250/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3134408966.7887 - mean_absolute_error: 42307.7334 - val_loss: 2482670796.0962 - val_mean_absolute_error: 27668.0301\n",
      "Epoch 3251/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3048918165.7896 - mean_absolute_error: 41184.6873 - val_loss: 2221879883.6564 - val_mean_absolute_error: 26676.1954\n",
      "Epoch 3252/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3383540041.3618 - mean_absolute_error: 42188.6161 - val_loss: 1930909637.0584 - val_mean_absolute_error: 24408.1812\n",
      "Epoch 3253/5000\n",
      "1169/1169 [==============================] - ETA: 0s - loss: 3260312974.5965 - mean_absolute_error: 42796.71 - 0s 351us/step - loss: 3231249448.0753 - mean_absolute_error: 42671.8030 - val_loss: 1986317672.0275 - val_mean_absolute_error: 25754.3133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3254/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3229224871.5278 - mean_absolute_error: 42033.9091 - val_loss: 2415011330.1993 - val_mean_absolute_error: 28812.3629\n",
      "Epoch 3255/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 3041882820.8725 - mean_absolute_error: 40832.5636 - val_loss: 2246970741.4433 - val_mean_absolute_error: 27785.6990\n",
      "Epoch 3256/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 2846723668.5304 - mean_absolute_error: 40363.4932 - val_loss: 2426614243.4089 - val_mean_absolute_error: 29660.1479\n",
      "Epoch 3257/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3038429564.2772 - mean_absolute_error: 41453.7176 - val_loss: 2238897159.0378 - val_mean_absolute_error: 28251.1938\n",
      "Epoch 3258/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 3106081139.6270 - mean_absolute_error: 40748.7019 - val_loss: 2348022705.2646 - val_mean_absolute_error: 27916.3694\n",
      "Epoch 3259/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 2931486709.7074 - mean_absolute_error: 40629.2285 - val_loss: 2238235783.9175 - val_mean_absolute_error: 27482.7319\n",
      "Epoch 3260/5000\n",
      "1169/1169 [==============================] - 0s 394us/step - loss: 3247052508.9615 - mean_absolute_error: 40521.1673 - val_loss: 2563174692.5086 - val_mean_absolute_error: 29334.6487\n",
      "Epoch 3261/5000\n",
      "1169/1169 [==============================] - 0s 325us/step - loss: 3146666457.8409 - mean_absolute_error: 40430.0749 - val_loss: 2156570259.3540 - val_mean_absolute_error: 26508.0142\n",
      "Epoch 3262/5000\n",
      "1169/1169 [==============================] - 0s 377us/step - loss: 3380983725.6595 - mean_absolute_error: 42316.3221 - val_loss: 2176910503.5876 - val_mean_absolute_error: 27405.8349\n",
      "Epoch 3263/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 2910176086.5013 - mean_absolute_error: 40652.0251 - val_loss: 2223203532.5361 - val_mean_absolute_error: 27270.5532\n",
      "Epoch 3264/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3233371938.8195 - mean_absolute_error: 41836.2092 - val_loss: 2216584566.7629 - val_mean_absolute_error: 28404.9892\n",
      "Epoch 3265/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3250485482.5389 - mean_absolute_error: 42010.2692 - val_loss: 2216615113.4570 - val_mean_absolute_error: 28150.9244\n",
      "Epoch 3266/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3219282375.2814 - mean_absolute_error: 41976.5516 - val_loss: 2381393770.8866 - val_mean_absolute_error: 28118.8224\n",
      "Epoch 3267/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3179818695.2814 - mean_absolute_error: 42057.9534 - val_loss: 2877297704.9072 - val_mean_absolute_error: 30494.9731\n",
      "Epoch 3268/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3203228055.5415 - mean_absolute_error: 41480.7136 - val_loss: 1996238315.7663 - val_mean_absolute_error: 25893.9733\n",
      "Epoch 3269/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 2907714259.9829 - mean_absolute_error: 40590.2331 - val_loss: 2200393966.8454 - val_mean_absolute_error: 27161.2540\n",
      "Epoch 3270/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 2914979134.6313 - mean_absolute_error: 39724.3642 - val_loss: 2163688309.8832 - val_mean_absolute_error: 26041.8353\n",
      "Epoch 3271/5000\n",
      "1169/1169 [==============================] - 0s 396us/step - loss: 3022943118.1249 - mean_absolute_error: 41548.9463 - val_loss: 2105910005.8832 - val_mean_absolute_error: 26213.2514\n",
      "Epoch 3272/5000\n",
      "1169/1169 [==============================] - 0s 338us/step - loss: 3141217647.2472 - mean_absolute_error: 42190.9138 - val_loss: 2260678740.4536 - val_mean_absolute_error: 27652.3785\n",
      "Epoch 3273/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 2936335882.2926 - mean_absolute_error: 39956.2216 - val_loss: 2028247674.2818 - val_mean_absolute_error: 26483.7034\n",
      "Epoch 3274/5000\n",
      "1169/1169 [==============================] - 0s 411us/step - loss: 3460401432.5269 - mean_absolute_error: 43548.5825 - val_loss: 2161183970.0893 - val_mean_absolute_error: 26231.0627\n",
      "Epoch 3275/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3620878354.8332 - mean_absolute_error: 43221.1935 - val_loss: 2666128019.3540 - val_mean_absolute_error: 30522.1836\n",
      "Epoch 3276/5000\n",
      "1169/1169 [==============================] - 0s 337us/step - loss: 3268922053.5295 - mean_absolute_error: 41395.1249 - val_loss: 2291863603.0241 - val_mean_absolute_error: 27982.2150\n",
      "Epoch 3277/5000\n",
      "1169/1169 [==============================] - 0s 343us/step - loss: 2997140827.5381 - mean_absolute_error: 40020.3877 - val_loss: 3384765163.3265 - val_mean_absolute_error: 33699.8785\n",
      "Epoch 3278/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3125658583.9247 - mean_absolute_error: 42084.4581 - val_loss: 2375060681.0172 - val_mean_absolute_error: 28447.3065\n",
      "Epoch 3279/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3287972423.8289 - mean_absolute_error: 42557.3889 - val_loss: 3082434486.5430 - val_mean_absolute_error: 32503.1864\n",
      "Epoch 3280/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3047535197.2900 - mean_absolute_error: 39590.3615 - val_loss: 2271690219.3265 - val_mean_absolute_error: 25856.8292\n",
      "Epoch 3281/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3344140422.8982 - mean_absolute_error: 43268.3751 - val_loss: 2389364786.5842 - val_mean_absolute_error: 26871.1519\n",
      "Epoch 3282/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3423719587.5860 - mean_absolute_error: 42538.8221 - val_loss: 3043548368.0550 - val_mean_absolute_error: 33002.4780\n",
      "Epoch 3283/5000\n",
      "1169/1169 [==============================] - 0s 384us/step - loss: 3239204655.7399 - mean_absolute_error: 40399.2545 - val_loss: 2298073094.5979 - val_mean_absolute_error: 28084.3491\n",
      "Epoch 3284/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 2803186654.0565 - mean_absolute_error: 39575.2389 - val_loss: 2335142695.5876 - val_mean_absolute_error: 26978.4280\n",
      "Epoch 3285/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3440906064.5885 - mean_absolute_error: 43142.9696 - val_loss: 2298552351.6701 - val_mean_absolute_error: 25841.8883\n",
      "Epoch 3286/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3089559379.8734 - mean_absolute_error: 42535.2823 - val_loss: 2207337516.8660 - val_mean_absolute_error: 27776.6911\n",
      "Epoch 3287/5000\n",
      "1169/1169 [==============================] - 0s 371us/step - loss: 3072168595.3807 - mean_absolute_error: 41035.3551 - val_loss: 2122256588.5361 - val_mean_absolute_error: 26803.2827\n",
      "Epoch 3288/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3104766893.0026 - mean_absolute_error: 41574.9685 - val_loss: 2036215044.3986 - val_mean_absolute_error: 26673.6800\n",
      "Epoch 3289/5000\n",
      "1169/1169 [==============================] - 0s 397us/step - loss: 3135587787.3328 - mean_absolute_error: 41274.8305 - val_loss: 2467680685.7457 - val_mean_absolute_error: 28987.0836\n",
      "Epoch 3290/5000\n",
      "1169/1169 [==============================] - 0s 316us/step - loss: 3383257225.0881 - mean_absolute_error: 41155.1193 - val_loss: 2402077624.7423 - val_mean_absolute_error: 28181.9918\n",
      "Epoch 3291/5000\n",
      "1169/1169 [==============================] - 0s 390us/step - loss: 3164741947.6749 - mean_absolute_error: 41895.7847 - val_loss: 2392423269.6082 - val_mean_absolute_error: 28938.6375\n",
      "Epoch 3292/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 3127863106.5731 - mean_absolute_error: 41102.1160 - val_loss: 2586485387.8763 - val_mean_absolute_error: 29546.6689\n",
      "Epoch 3293/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3451846144.8760 - mean_absolute_error: 43323.6483 - val_loss: 2325462735.1753 - val_mean_absolute_error: 28093.3447\n",
      "Epoch 3294/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3478983533.4953 - mean_absolute_error: 43244.3820 - val_loss: 2258327945.6770 - val_mean_absolute_error: 27347.5868\n",
      "Epoch 3295/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3235576466.5047 - mean_absolute_error: 41741.5225 - val_loss: 1890147115.1065 - val_mean_absolute_error: 25114.9137\n",
      "Epoch 3296/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3268972033.0950 - mean_absolute_error: 41354.8112 - val_loss: 2039174933.9931 - val_mean_absolute_error: 26120.3496\n",
      "Epoch 3297/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3135799447.7605 - mean_absolute_error: 41841.3971 - val_loss: 2196042627.0790 - val_mean_absolute_error: 26624.6707\n",
      "Epoch 3298/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3188468558.6176 - mean_absolute_error: 42544.9750 - val_loss: 2288548320.7698 - val_mean_absolute_error: 28178.8302\n",
      "Epoch 3299/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 2935430590.7408 - mean_absolute_error: 40468.3363 - val_loss: 2011034668.8660 - val_mean_absolute_error: 25687.4101\n",
      "Epoch 3300/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3310754916.2977 - mean_absolute_error: 41919.5011 - val_loss: 2450116385.4296 - val_mean_absolute_error: 28204.5434\n",
      "Epoch 3301/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 2930660833.9983 - mean_absolute_error: 40814.4516 - val_loss: 2313286929.1546 - val_mean_absolute_error: 27708.3344\n",
      "Epoch 3302/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3041204714.8674 - mean_absolute_error: 40596.3724 - val_loss: 2087608992.1100 - val_mean_absolute_error: 26066.6708\n",
      "Epoch 3303/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3137188962.5458 - mean_absolute_error: 41548.4137 - val_loss: 2236204229.9381 - val_mean_absolute_error: 27342.6435\n",
      "Epoch 3304/5000\n",
      "1169/1169 [==============================] - 0s 369us/step - loss: 3101002977.5603 - mean_absolute_error: 41227.8074 - val_loss: 2304435613.0309 - val_mean_absolute_error: 28160.3263\n",
      "Epoch 3305/5000\n",
      "1169/1169 [==============================] - 0s 320us/step - loss: 3121052867.1206 - mean_absolute_error: 42224.1411 - val_loss: 2413903548.7010 - val_mean_absolute_error: 29232.8839\n",
      "Epoch 3306/5000\n",
      "1169/1169 [==============================] - 0s 322us/step - loss: 3345480007.8289 - mean_absolute_error: 42781.2797 - val_loss: 2658727748.1787 - val_mean_absolute_error: 30698.9465\n",
      "Epoch 3307/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3092111543.9521 - mean_absolute_error: 40963.2634 - val_loss: 2169501446.5979 - val_mean_absolute_error: 26839.7094\n",
      "Epoch 3308/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3060468686.7271 - mean_absolute_error: 41344.2362 - val_loss: 2022665105.1546 - val_mean_absolute_error: 26334.5877\n",
      "Epoch 3309/5000\n",
      "1169/1169 [==============================] - 0s 416us/step - loss: 3439324584.4038 - mean_absolute_error: 41431.1078 - val_loss: 2030342677.9931 - val_mean_absolute_error: 26931.8697\n",
      "Epoch 3310/5000\n",
      "1169/1169 [==============================] - 0s 328us/step - loss: 3418496766.7956 - mean_absolute_error: 43038.6072 - val_loss: 2155290202.1718 - val_mean_absolute_error: 27730.7331\n",
      "Epoch 3311/5000\n",
      "1169/1169 [==============================] - 0s 413us/step - loss: 3189229006.2891 - mean_absolute_error: 42020.6379 - val_loss: 2274945956.5086 - val_mean_absolute_error: 27842.7956\n",
      "Epoch 3312/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3218043866.1146 - mean_absolute_error: 41865.9071 - val_loss: 2145416810.4467 - val_mean_absolute_error: 26448.2492\n",
      "Epoch 3313/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3312652912.9991 - mean_absolute_error: 42131.5009 - val_loss: 2714639998.6804 - val_mean_absolute_error: 28591.6127\n",
      "Epoch 3314/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3487143493.6390 - mean_absolute_error: 43927.3769 - val_loss: 1796745176.4124 - val_mean_absolute_error: 24426.6498\n",
      "Epoch 3315/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3291399170.6279 - mean_absolute_error: 42841.8742 - val_loss: 1892740686.2955 - val_mean_absolute_error: 25021.3113\n",
      "Epoch 3316/5000\n",
      "1169/1169 [==============================] - 0s 383us/step - loss: 3535057947.3738 - mean_absolute_error: 42998.5790 - val_loss: 2199053534.1306 - val_mean_absolute_error: 27540.8612\n",
      "Epoch 3317/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 3034280993.0676 - mean_absolute_error: 41176.3107 - val_loss: 1850828211.0241 - val_mean_absolute_error: 25355.9754\n",
      "Epoch 3318/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3392179654.6245 - mean_absolute_error: 42134.4825 - val_loss: 2086110870.8729 - val_mean_absolute_error: 26409.6848\n",
      "Epoch 3319/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3321110920.4311 - mean_absolute_error: 43145.3153 - val_loss: 2471519663.5052 - val_mean_absolute_error: 28467.7695\n",
      "Epoch 3320/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3145420224.7117 - mean_absolute_error: 41058.8488 - val_loss: 3058856018.6942 - val_mean_absolute_error: 31988.0676\n",
      "Epoch 3321/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3035749334.3918 - mean_absolute_error: 40888.9793 - val_loss: 2448926947.8488 - val_mean_absolute_error: 28805.9908\n",
      "Epoch 3322/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3199847429.6938 - mean_absolute_error: 41104.9633 - val_loss: 2267896502.1031 - val_mean_absolute_error: 27542.7980\n",
      "Epoch 3323/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3386452254.2207 - mean_absolute_error: 43700.6917 - val_loss: 2506869076.4536 - val_mean_absolute_error: 28422.4678\n",
      "Epoch 3324/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3079650956.3730 - mean_absolute_error: 40985.6110 - val_loss: 2232729082.7216 - val_mean_absolute_error: 27598.0095\n",
      "Epoch 3325/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 2955220581.3926 - mean_absolute_error: 40907.8920 - val_loss: 2103585356.0962 - val_mean_absolute_error: 25823.9316\n",
      "Epoch 3326/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3143325164.2908 - mean_absolute_error: 42186.5970 - val_loss: 2281879848.4674 - val_mean_absolute_error: 26494.9449\n",
      "Epoch 3327/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3397269804.3456 - mean_absolute_error: 42960.5538 - val_loss: 2922521199.2852 - val_mean_absolute_error: 30670.4897\n",
      "Epoch 3328/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 2913295071.5894 - mean_absolute_error: 40469.9713 - val_loss: 2726957129.8969 - val_mean_absolute_error: 29522.1730\n",
      "Epoch 3329/5000\n",
      "1169/1169 [==============================] - 0s 380us/step - loss: 2996004190.3849 - mean_absolute_error: 40218.6591 - val_loss: 2376985562.1718 - val_mean_absolute_error: 27776.2486\n",
      "Epoch 3330/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 2963620397.5500 - mean_absolute_error: 40986.1003 - val_loss: 2450114977.8694 - val_mean_absolute_error: 29261.4075\n",
      "Epoch 3331/5000\n",
      "1169/1169 [==============================] - 0s 351us/step - loss: 2923868844.5646 - mean_absolute_error: 40140.9235 - val_loss: 2227598824.2474 - val_mean_absolute_error: 27692.9807\n",
      "Epoch 3332/5000\n",
      "1169/1169 [==============================] - 0s 405us/step - loss: 3299425247.0419 - mean_absolute_error: 41981.7737 - val_loss: 2644746572.0962 - val_mean_absolute_error: 30490.4498\n",
      "Epoch 3333/5000\n",
      "1169/1169 [==============================] - 0s 405us/step - loss: 3088487904.7938 - mean_absolute_error: 41653.5113 - val_loss: 2251588811.6564 - val_mean_absolute_error: 27597.9649\n",
      "Epoch 3334/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3364875437.8785 - mean_absolute_error: 43214.7913 - val_loss: 2360046682.6117 - val_mean_absolute_error: 27852.3319\n",
      "Epoch 3335/5000\n",
      "1169/1169 [==============================] - 0s 375us/step - loss: 3072641445.1189 - mean_absolute_error: 42261.7419 - val_loss: 2421590120.2474 - val_mean_absolute_error: 28183.8414\n",
      "Epoch 3336/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1169 [==============================] - 0s 361us/step - loss: 3361349892.3798 - mean_absolute_error: 41334.1024 - val_loss: 2666791001.7320 - val_mean_absolute_error: 28831.7975\n",
      "Epoch 3337/5000\n",
      "1169/1169 [==============================] - 0s 388us/step - loss: 3175628446.5492 - mean_absolute_error: 41933.8001 - val_loss: 2386193027.7388 - val_mean_absolute_error: 26624.6384\n",
      "Epoch 3338/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3255858443.1685 - mean_absolute_error: 41752.9094 - val_loss: 2051826257.3746 - val_mean_absolute_error: 25979.2512\n",
      "Epoch 3339/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 2963668927.8358 - mean_absolute_error: 40290.7015 - val_loss: 1857984046.4055 - val_mean_absolute_error: 25095.9528\n",
      "Epoch 3340/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3015674401.9435 - mean_absolute_error: 42144.4373 - val_loss: 2504008477.0309 - val_mean_absolute_error: 29193.4799\n",
      "Epoch 3341/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3193559292.0582 - mean_absolute_error: 42255.3761 - val_loss: 2417611181.3058 - val_mean_absolute_error: 28365.9743\n",
      "Epoch 3342/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3446634502.7887 - mean_absolute_error: 42689.3689 - val_loss: 2330508233.0172 - val_mean_absolute_error: 27424.3120\n",
      "Epoch 3343/5000\n",
      "1169/1169 [==============================] - 0s 362us/step - loss: 3340415228.4962 - mean_absolute_error: 41955.2209 - val_loss: 3578709971.5739 - val_mean_absolute_error: 34271.6601\n",
      "Epoch 3344/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3199776728.2532 - mean_absolute_error: 42533.0163 - val_loss: 1832470798.5155 - val_mean_absolute_error: 25371.0432\n",
      "Epoch 3345/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3100544956.7699 - mean_absolute_error: 40544.7040 - val_loss: 2047822708.5636 - val_mean_absolute_error: 27167.1219\n",
      "Epoch 3346/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3378659873.5056 - mean_absolute_error: 42161.8278 - val_loss: 2708557982.7904 - val_mean_absolute_error: 31589.5239\n",
      "Epoch 3347/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3088251932.6878 - mean_absolute_error: 41493.1272 - val_loss: 2370241656.9622 - val_mean_absolute_error: 29164.1995\n",
      "Epoch 3348/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3433649860.6536 - mean_absolute_error: 42790.8449 - val_loss: 2323507849.6770 - val_mean_absolute_error: 28932.6803\n",
      "Epoch 3349/5000\n",
      "1169/1169 [==============================] - 0s 352us/step - loss: 3380781426.5321 - mean_absolute_error: 43265.6434 - val_loss: 2470038403.5189 - val_mean_absolute_error: 29773.5493\n",
      "Epoch 3350/5000\n",
      "1169/1169 [==============================] - 0s 342us/step - loss: 3041044022.3097 - mean_absolute_error: 41980.0749 - val_loss: 1985515223.9725 - val_mean_absolute_error: 26756.8146\n",
      "Epoch 3351/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3233540118.3370 - mean_absolute_error: 42197.0945 - val_loss: 2284797703.0378 - val_mean_absolute_error: 29206.8507\n",
      "Epoch 3352/5000\n",
      "1169/1169 [==============================] - 0s 379us/step - loss: 3497564351.3978 - mean_absolute_error: 44500.0407 - val_loss: 2495214003.9038 - val_mean_absolute_error: 30011.9886\n",
      "Epoch 3353/5000\n",
      "1169/1169 [==============================] - 0s 366us/step - loss: 3431725039.3567 - mean_absolute_error: 43200.6203 - val_loss: 2387433285.0584 - val_mean_absolute_error: 29390.3151\n",
      "Epoch 3354/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3572400808.4038 - mean_absolute_error: 42975.9493 - val_loss: 1940503123.1340 - val_mean_absolute_error: 25148.1280\n",
      "Epoch 3355/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3326923674.8263 - mean_absolute_error: 42416.0568 - val_loss: 2563095189.5533 - val_mean_absolute_error: 28480.3249\n",
      "Epoch 3356/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3249298005.6253 - mean_absolute_error: 41036.0788 - val_loss: 2265136313.6220 - val_mean_absolute_error: 27415.1312\n",
      "Epoch 3357/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 2918767753.5261 - mean_absolute_error: 40892.7478 - val_loss: 2221270820.5086 - val_mean_absolute_error: 27571.2876\n",
      "Epoch 3358/5000\n",
      "1169/1169 [==============================] - 0s 370us/step - loss: 3230886871.2678 - mean_absolute_error: 41643.9029 - val_loss: 1890460085.2234 - val_mean_absolute_error: 25386.7146\n",
      "Epoch 3359/5000\n",
      "1169/1169 [==============================] - 0s 372us/step - loss: 3242733064.7596 - mean_absolute_error: 42077.4818 - val_loss: 2100055232.2199 - val_mean_absolute_error: 26629.5553\n",
      "Epoch 3360/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3127538405.0642 - mean_absolute_error: 42452.4500 - val_loss: 2520865464.7423 - val_mean_absolute_error: 28764.4842\n",
      "Epoch 3361/5000\n",
      "1169/1169 [==============================] - 0s 354us/step - loss: 3220612393.8272 - mean_absolute_error: 42095.7801 - val_loss: 1950785900.6460 - val_mean_absolute_error: 25456.7517\n",
      "Epoch 3362/5000\n",
      "1169/1169 [==============================] - 0s 361us/step - loss: 3088345170.7784 - mean_absolute_error: 41644.4991 - val_loss: 2398327109.0584 - val_mean_absolute_error: 27871.2587\n",
      "Epoch 3363/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3172213789.1257 - mean_absolute_error: 42013.5379 - val_loss: 2033515588.1787 - val_mean_absolute_error: 25774.3665\n",
      "Epoch 3364/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3293601877.1873 - mean_absolute_error: 41372.2975 - val_loss: 2159952548.5086 - val_mean_absolute_error: 26248.9138\n",
      "Epoch 3365/5000\n",
      "1169/1169 [==============================] - 0s 358us/step - loss: 3010753883.9760 - mean_absolute_error: 41127.8810 - val_loss: 1952030757.8282 - val_mean_absolute_error: 25000.3218\n",
      "Epoch 3366/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 2895391608.6638 - mean_absolute_error: 40396.6228 - val_loss: 2807649901.9656 - val_mean_absolute_error: 30738.2818\n",
      "Epoch 3367/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3255262769.6014 - mean_absolute_error: 42430.1819 - val_loss: 2063491311.7251 - val_mean_absolute_error: 26416.0154\n",
      "Epoch 3368/5000\n",
      "1169/1169 [==============================] - 0s 345us/step - loss: 3263945677.1942 - mean_absolute_error: 41630.0953 - val_loss: 2441621674.2268 - val_mean_absolute_error: 28565.2514\n",
      "Epoch 3369/5000\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 3050095845.7211 - mean_absolute_error: 41877.1767 - val_loss: 2141054891.9863 - val_mean_absolute_error: 26690.3393\n",
      "Epoch 3370/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3169995931.3738 - mean_absolute_error: 42419.6011 - val_loss: 2246218393.0722 - val_mean_absolute_error: 27706.9266\n",
      "Epoch 3371/5000\n",
      "1169/1169 [==============================] - 0s 359us/step - loss: 3131892092.2772 - mean_absolute_error: 42093.7103 - val_loss: 2235702765.0859 - val_mean_absolute_error: 27911.1460\n",
      "Epoch 3372/5000\n",
      "1169/1169 [==============================] - 0s 367us/step - loss: 3392232322.6279 - mean_absolute_error: 41605.3242 - val_loss: 2533136182.9828 - val_mean_absolute_error: 28731.0241\n",
      "Epoch 3373/5000\n",
      "1169/1169 [==============================] - 0s 324us/step - loss: 3068166522.4157 - mean_absolute_error: 42022.2276 - val_loss: 2214793970.3643 - val_mean_absolute_error: 27445.1109\n",
      "Epoch 3374/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3043755753.4440 - mean_absolute_error: 41122.8359 - val_loss: 2470653754.9416 - val_mean_absolute_error: 28822.1966\n",
      "Epoch 3375/5000\n",
      "1169/1169 [==============================] - 0s 357us/step - loss: 3032279059.0522 - mean_absolute_error: 40025.1442 - val_loss: 2370211463.9175 - val_mean_absolute_error: 29671.8022\n",
      "Epoch 3376/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3123687431.2267 - mean_absolute_error: 41667.4452 - val_loss: 2232674611.0241 - val_mean_absolute_error: 27993.8579\n",
      "Epoch 3377/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3294555791.6578 - mean_absolute_error: 41561.4398 - val_loss: 2221495169.3196 - val_mean_absolute_error: 27357.5438\n",
      "Epoch 3378/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3231416207.2198 - mean_absolute_error: 41985.0500 - val_loss: 2791815162.7216 - val_mean_absolute_error: 31302.1647\n",
      "Epoch 3379/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3024773009.1908 - mean_absolute_error: 41135.3764 - val_loss: 2592937114.8316 - val_mean_absolute_error: 29953.2664\n",
      "Epoch 3380/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3354440790.9393 - mean_absolute_error: 42690.5260 - val_loss: 2316913625.7320 - val_mean_absolute_error: 28187.8507\n",
      "Epoch 3381/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3141703602.8058 - mean_absolute_error: 41130.1629 - val_loss: 1894408767.7801 - val_mean_absolute_error: 25648.1732\n",
      "Epoch 3382/5000\n",
      "1169/1169 [==============================] - 0s 347us/step - loss: 2852829496.2806 - mean_absolute_error: 39405.5880 - val_loss: 2256591618.6392 - val_mean_absolute_error: 28492.1848\n",
      "Epoch 3383/5000\n",
      "1169/1169 [==============================] - 0s 339us/step - loss: 2987564034.6279 - mean_absolute_error: 40938.6667 - val_loss: 2301057943.3127 - val_mean_absolute_error: 28249.8102\n",
      "Epoch 3384/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3185853484.2361 - mean_absolute_error: 42138.2103 - val_loss: 2308910111.2302 - val_mean_absolute_error: 27382.4412\n",
      "Epoch 3385/5000\n",
      "1169/1169 [==============================] - 0s 350us/step - loss: 3208027360.6843 - mean_absolute_error: 41127.6808 - val_loss: 2199666754.4192 - val_mean_absolute_error: 27087.9101\n",
      "Epoch 3386/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 2874557239.4046 - mean_absolute_error: 40742.6938 - val_loss: 2046169314.5292 - val_mean_absolute_error: 26304.3184\n",
      "Epoch 3387/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3114136365.9880 - mean_absolute_error: 40925.2866 - val_loss: 1882428810.1168 - val_mean_absolute_error: 23810.7283\n",
      "Epoch 3388/5000\n",
      "1169/1169 [==============================] - 0s 398us/step - loss: 3177852987.3464 - mean_absolute_error: 41959.3771 - val_loss: 2088645794.3093 - val_mean_absolute_error: 26122.8016\n",
      "Epoch 3389/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3128681551.9316 - mean_absolute_error: 42094.5793 - val_loss: 1843743893.1134 - val_mean_absolute_error: 24255.6941\n",
      "Epoch 3390/5000\n",
      "1169/1169 [==============================] - 0s 333us/step - loss: 3378034466.6005 - mean_absolute_error: 42941.9556 - val_loss: 2107149686.3230 - val_mean_absolute_error: 25799.1271\n",
      "Epoch 3391/5000\n",
      "1169/1169 [==============================] - 0s 360us/step - loss: 3036138815.9453 - mean_absolute_error: 41091.2459 - val_loss: 2215033852.9210 - val_mean_absolute_error: 26763.4966\n",
      "Epoch 3392/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3144365116.6604 - mean_absolute_error: 42465.3288 - val_loss: 2079820168.3574 - val_mean_absolute_error: 25831.3018\n",
      "Epoch 3393/5000\n",
      "1169/1169 [==============================] - 0s 353us/step - loss: 3180495202.7648 - mean_absolute_error: 42667.5265 - val_loss: 2576979851.4364 - val_mean_absolute_error: 29703.2988\n",
      "Epoch 3394/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 2928207559.9384 - mean_absolute_error: 41160.6251 - val_loss: 2053107781.9381 - val_mean_absolute_error: 26835.1874\n",
      "Epoch 3395/5000\n",
      "1169/1169 [==============================] - 0s 389us/step - loss: 3230366030.6176 - mean_absolute_error: 42248.3457 - val_loss: 2141887481.8419 - val_mean_absolute_error: 27102.8436\n",
      "Epoch 3396/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 2999832559.5757 - mean_absolute_error: 40748.5599 - val_loss: 2160060623.1753 - val_mean_absolute_error: 26037.4057\n",
      "Epoch 3397/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3100748092.6604 - mean_absolute_error: 40773.8607 - val_loss: 1737455776.3299 - val_mean_absolute_error: 24068.8230\n",
      "Epoch 3398/5000\n",
      "1169/1169 [==============================] - 0s 356us/step - loss: 3049803331.6681 - mean_absolute_error: 41367.1252 - val_loss: 2251755419.2715 - val_mean_absolute_error: 27071.4512\n",
      "Epoch 3399/5000\n",
      "1169/1169 [==============================] - 0s 340us/step - loss: 3141997417.9914 - mean_absolute_error: 42095.8652 - val_loss: 1879029964.5361 - val_mean_absolute_error: 25633.0090\n",
      "Epoch 3400/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 3477411981.9059 - mean_absolute_error: 42577.5027 - val_loss: 1842398523.8213 - val_mean_absolute_error: 26004.4798\n",
      "Epoch 3401/5000\n",
      "1169/1169 [==============================] - 0s 365us/step - loss: 3137233161.3071 - mean_absolute_error: 41834.8962 - val_loss: 1875573484.6460 - val_mean_absolute_error: 25758.8579\n",
      "Epoch 3402/5000\n",
      "1169/1169 [==============================] - 0s 335us/step - loss: 3133840013.4679 - mean_absolute_error: 41607.7588 - val_loss: 1732254195.4639 - val_mean_absolute_error: 25001.7290\n",
      "Epoch 3403/5000\n",
      "1169/1169 [==============================] - 0s 364us/step - loss: 3008739483.0453 - mean_absolute_error: 40664.6020 - val_loss: 1877983325.0309 - val_mean_absolute_error: 25539.3936\n",
      "Epoch 3404/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3425657306.3336 - mean_absolute_error: 42846.1250 - val_loss: 1819631013.6082 - val_mean_absolute_error: 24919.9224\n",
      "Epoch 3405/5000\n",
      "1169/1169 [==============================] - 0s 363us/step - loss: 3089372133.7211 - mean_absolute_error: 41950.3316 - val_loss: 2011509310.6804 - val_mean_absolute_error: 26177.7624\n",
      "Epoch 3406/5000\n",
      "1169/1169 [==============================] - 0s 334us/step - loss: 2990384621.8238 - mean_absolute_error: 40139.5365 - val_loss: 2068673830.7079 - val_mean_absolute_error: 26418.4523\n",
      "Epoch 3407/5000\n",
      "1169/1169 [==============================] - 0s 331us/step - loss: 3203040904.2121 - mean_absolute_error: 41596.1345 - val_loss: 2403336549.1684 - val_mean_absolute_error: 28575.6235\n",
      "Epoch 3408/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 3007813174.5287 - mean_absolute_error: 40895.9061 - val_loss: 1824367228.4811 - val_mean_absolute_error: 24571.3489\n",
      "Epoch 3409/5000\n",
      "1169/1169 [==============================] - 0s 348us/step - loss: 2722868188.9615 - mean_absolute_error: 39039.6369 - val_loss: 1886709696.6598 - val_mean_absolute_error: 24864.7957\n",
      "Epoch 3410/5000\n",
      "1169/1169 [==============================] - 1s 443us/step - loss: 3174460179.9281 - mean_absolute_error: 42410.1294 - val_loss: 2223711296.6598 - val_mean_absolute_error: 28740.3230\n",
      "Epoch 3411/5000\n",
      "1169/1169 [==============================] - 0s 349us/step - loss: 3187245356.2361 - mean_absolute_error: 41601.4461 - val_loss: 2093467363.1890 - val_mean_absolute_error: 26820.6996\n",
      "Epoch 3412/5000\n",
      "1169/1169 [==============================] - 0s 392us/step - loss: 3081487603.9555 - mean_absolute_error: 41842.7256 - val_loss: 2363224220.5911 - val_mean_absolute_error: 29044.9253\n",
      "Epoch 3413/5000\n",
      "1169/1169 [==============================] - 0s 344us/step - loss: 2925417419.0043 - mean_absolute_error: 40311.9855 - val_loss: 2804034649.7320 - val_mean_absolute_error: 30557.6853\n",
      "Epoch 3414/5000\n",
      " 860/1169 [=====================>........] - ETA: 0s - loss: 2766899488.7442 - mean_absolute_error: 40353.5186"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function IsSequence> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-bf7549a8d8e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0mfeed_handles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m       \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_dict_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_feed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten_dict_items\u001b[0;34m(dictionary)\u001b[0m\n\u001b[1;32m    302\u001b[0m   \u001b[0mflat_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_dictionary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mis_sequence\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function IsSequence> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val))\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37066.58848612858\n",
      "37891.79349146725\n"
     ]
    }
   ],
   "source": [
    "decoderLeaky1 = sqrt(2031421750)\n",
    "decoderLeaky2 = sqrt(1373931982)\n",
    "print(decoderLeaky2)\n",
    "fatLeaky = sqrt(1435788014)\n",
    "print(fatLeaky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='iii'></a>\n",
    "# III. Exploratory Data Analysis\n",
    "\n",
    "Now that we've cleaned up our data, at this point you would usually do a careful, thorough investigation into the patterns, outliers, and relationships between your features and the response variable, and the features with one another. This is often the most creative - and hardest - part of the Data Science Workflow. While you will be conducting more EDA on your cleaned dataset in future weeks, for now we're just going to go over some essentials of EDA and a couple of visualizations for you to interpret. \n",
    "\n",
    "There are a few things you should watch for when you conduct EDA. You should always check for outliers, to get a better idea of where your model may go wrong. We're going to skip this step for now, but you should check for outliers in this dataset when you work with your team or over SUSA Office Hours! EDA also helps give you a more explicit understanding of your data, and allows you to make educated decisions in your modeling design.\n",
    "\n",
    "For example, to better guess which features we should include in our model, there are a few guidelines that EDA can shed light upon. First, it is generally a bad idea to use too many features that are correlated (a.k.a high colinearity). Secondly, we can use EDA to see which features correlate with our response variable, `SalePrice` - these features will likely be useful in forming our model. \n",
    "\n",
    "## Avoiding Colinearity\n",
    "\n",
    "**Colinear** features are variables that can be exactly represented with a linear relationship. It is a statistical fact that you cannot make a linear model for features that are in any way colinear. Even if two features are not colinear, if they are highly correlated or nearly colinear, you want to avoid using both features if possible. This is because our model will get confused about which feature affects our response variable, since both variables affect each other too. \n",
    "\n",
    "You can check for high correlation with a **correlation plot**, which uses color to indicate which pairs of features are correlated. Below is a correlation plot of features with an absolute correlation of .7 or above. \n",
    "\n",
    "![](GRAPHICS/corr_features.png)\n",
    "\n",
    "> Which pairs of features are highly correlated? When you select your features, make sure you don't select pairs of features with a pinkish or greenish correlation square. \n",
    "\n",
    "One thing to keep aware of is that correlation only indicates what you might intuit it to mean for linear relationships. You can use a **pairs plot** to see the pairwise relationships between features in your data. \n",
    "\n",
    "![](GRAPHICS/corr_pairs.png)\n",
    "\n",
    "> Which of the correlated features above show a linear trend in the related pair plot?\n",
    "\n",
    "## Features Correlated with the Response Variable\n",
    "\n",
    "To inform which features will be important in predicting `SalePrice`, it would be useful to see which of the 79 features are correlated with `SalePrice`. Below is a matrix of plots - each plot is a simple linear regression between an individual numerical feature with `SalePrice`. \n",
    "\n",
    "![](GRAPHICS/y_pairs.png)\n",
    "\n",
    "> Which of these features are associated with a high `SalePrice`? How might this inform your model selection?\n",
    "\n",
    "There is definitely a lot more to be said on how EDA can inform your modeling process and verify your model assumptions. For more information, check out the `r3` workshop or stay tuned for later weeks' expansionary material on EDA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='iiii'></a>\n",
    "# IV. Modeling\n",
    "\n",
    "An important part to any good statisticians toolkit.\n",
    "\n",
    "> ***What I cannot create, I cannot understand.***\n",
    ">\n",
    ">  \\- Richard Feynman (Honorary Statistician)\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "Modeling begins with a guess. To create a model for data, you must guess the relevant features necessary to recreate the data distribution. Even among expert statisticians, this is regarded as a hard skill, bordering on art. Oftentimes, industry experts will provide insight as to what the right features to select are, and stasticians (like ourselves) will have to create a model from those features.\n",
    "\n",
    "There are lots of mathematical principles to guide your feature selection. So we'll begin with a theorem.\n",
    "> **Theorem 1.1**\n",
    ">\n",
    "> -- just kidding we're not that evil\n",
    "\n",
    "But seriously, there are lots of principles on how to do this correctly. But for now, do whatever feels intuitive. Explore. Create. Be inefficient. Only through walking can you learn to run. \n",
    "\n",
    "## A First Approach to Machine Learning: Linear Regression\n",
    "\n",
    "Linear regression is the most important tool in a modeler's toolkit. It's the basis for which almost all other modeling techniques arise. Essentially, it's a way to model a variable out a weighted combination of other random variables in the data.\n",
    "\n",
    "$$ \\hat{Y} = aA + bB +cC + \\ldots $$\n",
    "where **a, b, c** are (scalar) weight values, and **A, B, C** are features in the dataset, and **$\\hat{Y}$** is our modeled variable.\n",
    "\n",
    "Mathematicians have derivatives, functions, and domains.\n",
    "\n",
    "Statisticians have linear regression, data, and raw untamed IQ.\n",
    "\n",
    "Okay so the gameplan is to give an example of how to **a) select features** and how to **b) create a model**. Specifically, we ask you to model the `SalePrice` column of the dataframe from any combination of features you choose.\n",
    "\n",
    "For our linear model, we will be using the linear regression model from scikit learn. The docs are provided [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "#### [Meta Tips]\n",
    "Good ways to approach things you are not familiar with: here's my steps for this\n",
    "1. What is a linear model?\n",
    "2. What inputs does it take? What ouput does it give?\n",
    "3. How do I get inputs from the Pandas dataframe into a format that works with the Linear Regression model?\n",
    "4. Did I run the model correctly?\n",
    "5. How can I tell?\n",
    "6. What are other inputs I can try?\n",
    "\n",
    "... etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    208500\n",
       "1    181500\n",
       "2    223500\n",
       "3    140000\n",
       "4    250000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's what our 'SalePrice' column looks like\n",
    "clean['SalePrice'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8450  9600 11250  9550 14260]\n",
      "[3 3 3 3 3]\n",
      "[5 8 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# dataframe['column'].values returns the numpy array of that column\n",
    "# to check the type of each array, you can use `.dtype` on any numpy array\n",
    "\n",
    "print(clean['LotArea'].values[:5])\n",
    "print(clean['Utilities'].values[:5])\n",
    "print(clean['OverallCond'].values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MasVnrArea  ExterQual  ExterCond  BsmtQual  BsmtCond  BsmtExposure  \\\n",
       "0       196.0          3          2         4         3             1   \n",
       "1         0.0          2          2         4         3             4   \n",
       "2       162.0          3          2         4         3             2   \n",
       "3         0.0          2          2         3         4             1   \n",
       "4       350.0          3          2         4         3             3   \n",
       "\n",
       "   BsmtFinType1  BsmtFinSF1  BsmtFinType2  BsmtFinSF2  \n",
       "0             6         706             1           0  \n",
       "1             5         978             1           0  \n",
       "2             6         486             1           0  \n",
       "3             5         216             1           0  \n",
       "4             6         655             1           0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean[clean.columns[10:20]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.960e+02, 0.000e+00, 1.620e+02, 3.500e+02, 1.860e+02, 2.400e+02,\n",
       "       2.860e+02, 3.060e+02, 2.120e+02, 1.800e+02, 3.800e+02, 2.810e+02,\n",
       "       6.400e+02, 2.000e+02, 2.460e+02, 1.320e+02, 6.500e+02, 1.010e+02,\n",
       "       4.120e+02, 2.720e+02, 4.560e+02, 1.031e+03, 1.780e+02, 5.730e+02,\n",
       "       3.440e+02, 2.870e+02, 1.670e+02, 1.115e+03, 4.000e+01, 1.040e+02,\n",
       "       5.760e+02, 4.430e+02, 4.680e+02, 6.600e+01, 2.200e+01, 2.840e+02,\n",
       "       7.600e+01, 2.030e+02, 6.800e+01, 1.830e+02, 4.800e+01, 2.800e+01,\n",
       "       3.360e+02, 6.000e+02, 7.680e+02, 4.800e+02, 2.200e+02, 1.840e+02,\n",
       "       1.129e+03, 1.160e+02, 1.350e+02, 2.660e+02, 8.500e+01, 3.090e+02,\n",
       "       1.360e+02, 2.880e+02, 7.000e+01, 3.200e+02, 5.000e+01, 1.200e+02,\n",
       "       4.360e+02, 2.520e+02, 8.400e+01, 6.640e+02, 2.260e+02, 3.000e+02,\n",
       "       6.530e+02, 1.120e+02, 4.910e+02, 2.680e+02, 7.480e+02, 9.800e+01,\n",
       "       2.750e+02, 1.380e+02, 2.050e+02, 2.620e+02, 1.280e+02, 2.600e+02,\n",
       "       1.530e+02, 6.400e+01, 3.120e+02, 1.600e+01, 9.220e+02, 1.420e+02,\n",
       "       2.900e+02, 1.270e+02, 5.060e+02, 2.970e+02,       nan, 6.040e+02,\n",
       "       2.540e+02, 3.600e+01, 1.020e+02, 4.720e+02, 4.810e+02, 1.080e+02,\n",
       "       3.020e+02, 1.720e+02, 3.990e+02, 2.700e+02, 4.600e+01, 2.100e+02,\n",
       "       1.740e+02, 3.480e+02, 3.150e+02, 2.990e+02, 3.400e+02, 1.660e+02,\n",
       "       7.200e+01, 3.100e+01, 3.400e+01, 2.380e+02, 1.600e+03, 3.650e+02,\n",
       "       5.600e+01, 1.500e+02, 2.780e+02, 2.560e+02, 2.250e+02, 3.700e+02,\n",
       "       3.880e+02, 1.750e+02, 2.960e+02, 1.460e+02, 1.130e+02, 1.760e+02,\n",
       "       6.160e+02, 3.000e+01, 1.060e+02, 8.700e+02, 3.620e+02, 5.300e+02,\n",
       "       5.000e+02, 5.100e+02, 2.470e+02, 3.050e+02, 2.550e+02, 1.250e+02,\n",
       "       1.000e+02, 4.320e+02, 1.260e+02, 4.730e+02, 7.400e+01, 1.450e+02,\n",
       "       2.320e+02, 3.760e+02, 4.200e+01, 1.610e+02, 1.100e+02, 1.800e+01,\n",
       "       2.240e+02, 2.480e+02, 8.000e+01, 3.040e+02, 2.150e+02, 7.720e+02,\n",
       "       4.350e+02, 3.780e+02, 5.620e+02, 1.680e+02, 8.900e+01, 2.850e+02,\n",
       "       3.600e+02, 9.400e+01, 3.330e+02, 9.210e+02, 7.620e+02, 5.940e+02,\n",
       "       2.190e+02, 1.880e+02, 4.790e+02, 5.840e+02, 1.820e+02, 2.500e+02,\n",
       "       2.920e+02, 2.450e+02, 2.070e+02, 8.200e+01, 9.700e+01, 3.350e+02,\n",
       "       2.080e+02, 4.200e+02, 1.700e+02, 4.590e+02, 2.800e+02, 9.900e+01,\n",
       "       1.920e+02, 2.040e+02, 2.330e+02, 1.560e+02, 4.520e+02, 5.130e+02,\n",
       "       2.610e+02, 1.640e+02, 2.590e+02, 2.090e+02, 2.630e+02, 2.160e+02,\n",
       "       3.510e+02, 6.600e+02, 3.810e+02, 5.400e+01, 5.280e+02, 2.580e+02,\n",
       "       4.640e+02, 5.700e+01, 1.470e+02, 1.170e+03, 2.930e+02, 6.300e+02,\n",
       "       4.660e+02, 1.090e+02, 4.100e+01, 1.600e+02, 2.890e+02, 6.510e+02,\n",
       "       1.690e+02, 9.500e+01, 4.420e+02, 2.020e+02, 3.380e+02, 8.940e+02,\n",
       "       3.280e+02, 6.730e+02, 6.030e+02, 1.000e+00, 3.750e+02, 9.000e+01,\n",
       "       3.800e+01, 1.570e+02, 1.100e+01, 1.400e+02, 1.300e+02, 1.480e+02,\n",
       "       8.600e+02, 4.240e+02, 1.047e+03, 2.430e+02, 8.160e+02, 3.870e+02,\n",
       "       2.230e+02, 1.580e+02, 1.370e+02, 1.150e+02, 1.890e+02, 2.740e+02,\n",
       "       1.170e+02, 6.000e+01, 1.220e+02, 9.200e+01, 4.150e+02, 7.600e+02,\n",
       "       2.700e+01, 7.500e+01, 3.610e+02, 1.050e+02, 3.420e+02, 2.980e+02,\n",
       "       5.410e+02, 2.360e+02, 1.440e+02, 4.230e+02, 4.400e+01, 1.510e+02,\n",
       "       9.750e+02, 4.500e+02, 2.300e+02, 5.710e+02, 2.400e+01, 5.300e+01,\n",
       "       2.060e+02, 1.400e+01, 3.240e+02, 2.950e+02, 3.960e+02, 6.700e+01,\n",
       "       1.540e+02, 4.250e+02, 4.500e+01, 1.378e+03, 3.370e+02, 1.490e+02,\n",
       "       1.430e+02, 5.100e+01, 1.710e+02, 2.340e+02, 6.300e+01, 7.660e+02,\n",
       "       3.200e+01, 8.100e+01, 1.630e+02, 5.540e+02, 2.180e+02, 6.320e+02,\n",
       "       1.140e+02, 5.670e+02, 3.590e+02, 4.510e+02, 6.210e+02, 7.880e+02,\n",
       "       8.600e+01, 7.960e+02, 3.910e+02, 2.280e+02, 8.800e+01, 1.650e+02,\n",
       "       4.280e+02, 4.100e+02, 5.640e+02, 3.680e+02, 3.180e+02, 5.790e+02,\n",
       "       6.500e+01, 7.050e+02, 4.080e+02, 2.440e+02, 1.230e+02, 3.660e+02,\n",
       "       7.310e+02, 4.480e+02, 2.940e+02, 3.100e+02, 2.370e+02, 4.260e+02,\n",
       "       9.600e+01, 4.380e+02, 1.940e+02, 1.190e+02])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean['MasVnrArea'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression # There are lots of other models from this module you can try!\n",
    "\n",
    "def get_features(data, col_list, y_name):\n",
    "    \"\"\"\n",
    "    Function to return a numpy matrix of pandas dataframe features. \n",
    "    This is not a smart function - although it does drop rows with NA values. It might break. \n",
    "    \n",
    "    data(DataFrame): e.g. train, clean\n",
    "    col_list(list): list of columns to extract data from\n",
    "    y_name(string): name of the column you to treat as the y column\n",
    "    \n",
    "    Ideally returns np.array of shape (len(data), len(col_list)), and one of shape (len(data), len(col_list))\n",
    "    \"\"\"\n",
    "    \n",
    "    # keep track of numpy values\n",
    "    feature_matrix = data[col_list + [y_name]].dropna().values\n",
    "    return feature_matrix[:, :-1], feature_matrix[:, -1]\n",
    "    \n",
    "\n",
    "# Initialize our linear regression model\n",
    "first_model = LinearRegression()\n",
    "\n",
    "# X is a matrix of inputs, Y is the variable we are trying to learn\n",
    "feature_cols = ['LotArea', 'Utilities', 'OverallCond', 'BsmtFinSF1', 'MasVnrArea']\n",
    "X, Y = get_features(clean, feature_cols, 'SalePrice')\n",
    "\n",
    "# Fit the model to the data\n",
    "first_model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='v'></a>\n",
    "# V. Model Evaluation\n",
    "\n",
    "Now it's time to actually see how your model performed!\n",
    "\n",
    "Just mess around with the `.predict` method of your model object. See what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prediction for a house with 0 LotArea, 0 Utilities, and a rating of 0 OverallCond is:\n",
      "-29399.97\n"
     ]
    }
   ],
   "source": [
    "# for example\n",
    "prediction = first_model.predict(np.zeros((1,len(feature_cols))))\n",
    "print(\"Our prediction for a house with 0 LotArea, 0 Utilities, and a rating of 0 OverallCond is:\\n{:.2f}\".format(prediction[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our bias is pretty damn high. Obviously, we are extrapolating out of our dataset here, but it immediately gives us some intuition as to what the average price looks like. Actually that probably isn't true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 coeff: 0.329\n",
      "bias: -29399.97\n"
     ]
    }
   ],
   "source": [
    "r2_coeff = first_model.score(X, Y)\n",
    "bias = first_model.intercept_\n",
    "print(\"r^2 coeff: {:.3f}\".format(r2_coeff))\n",
    "print(\"bias: {:.2f}\".format(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the actual loss of the model, we'll compute the mean squared error on the train dataset. **NOTE:** Be wary here of overfitting. We are training and evaluating our data on the same dataset. However, we are using linear models which are too simple to overfit our data, so it makes a decent way to introduce modeling. In the future, ~20% of the dataset should be set aside for evaluating the model. This is to make sure models *generalize* their predictions.\n",
    "\n",
    "So how does your collection of selected features perform on predicting `SalePrice` using a multivariate linear model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error loss of our model: 4215215723.11\n"
     ]
    }
   ],
   "source": [
    "def get_loss(model, data, col_list, true_col_name):\n",
    "    \"\"\"Returns L2 loss between Y_hat and true values\n",
    "    \n",
    "    model(Model object): model we use to predict values\n",
    "    data(DataFrame): where we get our data from\n",
    "    col_list(list): list of column names that our model uses to predict on\n",
    "    true_col_name(String): name of the column in data we wish to predict\n",
    "    \"\"\"\n",
    "    X, Y_true = get_features(data, col_list, true_col_name)\n",
    "    Y_hat = model.predict(X)\n",
    "    return np.mean((Y_true-Y_hat)**2)\n",
    "\n",
    "loss = get_loss(model=first_model, data=clean, col_list=feature_cols, true_col_name='SalePrice')\n",
    "print(\"Mean Squared Error loss of our model: {:.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "# Conclusion\n",
    "\n",
    "This ends the first of our four collaborative sessions on the Kaggle Housing Prices competition. This week or the next would be a good time to come to a SUSA Office Hour and finish cleaning your dataset and getting more performant feature selections. This project will take much more work than was covered in this first hour, but as always, please email [`contact@arun.run`](mailto:contact@arun.run), [`prc@berkeley.edu`](mailto:prc@berkeley.edu), or [Noah Gundotra](mailto:noah.gundotra@berkeley.edu) or with any questions or concerns whatsoever. Happy machine learning!\n",
    "\n",
    "## Sneakpeek at SUSA Kaggle Competition II\n",
    "\n",
    "Next week, we're going to continue our initial modeling of the House Prices dataset with more EDA, a new algorithm for guaranteeing lack of colinearity called **Principal Component Analysis**, and cover concepts in **feature engineering**. The models we will be focusing on next week are **Polynomial Regression** and **Regularized Regression**. Stay tuned!\n",
    "\n",
    "<a id='reading'></a>\n",
    "# Additional Reading\n",
    "* For more information on the Kaggle API, a command-line program used to download and manage Kaggle datasets, visit the [Kaggle API Github page](https://github.com/Kaggle/kaggle-api)  \n",
    "* For an interactive guide to learning R and Python, visit [DataCamp](https://www.datacamp.com/) a paid tutorial website for learning data computing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
