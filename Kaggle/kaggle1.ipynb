{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUSA CX Kaggle Capstone\n",
    "## Part 1: Introduction, Exploratory Data Analysis, and Feature Selection\n",
    "### Hosted by and maintained by the [Statistics Undergraduate Students Association (SUSA)](https://susa.berkeley.edu). Originally authored by [Arun Ramamurthy](mailto:contact@arun.run), [Patrick Chao](mailto:prc@berkeley.edu), & [Noah Gundotra](mailto:noah.gundotra@berkeley.edu).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUSA CX Kaggle Capstone Project\n",
    "\n",
    "Welcome to the last four weeks of your semester in SUSA's Career Exploration committee! Now that you've participated in nearly a dozen workshops on Python, R, data science, and machine learning, we're going to guide you through a four-week collaborative Kaggle competition with your peers in Career Exploration. We want to give you the experience of working with real data, using real machine learning algorithms, in an educational setting. You will have to make use of your data computing skills in Python, dive into reading kernels on the Kaggle website, use visualization and feature engineering to improve your score, and maybe even pick up a few advanced deep learning models along the way. If this sounds a bit intimidating right now, do not fret! Your SUSA Mentors will be there to mentor you through the whole thing. So without further ado, let's get cracking!\n",
    "\n",
    "## What is Kaggle?\n",
    "\n",
    "### Kaggle Competition: Housing Prices\n",
    "\n",
    "In this project, we will be working with the [**Housing Prices**](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/) competition on the Kaggle website. The competition deals with accurately predicting the sales prices of houses in Ames, Iowa. More information on the dataset and competition will follow shortly.\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "## Accessing the `House Prices` Dataset\n",
    "\n",
    "While you can access these datasets online at the [Kaggle webpage for this competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data), we have already downloaded the data for you and placed it in the `crash-course/Kaggle/DATA/house-prices/` directory. \n",
    "\n",
    "## Logistics\n",
    "\n",
    "This project is going to be tough and long, but we will be there with you through the whole thing. Additionally, you won't be working alone - we have used your input to assign you into teams of 3 - 4 members. These will be your team members for the rest of the semester, so get to know each other a little!   \n",
    "\n",
    "The teams are as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data Science Workflow\n",
    "\n",
    "In general, there are a few key steps to begin working with a dataset. \n",
    "\n",
    "First, we need to **understand what the dataset actually is about**, and what we are trying to do with it. Key to this stage is understanding what each row of the dataset represents, as well as what each column indicates. You can read more about this dataset by looking at the dataset itself, or reading the data dictionary in `crash-course/Kaggle/DATA/house-prices/data_description.txt`.\n",
    "\n",
    "Second, before we can even do exploratory data analysis, we need to **clean our dataset**. It is very helpful to identify the size of the dataset, so we know how many samples we have. We need to determine a consistent method of dealing with missing values, such as setting them to a value, removing the feature entirely, interpolating values, etc. Other crucial steps are separating into training and validation, as well as creating elementary data plots.\n",
    "\n",
    "Third, we have **exploratory data analysis (EDA)**. The point of this phase is to inspect & visualize key relationships, trends, outliers, and issues with our data. By conducting EDA, we get a better sense of the underlying structure of our data, and which features are most important. Especially since we have 81 features, we would like to select the features that are most important to our analysis before we begin modeling `SalePrice`. Once we have an idea about which features to use and how they relate to one another, our modeling stage will be more informed and robust. \n",
    "\n",
    "Fourth, we have the **modeling phase**, consisting of **model selection** and **model training**. Here, we select a predictive model to train on our features, and then actually train the model! In this first week, we will be using linear regression as a first-pass. In later weeks of the SUSA CX Kaggle Capstone project, we will be using more advanced models like random forest and neural networks. Depending on the model we are using, it is important to verify the model's assumptions before fully pledging to that model. Additionally, we may use **validation** in this stage to select certain hyperparameters for our model selection.\n",
    "\n",
    "Finally, we have the **model evaluation phase**. Here, we compute a metric for our model's performance, usually by  summing the squared errors of the model's predictions on the test set. This stage allows us to effectively compare various data cleaning and modeling selection decisions, by giving us a single comparable value for performance across our potential models.\n",
    "\n",
    "## I. Understanding our Dataset \n",
    "Our dataset is about houses in Iowa! According to the Kaggle webpage, the competition is as follows:\n",
    "\n",
    "> Ask a home buyer to describe their dream house, and they probably won’t begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition’s dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "\n",
    "More explicitly, our dataset has 81 columns, or features: \n",
    "1. `SalePrice`, our response variable $Y$ that we are trying to predict accurately and precisely \n",
    "2. `Id`, a simple identification variable\n",
    "3. 79 explanatory variables $X_k$ that we can use to predict `SalePrice`. Some of the variables are categorical, and others are continuous quantitative. \n",
    "\n",
    "The goal of the next four weeks to to create a model that trains on (some of) the 79 explanators from the training set to predict `SalePrice` well in the test set. \n",
    "\n",
    "How will we know which explanators to use? We can start with some intuition and research into what each column represents by reading the data dictionary in `crash-course/Kaggle/DATA/house-prices/data_description.txt`. \n",
    "\n",
    "> Please take a moment to read over this dictionary, as you will need to have a keen sense of these features for the weeks ahead.\n",
    "\n",
    "Now that we've talked a bit about this dataset, let's actually take a look at it. The first step is to load in the data! We will store this in a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "5         Lvl    AllPub    ...            0    NaN  MnPrv        Shed     700   \n",
       "6         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "7         Lvl    AllPub    ...            0    NaN    NaN        Shed     350   \n",
       "8         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "9         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "5     10   2009        WD         Normal     143000  \n",
       "6      8   2007        WD         Normal     307000  \n",
       "7     11   2009        WD         Normal     200000  \n",
       "8      4   2008        WD        Abnorml     129900  \n",
       "9      1   2008        WD         Normal     118000  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('DATA/house-prices/train.csv')\n",
    "test = pd.read_csv('DATA/house-prices/test.csv')\n",
    "\n",
    "#Let's see what the training dataframe looks like!\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for Understanding:\n",
    "> 1. How many features (columns) do we have? How many entries (rows)?\n",
    "> 2. What does a single row represent in our dataset?\n",
    "> 3. List 3 issues/questions that you see from the dataset. Some ideas to get started: What does `LotShape` represent? Is it a good thing that we have so many features? How does a large number of features affect our modeling approach?\n",
    "> 4. What are some important things we should do for data cleaning and exploration? Some ideas to get started: are all the values in `LotFrontage` numeric? What about `Alley`? How should we fix missing/`NA` values that appear sporadically in some columns? What about columns that are almost entirely full of `NA` values? Some columns are qualitative strings, whereas others are qualitative numerics - how might this affect our cleaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Cleaning\n",
    "First, let's see how big our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size (1460, 81)\n",
      "Test size (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size\",train.shape)\n",
    "print(\"Test size\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we have $1460$ datapoints in the training set, and we would like to predict on $1459$ samples. There are $80$ total features, and one response variable we would like to predict. However, not all these 'features' are actually useful, such as `Id`. Thus we need to understand what the actual variables mean. A huge part in data science is actually understanding the variables. Of course it is possible to throw the data into some machine learning model and have it spit out predictions, but without actually understanding what data you are dealing with and how to feed the data into the model, your model is worthless.\n",
    "\n",
    "Spend a good deal of time reading over the data dictionary. It is located in  \n",
    "`crash-course/Kaggle/DATA/house-prices/data_description.txt`\n",
    "\n",
    "## Questions for Understanding:\n",
    "> 1. There are many categorical variables. What are some possibilities to deal with these variables? (Hint: [one hot encoding](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding))\n",
    "> 2. Are there any categorical variables that we can convert to numerical/quantitative variables as well? How might we do that?\n",
    "> 3. Are there any variables that are just irrelevant and we can ignore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NA values\n",
    "In almost all datasets, we will have NA values. These can be a pain to deal with, as there are many viable choices of what to do. First, it is good to see what columns have NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "                 ... \n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sum the number of NA's in each column\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that many of the features have a great deal of NAs. However, this is not necessarily the case. The astute reader will notice that some variables like `Alley`, `PoolQC`, and `Fence`, have NA has an actual value. For example for `Pool Quality`, we have these possibilities.\n",
    "\n",
    "PoolQC: Pool quality\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "So having NA values is not the usual not available, it can actually be a legitimate value! We need to parse through the data dictionary to see when NA's are actually significant, and when they actually mean NA.\n",
    "\n",
    "## Questions for Understanding:\n",
    "> 1. Go through the data dictionary and find all features that have NA as legitimate values.\n",
    "> 2. How can we refactor the variables in question 1 appropriately?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that we found with NA's are:\n",
    "`Alley`, `BsmtQual`, `BsmtCond`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2`, `FireplaceQu`, `GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`, `PoolQC`, `Fence`, `Misc Feature`.\n",
    "\n",
    "Alley: NA for no alley access  \n",
    "`BsmtQual`, `BsmtCond`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2`: NA for no basement  \n",
    "`FireplaceQu`: NA for no fireplace  \n",
    "`GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`: NA for no garage  \n",
    "`PoolQC`: NA for no pool  \n",
    "`Fence`: NA for no fence  \n",
    "`Misc Feature`: NA for no other miscellanous features (i.e. elevator, 2nd garage, shed, tennis Court, other) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Functions\n",
    "We provide some functions to help with data cleaning and preprocessing. One is creating one hot encodings of various features, and the latter is converting a categorical feature into values.\n",
    "\n",
    "### One Hot Encoding for Unordered Categorical Variables\n",
    "Consider we have a feature `committee` for a data frame of SUSA members. Let's say for sake of simplicity there are four committees, `CX`, `DC`, `RP`, and `WD`. There is no inherent ordering to the features, but each member is only in one committee. Thus we can replace this categorical variable with a single boolean for `committee`. If a member is a part of `CX`, then they will have a $1$ for `DC` and $0$ for all other variables. We have written this function for you in `oneHotFeature`.\n",
    "\n",
    "### Ordered Categorical Variables\n",
    "Consider we have a feature `attendance` for a data frame of SUSA members. Let's say there are $3$ possible values, `Good`, `Ok`, `Poor`. These inherently have an ordering, `Good` is better than `Okay` which is better than `Poor`. We can assign a numerical value to these, such as $0$ for `Poor`, $1$ for `Ok`, and $2$ for `Good`. We have written this function for you in `categoricalToQuantitative`.\n",
    "\n",
    "\n",
    "Please read over the following functions and read the comments carefully! They describe in detail what the functions do, and are **very** crucial to the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning Functions\n",
    "\n",
    "\n",
    "# This function is for unordered categorical features \n",
    "\n",
    "# This function takes in input as: \n",
    "# Data frame 'df'\n",
    "# List of features to one hot encode 'features'\n",
    "# Boolean for how to deal with NA's 'withNA'\n",
    "\n",
    "# This function creates a set of output features from a categorical feature\n",
    "# The output features are one hot encodings with names featureName_{value}\n",
    "# Returns a new data frame (does not modify original dataframe) with appended features\n",
    "# Usually the NA values are also considered\n",
    "# Will add a column featureName_none one hot encoding of NA values\n",
    "# If the boolean withNA is false, it will not consider NA values\n",
    "\n",
    "# If a feature is not found, it will ignore that feature and attempt to one hot the other features\n",
    "\n",
    "# Code from Numpy and Pandas SUSA guide\n",
    "# crash-course/Python/Numpy and Pandas.ipynb\n",
    "def oneHotFeature(df, features, withNA=True):\n",
    "    #Copy over data\n",
    "    newDf = df.copy()\n",
    "    for feature in features:\n",
    "        try:\n",
    "            if withNA:\n",
    "                newDf[feature] = newDf[feature].fillna('none')\n",
    "            col_onehot = pd.get_dummies(newDf[feature], prefix=feature) \n",
    "            newDf.drop(feature, axis=1)\n",
    "            newDf = newDf.join(col_onehot)\n",
    "        except:\n",
    "            print(\"No such feature\", feature, \"found in the dataframe when trying to one-hot encode!\")\n",
    "    return newDf\n",
    "\n",
    "\n",
    "# This function is for ordered categorical features \n",
    "\n",
    "# This function takes in input as: \n",
    "# Data frame 'df'\n",
    "# A single categorical feature to to be mapped 'feature'\n",
    "# A mapping dictionary 'mapping'\n",
    "\n",
    "# This function creates takes a dataframe and categorical feature, and maps the categorical values\n",
    "# using the dictionary mapping\n",
    "# Returns a new data frame (does not modify original dataframe) with modified values for the feature column\n",
    "# For mappings with NA values, use 'NA' in the dictionary, this function properly deals with them\n",
    "\n",
    "# If the mapping is just from 0 to n-1 for n values\n",
    "# Then set default to True, and mapping is instead a list of ordering from worst to best\n",
    "\n",
    "# If a feature is not found, the function will fail\n",
    "def categoricalToQuantitative(df,feature, mapping,assumeInOrder = False):\n",
    "    newDf = df.copy()\n",
    "    try:\n",
    "        newDf[feature] = newDf[feature].fillna('none')\n",
    "        if assumeInOrder:\n",
    "            newMapping ={}\n",
    "            for i in range(len(mapping)):\n",
    "                if mapping[i] == 'NA':\n",
    "                    newMapping['none'] = i \n",
    "                else:\n",
    "                    newMapping[mapping[i]] = i\n",
    "        else:    \n",
    "            newMapping = mapping.copy()\n",
    "            if 'NA' in newMapping.keys():\n",
    "                newMapping['none'] = newMapping['NA']\n",
    "        newDf[feature] = newDf[feature].apply(lambda feat: newMapping[feat] if feat in newMapping.keys() else feat)\n",
    "    except:\n",
    "        print(\"No such feature\", feature, \"found in the dataframe when trying to map!\")\n",
    "    return newDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the first function `oneHotFeature` first. Consider the `Heating` feature. There are $5$ possible values, Brick & Tile, Cinder Block, Poured Concrete, Slab, Stone and Wood. There isn't an inherent ordering to these, where one is better than the other. The best way to go about preprocessing the data is through one hot encoding the data. We remove the `Foundation` feature and replace it with $5$ separate boolean features, one for each of the possible values.\n",
    "\n",
    "The dataframe is shown below. Keep in mind that the original dataframe, `train`, is not modified in this function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Foundation_BrkTil</th>\n",
       "      <th>Foundation_CBlock</th>\n",
       "      <th>Foundation_PConc</th>\n",
       "      <th>Foundation_Slab</th>\n",
       "      <th>Foundation_Stone</th>\n",
       "      <th>Foundation_Wood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities       ...        YrSold SaleType SaleCondition  \\\n",
       "0         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "1         Lvl    AllPub       ...          2007       WD        Normal   \n",
       "2         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "3         Lvl    AllPub       ...          2006       WD       Abnorml   \n",
       "4         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "5         Lvl    AllPub       ...          2009       WD        Normal   \n",
       "6         Lvl    AllPub       ...          2007       WD        Normal   \n",
       "7         Lvl    AllPub       ...          2009       WD        Normal   \n",
       "8         Lvl    AllPub       ...          2008       WD       Abnorml   \n",
       "9         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "\n",
       "  SalePrice Foundation_BrkTil Foundation_CBlock Foundation_PConc  \\\n",
       "0    208500                 0                 0                1   \n",
       "1    181500                 0                 1                0   \n",
       "2    223500                 0                 0                1   \n",
       "3    140000                 1                 0                0   \n",
       "4    250000                 0                 0                1   \n",
       "5    143000                 0                 0                0   \n",
       "6    307000                 0                 0                1   \n",
       "7    200000                 0                 1                0   \n",
       "8    129900                 1                 0                0   \n",
       "9    118000                 1                 0                0   \n",
       "\n",
       "   Foundation_Slab  Foundation_Stone  Foundation_Wood  \n",
       "0                0                 0                0  \n",
       "1                0                 0                0  \n",
       "2                0                 0                0  \n",
       "3                0                 0                0  \n",
       "4                0                 0                0  \n",
       "5                0                 0                1  \n",
       "6                0                 0                0  \n",
       "7                0                 0                0  \n",
       "8                0                 0                0  \n",
       "9                0                 0                0  \n",
       "\n",
       "[10 rows x 87 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotFeature(train,['Foundation']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     PConc\n",
       "1    CBlock\n",
       "2     PConc\n",
       "3    BrkTil\n",
       "4     PConc\n",
       "5      Wood\n",
       "6     PConc\n",
       "7    CBlock\n",
       "8    BrkTil\n",
       "9    BrkTil\n",
       "Name: Foundation, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train is not modified\n",
    "train['Foundation'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may try this with the other function `categoricalToQuantitative`, mapping a categorical data where there is an quantitative correspondence. Consider the feature `FireplaceQu`. There are $6$ possible values, `Ex`, `Gd`, `TA`, `Fa`, `Po`, `NA`, corresponding to Excellent, Good, Average, Fair, Poor, and No fireplace. These could be mapped to the values from $0$ to $5$, in order of quality. Thus we can make a dictionary of values, where `Ex` corresponds to $5$, `Gd` corresponds to $4$, ..., `NA` corresponds to zero. This is written out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1     TA\n",
      "2     TA\n",
      "3     Gd\n",
      "4     TA\n",
      "5    NaN\n",
      "6     Gd\n",
      "7     TA\n",
      "8     TA\n",
      "9     TA\n",
      "Name: FireplaceQu, dtype: object\n",
      "0    0\n",
      "1    3\n",
      "2    3\n",
      "3    4\n",
      "4    3\n",
      "5    0\n",
      "6    4\n",
      "7    3\n",
      "8    3\n",
      "9    3\n",
      "Name: FireplaceQu, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "mapping['NA'] = 0\n",
    "mapping['Po'] = 1\n",
    "mapping['Fa'] = 2\n",
    "mapping['TA'] = 3\n",
    "mapping['Gd'] = 4\n",
    "mapping['Ex'] = 5\n",
    "\n",
    "print(train['FireplaceQu'].head(10))\n",
    "print(categoricalToQuantitative(train,'FireplaceQu',mapping)['FireplaceQu'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is a bit annoying to type out the entire dictionary like that if we would like to order from $0$ to $5$. Another variable in `categoricalToQuantitative` is `default`. If `assumeInOrder` is true, then mapping is instead a list of variables rather than a dictionary, and we can just pass in the order of values from worst to best. This maps from $0$ to $n-1$ when there are $n$ possible values. This is more convenient, but it may be better at times to be able to customize how you want to map the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    3\n",
      "2    3\n",
      "3    4\n",
      "4    3\n",
      "5    0\n",
      "6    4\n",
      "7    3\n",
      "8    3\n",
      "9    3\n",
      "Name: FireplaceQu, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mapping = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "#Notice these mappings are the same\n",
    "print(categoricalToQuantitative(train,'FireplaceQu',mapping,assumeInOrder=True)['FireplaceQu'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to remove a feature, use the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-85f8c8cf4ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe.drop(feature, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above two functions to clean the dataset! This may take a while, but doing a good job should take a while. Decide what variables are not worth keeping, decide what categorical features need to be changed, and how they should be changed. Consider how to deal with NA values, and keep all these commands together. We would recommend to save the final cleaned file as a csv so that you may easily reopen and send it, and also keep all the commands together neatly in the code block below.\n",
    "\n",
    "Some recommendations:\n",
    "> 1. Convert all features into quantitative values\n",
    "> 2. While cleaning, keep in mind some features that you feel are very helpful.\n",
    "> 3. Remove features that do not seem important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>Neighborhood_NoRidge</th>\n",
       "      <th>Neighborhood_NridgHt</th>\n",
       "      <th>Neighborhood_OldTown</th>\n",
       "      <th>Neighborhood_SWISU</th>\n",
       "      <th>Neighborhood_Sawyer</th>\n",
       "      <th>Neighborhood_SawyerW</th>\n",
       "      <th>Neighborhood_Somerst</th>\n",
       "      <th>Neighborhood_StoneBr</th>\n",
       "      <th>Neighborhood_Timber</th>\n",
       "      <th>Neighborhood_Veenker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>none</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave  none      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave  none      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave  none        2   \n",
       "3   4          70       RL         60.0     9550   Pave  none        2   \n",
       "4   5          60       RL         84.0    14260   Pave  none        2   \n",
       "5   6          50       RL         85.0    14115   Pave  none        2   \n",
       "6   7          20       RL         75.0    10084   Pave  none      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave  none        2   \n",
       "8   9          50       RM         51.0     6120   Pave  none      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave  none      Reg   \n",
       "\n",
       "  LandContour  Utilities          ...          Neighborhood_NoRidge  \\\n",
       "0         Lvl          3          ...                             0   \n",
       "1         Lvl          3          ...                             0   \n",
       "2         Lvl          3          ...                             0   \n",
       "3         Lvl          3          ...                             0   \n",
       "4         Lvl          3          ...                             1   \n",
       "5         Lvl          3          ...                             0   \n",
       "6         Lvl          3          ...                             0   \n",
       "7         Lvl          3          ...                             0   \n",
       "8         Lvl          3          ...                             0   \n",
       "9         Lvl          3          ...                             0   \n",
       "\n",
       "   Neighborhood_NridgHt Neighborhood_OldTown Neighborhood_SWISU  \\\n",
       "0                     0                    0                  0   \n",
       "1                     0                    0                  0   \n",
       "2                     0                    0                  0   \n",
       "3                     0                    0                  0   \n",
       "4                     0                    0                  0   \n",
       "5                     0                    0                  0   \n",
       "6                     0                    0                  0   \n",
       "7                     0                    0                  0   \n",
       "8                     0                    1                  0   \n",
       "9                     0                    0                  0   \n",
       "\n",
       "  Neighborhood_Sawyer Neighborhood_SawyerW Neighborhood_Somerst  \\\n",
       "0                   0                    0                    0   \n",
       "1                   0                    0                    0   \n",
       "2                   0                    0                    0   \n",
       "3                   0                    0                    0   \n",
       "4                   0                    0                    0   \n",
       "5                   0                    0                    0   \n",
       "6                   0                    0                    1   \n",
       "7                   0                    0                    0   \n",
       "8                   0                    0                    0   \n",
       "9                   0                    0                    0   \n",
       "\n",
       "   Neighborhood_StoneBr  Neighborhood_Timber  Neighborhood_Veenker  \n",
       "0                     0                    0                     0  \n",
       "1                     0                    0                     1  \n",
       "2                     0                    0                     0  \n",
       "3                     0                    0                     0  \n",
       "4                     0                    0                     0  \n",
       "5                     0                    0                     0  \n",
       "6                     0                    0                     0  \n",
       "7                     0                    0                     0  \n",
       "8                     0                    0                     0  \n",
       "9                     0                    0                     0  \n",
       "\n",
       "[10 rows x 131 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA CLEANING\n",
    "# To start off data cleaning\n",
    "clean = train.copy()\n",
    "\n",
    "\n",
    "clean = categoricalToQuantitative(clean,'FireplaceQu',['NA','Po','Fa','TA','Gd','Ex'],assumeInOrder=True)\n",
    "clean = oneHotFeature(clean,['Foundation'])\n",
    "\n",
    "# DATA CLEANING SOLUTION\n",
    "\n",
    "# ====================== DO NOT INCLUDE IN FINAL WORKBOOK ========================\n",
    "\n",
    "unorderedFeatures = ['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood']\n",
    "clean = oneHotFeature(clean,unorderedFeatures)\n",
    "clean = categoricalToQuantitative(clean,'LotShape',['IR3','IR2','IR1','R'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'Utilities',['ELO','NoSeWa','NoSewr','AllPub'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'LandSlope',['Sev','Mod','Gtl'],assumeInOrder=True)\n",
    "clean = categoricalToQuantitative(clean,'LandSlope',['Sev','Mod','Gtl'],assumeInOrder=True)\n",
    "\n",
    "## STILL IN PROGRESS\n",
    "\n",
    "# ================================================================================\n",
    "\n",
    "clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the dataframe as csv, run this line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "clean.to_csv('DATA/house-prices/train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Exploratory Data Analysis\n",
    "\n",
    "Now that we've \n",
    "\n",
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Modeling\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "## A First Approach to Machine Learning: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Model Evaluation\n",
    "\n",
    "Now it's time to actually see how your model performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Regression\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "This ends our textbook-style primer into deep learning with Keras. While this was just an introduction to neural nets, we hope that you can now see some of the workflow patterns associated with machine learning. Feel free to play around with the code above to get a better feel for the hyperparameters of the neural net model. As always, please email [`contact@arun.run`](mailto:contact@arun.run) or [`prc@berkeley.edu`](mailto:prc@berkeley.edu) with any questions or concerns whatsoever. Happy machine learning!\n",
    "\n",
    "## Sneakpeek at SUSA Kaggle Competition II\n",
    "\n",
    "After Spring Break, we will be guiding you through a four-week collaborative Kaggle competition with your peers in Career Exploration! We want to give you the experience of working with real data, using real machine learning algorithms, in an educational setting. You will have to choose either Python or R, and dive into reading kernels on the Kaggle website, use visualization and feature engineering to improve your score, and maybe even pick up a few advanced deep learning models along the way. If this sounds a bit intimidating right now, do not fret! Your SUSA Mentors will be there to mentor you through the whole thing. So rest up during Spring Break, and come back ready to tackle your biggest data challenge yet!\n",
    "\n",
    "# Additional Reading\n",
    "* For more information on the Kaggle API, a command-line program used to download and manage Kaggle datasets, visit the [Kaggle API Github page](https://github.com/Kaggle/kaggle-api)  \n",
    "* For an interactive guide to learning R and Python, visit [DataCamp](https://www.datacamp.com/) a paid tutorial website for learning data computing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
