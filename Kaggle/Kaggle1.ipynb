{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUSA Kaggle Competition\n",
    "## Part 1: Exploratory Data Analysis and Kaggle Introduction\n",
    "### Hosted by and maintained by the [Statistics Undergraduate Students Association (SUSA)](https://susa.berkeley.edu). Originally authored by [Arun Ramamurthy](mailto:contact@arun.run), [Patrick Chao](mailto:prc@berkeley.edu), & [Noah Gundotra](mailto:noah.gundotra@berkeley.edu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "\n",
    "## What is Kaggle?\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "## Accessing the `House Prices` Dataset\n",
    "\n",
    "`crash-course/Kaggle/DATA/house-prices/train.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "The first step is to load in the data! We will store this in a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "5         Lvl    AllPub    ...            0    NaN  MnPrv        Shed     700   \n",
       "6         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "7         Lvl    AllPub    ...            0    NaN    NaN        Shed     350   \n",
       "8         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "9         Lvl    AllPub    ...            0    NaN    NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "5     10   2009        WD         Normal     143000  \n",
       "6      8   2007        WD         Normal     307000  \n",
       "7     11   2009        WD         Normal     200000  \n",
       "8      4   2008        WD        Abnorml     129900  \n",
       "9      1   2008        WD         Normal     118000  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('DATA/house-prices/train.csv')\n",
    "test = pd.read_csv('DATA/house-prices/test.csv')\n",
    "\n",
    "#Let's see what the training dataframe looks like!\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions for Understanding:\n",
    "> 1. How many features do we have?\n",
    "> 2. List 3 issues/questions that you see from the dataset\n",
    "> 3. What are some important things we should do for data cleaning and exploration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data Science Workflow\n",
    "\n",
    "In general, there are a few key steps to begin working with a dataset. First, we need to understand what the dataset actually is about, and what we are trying to do with it. Second it is very helpful to identify the size of the dataset, so we know how many samples we have. We need to determine a consistent method of dealing with missing values, such as setting them to a value, removing the feature entirely, interpolating values, etc. Other crucial steps are separating into training and validation, as well as creating elementary data plots. \n",
    "\n",
    "## What is our dataset? TODO\n",
    "Our dataset is from blank, and we are trying to do blank \n",
    "\n",
    "# Data Cleaning\n",
    "First, let's see how big our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size (1460, 81)\n",
      "Test size (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size\",train.shape)\n",
    "print(\"Test size\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we have $1460$ datapoints in the training set, and we would like to predict on $1459$ samples. There are $80$ total features, and one response variable we would like to predict. However, not all these 'features' are actually useful, such as `Id`. Thus we need to understand what the actual variables mean. A huge part in data science is actually understanding the variables. Of course it is possible to throw the data into some machine learning model and have it spit out predictions, but without actually understanding what data you are dealing with and how to feed the data into the model, your model is worthless.\n",
    "\n",
    "Spend a good deal of time reading over the data dictionary. It is located in  \n",
    "`crash-course/Kaggle/DATA/house-prices/data_description.txt`\n",
    "\n",
    "## Questions for Understanding:\n",
    "> 1. There are many categorical variables. What are some possibilities to deal with these variables? (Hint: [one hot encoding](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding))\n",
    "> 2. Are there any categorical variables that we can convert to numerical/quantitative variables as well? How might we do that?\n",
    "> 3. Are there any variables that are just irrelevant and we can ignore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NA values\n",
    "In almost all datasets, we will have NA values. These can be a pain to deal with, as there are many viable choices of what to do. First, it is good to see what columns have NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "                 ... \n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sum the number of NA's in each column\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that many of the features have a great deal of NAs. However, this is not necessarily the case. The astute reader will notice that some variables like `Alley`, `PoolQC`, and `Fence`, have NA has an actual value. For example for `Pool Quality`, we have these possibilities.\n",
    "\n",
    "PoolQC: Pool quality\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "So having NA values is not the usual not available, it can actually be a legitimate value! We need to parse through the data dictionary to see when NA's are actually significant, and when they actually mean NA.\n",
    "\n",
    "## Questions for Understanding:\n",
    "> 1. Go through the data dictionary and find all features that have NA as legitimate values.\n",
    "> 2. How can we refactor the variables in question 1 appropriately?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features that we found with NA's are:\n",
    "`Alley`, `BsmtQual`, `BsmtCond`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2`, `FireplaceQu`, `GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`, `PoolQC`, `Fence`, `Misc Feature`.\n",
    "\n",
    "Alley: NA for no alley access  \n",
    "`BsmtQual`, `BsmtCond`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2`: NA for no basement  \n",
    "`FireplaceQu`: NA for no fireplace  \n",
    "`GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`: NA for no garage  \n",
    "`PoolQC`: NA for no pool  \n",
    "`Fence`: NA for no fence  \n",
    "`Misc Feature`: NA for no other miscellanous features (i.e. elevator, 2nd garage, shed, tennis Court, other) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Functions\n",
    "We provide some functions to help with data cleaning and preprocessing. One is creating one hot encodings of various features, and the latter is converting a categorical feature into values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning Functions\n",
    "\n",
    "\n",
    "# This function takes in input as: \n",
    "# Data frame 'df'\n",
    "# List of features to one hot encode 'features'\n",
    "# Boolean for how to deal with NA's 'withNA'\n",
    "\n",
    "# This function creates a set of output features from a categorical feature\n",
    "# The output features are one hot encodings with names featureName_{value}\n",
    "# Returns a new data frame (does not modify original dataframe) with appended features\n",
    "# Usually the NA values are also considered\n",
    "# Will add a column featureName_none one hot encoding of NA values\n",
    "# If the boolean withNA is false, it will not consider NA values\n",
    "\n",
    "# If a feature is not found, it will ignore that feature and attempt to one hot the other features\n",
    "\n",
    "# Code from Numpy and Pandas SUSA guide\n",
    "# crash-course/Python/Numpy and Pandas.ipynb\n",
    "def oneHotFeature(df, features, withNA=True):\n",
    "    #Copy over data\n",
    "    newDf = df.copy()\n",
    "    for feature in features:\n",
    "        try:\n",
    "            if withNA:\n",
    "                newDf[feature] = newDf[feature].fillna('none')\n",
    "        \n",
    "            col_onehot = pd.get_dummies(newDf[feature], prefix=feature) \n",
    "            newDf.drop(feature, axis=1)\n",
    "            newDf = newDf.join(col_onehot)\n",
    "        except:\n",
    "            print(\"No such feature\", feature, \"found in the dataframe when trying to one-hot encode!\")\n",
    "    return newDf\n",
    "\n",
    "# This function takes in input as: \n",
    "# Data frame 'df'\n",
    "# A single categorical feature to to be mapped 'feature'\n",
    "# A mapping dictionary 'mapping'\n",
    "\n",
    "# This function creates takes a dataframe and categorical feature, and maps the categorical values\n",
    "# using the dictionary mapping\n",
    "# Returns a new data frame (does not modify original dataframe) with modified values for the feature column\n",
    "# For mappings with NA values, use 'NA' in the dictionary, this function properly deals with them\n",
    "\n",
    "# If the mapping is just from 0 to n-1 for n values\n",
    "# Then set default to True, and mapping is instead a list of ordering from worst to best\n",
    "\n",
    "# If a feature is not found, the function will fail\n",
    "def categoricalToQuantitative(df,feature, mapping,assumeInOrder = False):\n",
    "    newDf = df.copy()\n",
    "    try:\n",
    "        newDf[feature] = newDf[feature].fillna('none')\n",
    "        if assumeInOrder:\n",
    "            newMapping ={}\n",
    "            for i in range(len(mapping)):\n",
    "                if mapping[i] == 'NA':\n",
    "                    newMapping['none'] = i \n",
    "                else:\n",
    "                    newMapping[mapping[i]] = i\n",
    "        else:    \n",
    "            newMapping = mapping.copy()\n",
    "\n",
    "            if 'NA' in newMapping.keys():\n",
    "                newMapping['none'] = newMapping['NA']\n",
    "        newDf[feature] = newDf[feature].apply(lambda feat: newMapping[feat] if feat in newMapping.keys() else feat)\n",
    "    except:\n",
    "        print(\"No such feature\", feature, \"found in the dataframe when trying to map!\")\n",
    "    return newDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the first function `oneHotFeature` first. Consider the `Heating` feature. There are $5$ possible values, Brick & Tile, Cinder Block, Poured Concrete, Slab, Stone and Wood. There isn't an inherent ordering to these, where one is better than the other. The best way to go about preprocessing the data is through one hot encoding the data. We remove the `Foundation` feature and replace it with $5$ separate boolean features, one for each of the possible values.\n",
    "\n",
    "The dataframe is shown below. Keep in mind that the original dataframe, `train`, is not modified in this function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Foundation_BrkTil</th>\n",
       "      <th>Foundation_CBlock</th>\n",
       "      <th>Foundation_PConc</th>\n",
       "      <th>Foundation_Slab</th>\n",
       "      <th>Foundation_Stone</th>\n",
       "      <th>Foundation_Wood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities       ...        YrSold SaleType SaleCondition  \\\n",
       "0         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "1         Lvl    AllPub       ...          2007       WD        Normal   \n",
       "2         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "3         Lvl    AllPub       ...          2006       WD       Abnorml   \n",
       "4         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "5         Lvl    AllPub       ...          2009       WD        Normal   \n",
       "6         Lvl    AllPub       ...          2007       WD        Normal   \n",
       "7         Lvl    AllPub       ...          2009       WD        Normal   \n",
       "8         Lvl    AllPub       ...          2008       WD       Abnorml   \n",
       "9         Lvl    AllPub       ...          2008       WD        Normal   \n",
       "\n",
       "  SalePrice Foundation_BrkTil Foundation_CBlock Foundation_PConc  \\\n",
       "0    208500                 0                 0                1   \n",
       "1    181500                 0                 1                0   \n",
       "2    223500                 0                 0                1   \n",
       "3    140000                 1                 0                0   \n",
       "4    250000                 0                 0                1   \n",
       "5    143000                 0                 0                0   \n",
       "6    307000                 0                 0                1   \n",
       "7    200000                 0                 1                0   \n",
       "8    129900                 1                 0                0   \n",
       "9    118000                 1                 0                0   \n",
       "\n",
       "   Foundation_Slab  Foundation_Stone  Foundation_Wood  \n",
       "0                0                 0                0  \n",
       "1                0                 0                0  \n",
       "2                0                 0                0  \n",
       "3                0                 0                0  \n",
       "4                0                 0                0  \n",
       "5                0                 0                1  \n",
       "6                0                 0                0  \n",
       "7                0                 0                0  \n",
       "8                0                 0                0  \n",
       "9                0                 0                0  \n",
       "\n",
       "[10 rows x 87 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotFeature(train,['Foundation']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     PConc\n",
       "1    CBlock\n",
       "2     PConc\n",
       "3    BrkTil\n",
       "4     PConc\n",
       "5      Wood\n",
       "6     PConc\n",
       "7    CBlock\n",
       "8    BrkTil\n",
       "9    BrkTil\n",
       "Name: Foundation, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train is not modified\n",
    "train['Foundation'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may try this with the other function `categoricalToQuantitative`, mapping a categorical data where there is an quantitative correspondence. Consider the feature `FireplaceQu`. There are $6$ possible values, `Ex`, `Gd`, `TA`, `Fa`, `Po`, `NA`, corresponding to Excellent, Good, Average, Fair, Poor, and No fireplace. These could be mapped to the values from $0$ to $5$, in order of quality. Thus we can make a dictionary of values, where `Ex` corresponds to $5$, `Gd` corresponds to $4$, ..., `NA` corresponds to zero. This is written out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1     TA\n",
      "2     TA\n",
      "3     Gd\n",
      "4     TA\n",
      "5    NaN\n",
      "6     Gd\n",
      "7     TA\n",
      "8     TA\n",
      "9     TA\n",
      "Name: FireplaceQu, dtype: object\n",
      "0    0\n",
      "1    3\n",
      "2    3\n",
      "3    4\n",
      "4    3\n",
      "5    0\n",
      "6    4\n",
      "7    3\n",
      "8    3\n",
      "9    3\n",
      "Name: FireplaceQu, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "mapping['NA'] = 0\n",
    "mapping['Po'] = 1\n",
    "mapping['Fa'] = 2\n",
    "mapping['TA'] = 3\n",
    "mapping['Gd'] = 4\n",
    "mapping['Ex'] = 5\n",
    "\n",
    "print(train['FireplaceQu'].head(10))\n",
    "print(categoricalToQuantitative(train,'FireplaceQu',mapping)['FireplaceQu'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is a bit annoying to type out the entire dictionary like that if we would like to order from $0$ to $5$. Another variable in `categoricalToQuantitative` is `default`. If `assumeInOrder` is true, then mapping is instead a list of variables rather than a dictionary, and we can just pass in the order of values from worst to best. This maps from $0$ to $n-1$ when there are $n$ possible values. This is more convenient, but it may be better at times to be able to customize how you want to map the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    3\n",
      "2    3\n",
      "3    4\n",
      "4    3\n",
      "5    0\n",
      "6    4\n",
      "7    3\n",
      "8    3\n",
      "9    3\n",
      "Name: FireplaceQu, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mapping = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "#Notice these mappings are the same\n",
    "print(categoricalToQuantitative(train,'FireplaceQu',mapping,assumeInOrder=True)['FireplaceQu'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above two functions to clean the dataset! This may take a while, but doing a good job should take a while. Decide what variables are not worth keeping, decide what categorical features need to be changed, and how they should be changed. Consider how to deal with NA values, and keep all these commands together. We would recommend to save the final cleaned file as a csv so that you may easily reopen and send it, and also keep all the commands together neatly in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-c41f10c0ecda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# DATA CLEANING\n",
    "# To start off data cleaning\n",
    "clean = train.copy()\n",
    "\n",
    "mapping = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "clean = categoricalToQuantitative(clean,'FireplaceQu',mapping,assumeInOrder=True)\n",
    "clean = oneHotFeature(clean,['Foundation'])\n",
    "\n",
    "# More cleaning here!!\n",
    "\n",
    "\n",
    "clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the dataframe as csv, run this line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "clean.to_csv('DATA/house-prices/train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "# A First Approach to Machine Learning: Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Regression\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "This ends our textbook-style primer into deep learning with Keras. While this was just an introduction to neural nets, we hope that you can now see some of the workflow patterns associated with machine learning. Feel free to play around with the code above to get a better feel for the hyperparameters of the neural net model. As always, please email [`contact@arun.run`](mailto:contact@arun.run) or [`prc@berkeley.edu`](mailto:prc@berkeley.edu) with any questions or concerns whatsoever. Happy machine learning!\n",
    "\n",
    "## Sneakpeek at SUSA Kaggle Competition II\n",
    "\n",
    "After Spring Break, we will be guiding you through a four-week collaborative Kaggle competition with your peers in Career Exploration! We want to give you the experience of working with real data, using real machine learning algorithms, in an educational setting. You will have to choose either Python or R, and dive into reading kernels on the Kaggle website, use visualization and feature engineering to improve your score, and maybe even pick up a few advanced deep learning models along the way. If this sounds a bit intimidating right now, do not fret! Your SUSA Mentors will be there to mentor you through the whole thing. So rest up during Spring Break, and come back ready to tackle your biggest data challenge yet!\n",
    "\n",
    "# Additional Reading\n",
    "* For more information on the Kaggle API, a command-line program used to download and manage Kaggle datasets, visit the [Kaggle API Github page](https://github.com/Kaggle/kaggle-api)  \n",
    "* For an interactive guide to learning R and Python, visit [DataCamp](https://www.datacamp.com/) a paid tutorial website for learning data computing.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
